{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e38e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c03b8a",
   "metadata": {},
   "source": [
    "# Viewing the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfa98cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(Path('./WA_Fn-UseC_-Telco-Customer-Churn.csv'), low_memory=False)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9616d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Prints the column names and their unique values.\"\"\"\n",
    "    if isinstance(df, pd.core.series.Series):\n",
    "        print(f\"{df.unique()}\")\n",
    "    elif isinstance(df, pd.core.frame.DataFrame):\n",
    "        for col in df:\n",
    "            print(f\"{col}: {df[col].unique()}\")\n",
    "    else:\n",
    "        raise TypeError(f\"Expected DataFrame or Series, recieved {type(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cd85f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID: ['7590-VHVEG' '5575-GNVDE' '3668-QPYBK' ... '4801-JZAZL' '8361-LTMKD'\n",
      " '3186-AJIEK']\n",
      "gender: ['Female' 'Male']\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: ['Yes' 'No']\n",
      "Dependents: ['No' 'Yes']\n",
      "tenure: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
      " 39]\n",
      "PhoneService: ['No' 'Yes']\n",
      "MultipleLines: ['No phone service' 'No' 'Yes']\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: ['No' 'Yes' 'No internet service']\n",
      "OnlineBackup: ['Yes' 'No' 'No internet service']\n",
      "DeviceProtection: ['No' 'Yes' 'No internet service']\n",
      "TechSupport: ['No' 'Yes' 'No internet service']\n",
      "StreamingTV: ['No' 'Yes' 'No internet service']\n",
      "StreamingMovies: ['No' 'Yes' 'No internet service']\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: ['Yes' 'No']\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print_unique(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69abca",
   "metadata": {},
   "source": [
    "## Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c470f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = raw_data.drop(labels=['customerID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37281a7",
   "metadata": {},
   "source": [
    "## Reduce unessecary variable cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe32189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: ['Female' 'Male']\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: ['Yes' 'No']\n",
      "Dependents: ['No' 'Yes']\n",
      "tenure: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
      " 39]\n",
      "PhoneService: ['No' 'Yes']\n",
      "MultipleLines: ['No' 'Yes']\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: ['No' 'Yes']\n",
      "OnlineBackup: ['Yes' 'No']\n",
      "DeviceProtection: ['No' 'Yes']\n",
      "TechSupport: ['No' 'Yes']\n",
      "StreamingTV: ['No' 'Yes']\n",
      "StreamingMovies: ['No' 'Yes']\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: ['Yes' 'No']\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['TechSupport'].replace('No internet service', 'No', inplace=True)\n",
    "cleaned_data['StreamingTV'].replace('No internet service', 'No', inplace=True)\n",
    "cleaned_data['MultipleLines'].replace('No phone service', 'No', inplace=True)\n",
    "cleaned_data['OnlineSecurity'].replace('No internet service', 'No', inplace=True)\n",
    "cleaned_data['OnlineBackup'].replace('No internet service', 'No', inplace=True)\n",
    "cleaned_data['DeviceProtection'].replace('No internet service', 'No', inplace=True)\n",
    "cleaned_data['StreamingMovies'].replace('No internet service', 'No', inplace=True)\n",
    "print_unique(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39c78b",
   "metadata": {},
   "source": [
    "## These columns will be encoded as 1 - Yes or 0 - No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dab85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
    "           'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51691ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['gender'].replace({\"Male\": 1, \"Female\": 0}, inplace=True)\n",
    "print_unique(cleaned_data['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28fd19d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: [0 1]\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: [1 0]\n",
      "Dependents: [0 1]\n",
      "tenure: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
      " 39]\n",
      "PhoneService: [0 1]\n",
      "MultipleLines: [0 1]\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: [0 1]\n",
      "OnlineBackup: [1 0]\n",
      "DeviceProtection: [0 1]\n",
      "TechSupport: [0 1]\n",
      "StreamingTV: [0 1]\n",
      "StreamingMovies: [0 1]\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: [1 0]\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: [0 1]\n"
     ]
    }
   ],
   "source": [
    "for column in binary_cols:\n",
    "    cleaned_data[column].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
    "print_unique(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c01d13",
   "metadata": {},
   "source": [
    "## One-Hot Encode Non-Binary Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88815770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: [0 1]\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: [1 0]\n",
      "Dependents: [0 1]\n",
      "tenure: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
      " 39]\n",
      "PhoneService: [0 1]\n",
      "MultipleLines: [0 1]\n",
      "OnlineSecurity: [0 1]\n",
      "OnlineBackup: [1 0]\n",
      "DeviceProtection: [0 1]\n",
      "TechSupport: [0 1]\n",
      "StreamingTV: [0 1]\n",
      "StreamingMovies: [0 1]\n",
      "PaperlessBilling: [1 0]\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: [0 1]\n",
      "Contract_Month-to-month: [1 0]\n",
      "Contract_One year: [0 1]\n",
      "Contract_Two year: [0 1]\n",
      "PaymentMethod_Bank transfer (automatic): [0 1]\n",
      "PaymentMethod_Credit card (automatic): [0 1]\n",
      "PaymentMethod_Electronic check: [1 0]\n",
      "PaymentMethod_Mailed check: [0 1]\n",
      "InternetService_DSL: [1 0]\n",
      "InternetService_Fiber optic: [0 1]\n",
      "InternetService_No: [0 1]\n"
     ]
    }
   ],
   "source": [
    "one_hot_vars = [\"Contract\", \"PaymentMethod\", \"InternetService\"]\n",
    "cleaned_data = pd.get_dummies(cleaned_data, columns=one_hot_vars)\n",
    "print_unique(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d97c0",
   "metadata": {},
   "source": [
    "## Investigate the TotalCharges variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc4c6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data['TotalCharges'].value_counts()[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1c07d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4472-LVYGI</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>52.55</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>3115-CZMZD</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.25</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>5709-LVOEQ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>80.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>4367-NUYAO</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.75</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1371-DWPAZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>56.05</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>7644-OMVMY</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>3213-VVOLG</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>2520-SGTTA</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>2923-ARZLG</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.70</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>4075-WKNIU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>73.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>2775-SEFEE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>61.90</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "488   4472-LVYGI  Female              0     Yes        Yes       0   \n",
       "753   3115-CZMZD    Male              0      No        Yes       0   \n",
       "936   5709-LVOEQ  Female              0     Yes        Yes       0   \n",
       "1082  4367-NUYAO    Male              0     Yes        Yes       0   \n",
       "1340  1371-DWPAZ  Female              0     Yes        Yes       0   \n",
       "3331  7644-OMVMY    Male              0     Yes        Yes       0   \n",
       "3826  3213-VVOLG    Male              0     Yes        Yes       0   \n",
       "4380  2520-SGTTA  Female              0     Yes        Yes       0   \n",
       "5218  2923-ARZLG    Male              0     Yes        Yes       0   \n",
       "6670  4075-WKNIU  Female              0     Yes        Yes       0   \n",
       "6754  2775-SEFEE    Male              0      No        Yes       0   \n",
       "\n",
       "     PhoneService     MultipleLines InternetService       OnlineSecurity  \\\n",
       "488            No  No phone service             DSL                  Yes   \n",
       "753           Yes                No              No  No internet service   \n",
       "936           Yes                No             DSL                  Yes   \n",
       "1082          Yes               Yes              No  No internet service   \n",
       "1340           No  No phone service             DSL                  Yes   \n",
       "3331          Yes                No              No  No internet service   \n",
       "3826          Yes               Yes              No  No internet service   \n",
       "4380          Yes                No              No  No internet service   \n",
       "5218          Yes                No              No  No internet service   \n",
       "6670          Yes               Yes             DSL                   No   \n",
       "6754          Yes               Yes             DSL                  Yes   \n",
       "\n",
       "             OnlineBackup     DeviceProtection          TechSupport  \\\n",
       "488                    No                  Yes                  Yes   \n",
       "753   No internet service  No internet service  No internet service   \n",
       "936                   Yes                  Yes                   No   \n",
       "1082  No internet service  No internet service  No internet service   \n",
       "1340                  Yes                  Yes                  Yes   \n",
       "3331  No internet service  No internet service  No internet service   \n",
       "3826  No internet service  No internet service  No internet service   \n",
       "4380  No internet service  No internet service  No internet service   \n",
       "5218  No internet service  No internet service  No internet service   \n",
       "6670                  Yes                  Yes                  Yes   \n",
       "6754                  Yes                   No                  Yes   \n",
       "\n",
       "              StreamingTV      StreamingMovies  Contract PaperlessBilling  \\\n",
       "488                   Yes                   No  Two year              Yes   \n",
       "753   No internet service  No internet service  Two year               No   \n",
       "936                   Yes                  Yes  Two year               No   \n",
       "1082  No internet service  No internet service  Two year               No   \n",
       "1340                  Yes                   No  Two year               No   \n",
       "3331  No internet service  No internet service  Two year               No   \n",
       "3826  No internet service  No internet service  Two year               No   \n",
       "4380  No internet service  No internet service  Two year               No   \n",
       "5218  No internet service  No internet service  One year              Yes   \n",
       "6670                  Yes                   No  Two year               No   \n",
       "6754                   No                   No  Two year              Yes   \n",
       "\n",
       "                  PaymentMethod  MonthlyCharges TotalCharges Churn  \n",
       "488   Bank transfer (automatic)           52.55                 No  \n",
       "753                Mailed check           20.25                 No  \n",
       "936                Mailed check           80.85                 No  \n",
       "1082               Mailed check           25.75                 No  \n",
       "1340    Credit card (automatic)           56.05                 No  \n",
       "3331               Mailed check           19.85                 No  \n",
       "3826               Mailed check           25.35                 No  \n",
       "4380               Mailed check           20.00                 No  \n",
       "5218               Mailed check           19.70                 No  \n",
       "6670               Mailed check           73.35                 No  \n",
       "6754  Bank transfer (automatic)           61.90                 No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "odd_rows_raw = raw_data[cleaned_data['TotalCharges'].map(lambda x: x=='' or x==' ')]\n",
    "odd_rows = cleaned_data[cleaned_data['TotalCharges'].map(lambda x: x=='' or x==' ')]\n",
    "display(odd_rows_raw)    # To see unencoded, human readable data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea59392",
   "metadata": {},
   "source": [
    "## Fill the empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65ca0ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.55</td>\n",
       "      <td>1261.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.25</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80.85</td>\n",
       "      <td>1940.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.75</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.05</td>\n",
       "      <td>1345.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.85</td>\n",
       "      <td>476.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.35</td>\n",
       "      <td>608.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.70</td>\n",
       "      <td>236.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.35</td>\n",
       "      <td>1760.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.90</td>\n",
       "      <td>1485.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "488        0              0        1           1       0             0   \n",
       "753        1              0        0           1       0             1   \n",
       "936        0              0        1           1       0             1   \n",
       "1082       1              0        1           1       0             1   \n",
       "1340       0              0        1           1       0             0   \n",
       "3331       1              0        1           1       0             1   \n",
       "3826       1              0        1           1       0             1   \n",
       "4380       0              0        1           1       0             1   \n",
       "5218       1              0        1           1       0             1   \n",
       "6670       0              0        1           1       0             1   \n",
       "6754       1              0        0           1       0             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  \\\n",
       "488               0               1             0                 1   \n",
       "753               0               0             0                 0   \n",
       "936               0               1             1                 1   \n",
       "1082              1               0             0                 0   \n",
       "1340              0               1             1                 1   \n",
       "3331              0               0             0                 0   \n",
       "3826              1               0             0                 0   \n",
       "4380              0               0             0                 0   \n",
       "5218              0               0             0                 0   \n",
       "6670              1               0             1                 1   \n",
       "6754              1               1             1                 0   \n",
       "\n",
       "      TechSupport  StreamingTV  StreamingMovies  PaperlessBilling  \\\n",
       "488             1            1                0                 1   \n",
       "753             0            0                0                 0   \n",
       "936             0            1                1                 0   \n",
       "1082            0            0                0                 0   \n",
       "1340            1            1                0                 0   \n",
       "3331            0            0                0                 0   \n",
       "3826            0            0                0                 0   \n",
       "4380            0            0                0                 0   \n",
       "5218            0            0                0                 1   \n",
       "6670            1            1                0                 0   \n",
       "6754            1            0                0                 1   \n",
       "\n",
       "      MonthlyCharges TotalCharges  Churn  Contract_Month-to-month  \\\n",
       "488            52.55       1261.2      0                        0   \n",
       "753            20.25        486.0      0                        0   \n",
       "936            80.85       1940.4      0                        0   \n",
       "1082           25.75        618.0      0                        0   \n",
       "1340           56.05       1345.2      0                        0   \n",
       "3331           19.85        476.4      0                        0   \n",
       "3826           25.35        608.4      0                        0   \n",
       "4380           20.00        480.0      0                        0   \n",
       "5218           19.70        236.4      0                        0   \n",
       "6670           73.35       1760.4      0                        0   \n",
       "6754           61.90       1485.6      0                        0   \n",
       "\n",
       "      Contract_One year  Contract_Two year  \\\n",
       "488                   0                  1   \n",
       "753                   0                  1   \n",
       "936                   0                  1   \n",
       "1082                  0                  1   \n",
       "1340                  0                  1   \n",
       "3331                  0                  1   \n",
       "3826                  0                  1   \n",
       "4380                  0                  1   \n",
       "5218                  1                  0   \n",
       "6670                  0                  1   \n",
       "6754                  0                  1   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "488                                         1   \n",
       "753                                         0   \n",
       "936                                         0   \n",
       "1082                                        0   \n",
       "1340                                        0   \n",
       "3331                                        0   \n",
       "3826                                        0   \n",
       "4380                                        0   \n",
       "5218                                        0   \n",
       "6670                                        0   \n",
       "6754                                        1   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "488                                       0                               0   \n",
       "753                                       0                               0   \n",
       "936                                       0                               0   \n",
       "1082                                      0                               0   \n",
       "1340                                      1                               0   \n",
       "3331                                      0                               0   \n",
       "3826                                      0                               0   \n",
       "4380                                      0                               0   \n",
       "5218                                      0                               0   \n",
       "6670                                      0                               0   \n",
       "6754                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  InternetService_DSL  \\\n",
       "488                            0                    1   \n",
       "753                            1                    0   \n",
       "936                            1                    1   \n",
       "1082                           1                    0   \n",
       "1340                           0                    1   \n",
       "3331                           1                    0   \n",
       "3826                           1                    0   \n",
       "4380                           1                    0   \n",
       "5218                           1                    0   \n",
       "6670                           1                    1   \n",
       "6754                           0                    1   \n",
       "\n",
       "      InternetService_Fiber optic  InternetService_No  \n",
       "488                             0                   0  \n",
       "753                             0                   1  \n",
       "936                             0                   0  \n",
       "1082                            0                   1  \n",
       "1340                            0                   0  \n",
       "3331                            0                   1  \n",
       "3826                            0                   1  \n",
       "4380                            0                   1  \n",
       "5218                            0                   1  \n",
       "6670                            0                   0  \n",
       "6754                            0                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# None of them actually churned, so value replacement is easy\n",
    "odd_rows.loc[odd_rows['Contract_One year'] == 1, 'TotalCharges'] = odd_rows[odd_rows['Contract_One year'] == 1]['MonthlyCharges'] * 12\n",
    "odd_rows.loc[odd_rows['Contract_Two year'] == 1, 'TotalCharges'] = odd_rows[odd_rows['Contract_Two year'] == 1]['MonthlyCharges'] * 24\n",
    "display(odd_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09d189c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261.1999999999998"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.update(odd_rows)\n",
    "cleaned_data.iloc[488]['TotalCharges']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7330427",
   "metadata": {},
   "source": [
    "## Looks good, now convert all strs to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af6fd4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: [0. 1.]\n",
      "SeniorCitizen: [0. 1.]\n",
      "Partner: [1. 0.]\n",
      "Dependents: [0. 1.]\n",
      "tenure: [ 1. 34.  2. 45.  8. 22. 10. 28. 62. 13. 16. 58. 49. 25. 69. 52. 71. 21.\n",
      " 12. 30. 47. 72. 17. 27.  5. 46. 11. 70. 63. 43. 15. 60. 18. 66.  9.  3.\n",
      " 31. 50. 64. 56.  7. 42. 35. 48. 29. 65. 38. 68. 32. 55. 37. 36. 41.  6.\n",
      "  4. 33. 67. 23. 57. 61. 14. 20. 53. 40. 59. 24. 44. 19. 54. 51. 26.  0.\n",
      " 39.]\n",
      "PhoneService: [0. 1.]\n",
      "MultipleLines: [0. 1.]\n",
      "OnlineSecurity: [0. 1.]\n",
      "OnlineBackup: [1. 0.]\n",
      "DeviceProtection: [0. 1.]\n",
      "TechSupport: [0. 1.]\n",
      "StreamingTV: [0. 1.]\n",
      "StreamingMovies: [0. 1.]\n",
      "PaperlessBilling: [1. 0.]\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: [0. 1.]\n",
      "Contract_Month-to-month: [1. 0.]\n",
      "Contract_One year: [0. 1.]\n",
      "Contract_Two year: [0. 1.]\n",
      "PaymentMethod_Bank transfer (automatic): [0. 1.]\n",
      "PaymentMethod_Credit card (automatic): [0. 1.]\n",
      "PaymentMethod_Electronic check: [1. 0.]\n",
      "PaymentMethod_Mailed check: [0. 1.]\n",
      "InternetService_DSL: [1. 0.]\n",
      "InternetService_Fiber optic: [0. 1.]\n",
      "InternetService_No: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print_unique(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022fa71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: [0 1]\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: [1 0]\n",
      "Dependents: [0 1]\n",
      "tenure: [ 1. 34.  2. 45.  8. 22. 10. 28. 62. 13. 16. 58. 49. 25. 69. 52. 71. 21.\n",
      " 12. 30. 47. 72. 17. 27.  5. 46. 11. 70. 63. 43. 15. 60. 18. 66.  9.  3.\n",
      " 31. 50. 64. 56.  7. 42. 35. 48. 29. 65. 38. 68. 32. 55. 37. 36. 41.  6.\n",
      "  4. 33. 67. 23. 57. 61. 14. 20. 53. 40. 59. 24. 44. 19. 54. 51. 26.  0.\n",
      " 39.]\n",
      "PhoneService: [0 1]\n",
      "MultipleLines: [0 1]\n",
      "OnlineSecurity: [0 1]\n",
      "OnlineBackup: [1 0]\n",
      "DeviceProtection: [0 1]\n",
      "TechSupport: [0 1]\n",
      "StreamingTV: [0 1]\n",
      "StreamingMovies: [0 1]\n",
      "PaperlessBilling: [1 0]\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: [0 1]\n",
      "Contract_Month-to-month: [1 0]\n",
      "Contract_One year: [0 1]\n",
      "Contract_Two year: [0 1]\n",
      "PaymentMethod_Bank transfer (automatic): [0 1]\n",
      "PaymentMethod_Credit card (automatic): [0 1]\n",
      "PaymentMethod_Electronic check: [1 0]\n",
      "PaymentMethod_Mailed check: [0 1]\n",
      "InternetService_DSL: [1 0]\n",
      "InternetService_Fiber optic: [0 1]\n",
      "InternetService_No: [0 1]\n"
     ]
    }
   ],
   "source": [
    "diff_df = cleaned_data.loc[:, cleaned_data.columns.difference(['MonthlyCharges', 'TotalCharges', 'tenure'])]\n",
    "\n",
    "for col in diff_df:\n",
    "    cleaned_data[col] = cleaned_data[col].astype('int')\n",
    "print_unique(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1debd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalCharges dtype before object\n",
      "TotalCharges dtype after float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"TotalCharges dtype before {cleaned_data['TotalCharges'].dtype}\")\n",
    "cleaned_data['TotalCharges'] = pd.to_numeric(cleaned_data['TotalCharges'])\n",
    "print(f\"TotalCharges dtype after {cleaned_data['TotalCharges'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ef66296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: [0 1]\n",
      "SeniorCitizen: [0 1]\n",
      "Partner: [1 0]\n",
      "Dependents: [0 1]\n",
      "tenure: [ 1. 34.  2. 45.  8. 22. 10. 28. 62. 13. 16. 58. 49. 25. 69. 52. 71. 21.\n",
      " 12. 30. 47. 72. 17. 27.  5. 46. 11. 70. 63. 43. 15. 60. 18. 66.  9.  3.\n",
      " 31. 50. 64. 56.  7. 42. 35. 48. 29. 65. 38. 68. 32. 55. 37. 36. 41.  6.\n",
      "  4. 33. 67. 23. 57. 61. 14. 20. 53. 40. 59. 24. 44. 19. 54. 51. 26.  0.\n",
      " 39.]\n",
      "PhoneService: [0 1]\n",
      "MultipleLines: [0 1]\n",
      "OnlineSecurity: [0 1]\n",
      "OnlineBackup: [1 0]\n",
      "DeviceProtection: [0 1]\n",
      "TechSupport: [0 1]\n",
      "StreamingTV: [0 1]\n",
      "StreamingMovies: [0 1]\n",
      "PaperlessBilling: [1 0]\n",
      "MonthlyCharges: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "TotalCharges: [  29.85 1889.5   108.15 ...  346.45  306.6  6844.5 ]\n",
      "Churn: [0 1]\n",
      "Contract_Month-to-month: [1 0]\n",
      "Contract_One year: [0 1]\n",
      "Contract_Two year: [0 1]\n",
      "PaymentMethod_Bank transfer (automatic): [0 1]\n",
      "PaymentMethod_Credit card (automatic): [0 1]\n",
      "PaymentMethod_Electronic check: [1 0]\n",
      "PaymentMethod_Mailed check: [0 1]\n",
      "InternetService_DSL: [1 0]\n",
      "InternetService_Fiber optic: [0 1]\n",
      "InternetService_No: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print_unique(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b88796",
   "metadata": {},
   "source": [
    "## Training/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34851f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0          0              0        1           0     1.0             0   \n",
       "1          1              0        0           0    34.0             1   \n",
       "2          1              0        0           0     2.0             1   \n",
       "3          1              0        0           0    45.0             0   \n",
       "4          0              0        0           0     2.0             1   \n",
       "...      ...            ...      ...         ...     ...           ...   \n",
       "7038       1              0        1           1    24.0             1   \n",
       "7039       0              0        1           1    72.0             1   \n",
       "7040       0              0        1           1    11.0             0   \n",
       "7041       1              1        1           0     4.0             1   \n",
       "7042       1              0        0           0    66.0             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  \\\n",
       "0                 0               0             1                 0   \n",
       "1                 0               1             0                 1   \n",
       "2                 0               1             1                 0   \n",
       "3                 0               1             0                 1   \n",
       "4                 0               0             0                 0   \n",
       "...             ...             ...           ...               ...   \n",
       "7038              1               1             0                 1   \n",
       "7039              1               0             1                 1   \n",
       "7040              0               1             0                 0   \n",
       "7041              1               0             0                 0   \n",
       "7042              0               1             0                 1   \n",
       "\n",
       "      TechSupport  StreamingTV  StreamingMovies  PaperlessBilling  \\\n",
       "0               0            0                0                 1   \n",
       "1               0            0                0                 0   \n",
       "2               0            0                0                 1   \n",
       "3               1            0                0                 0   \n",
       "4               0            0                0                 1   \n",
       "...           ...          ...              ...               ...   \n",
       "7038            1            1                1                 1   \n",
       "7039            0            1                1                 1   \n",
       "7040            0            0                0                 1   \n",
       "7041            0            0                0                 1   \n",
       "7042            1            1                1                 1   \n",
       "\n",
       "      MonthlyCharges  TotalCharges  Contract_Month-to-month  \\\n",
       "0              29.85         29.85                        1   \n",
       "1              56.95       1889.50                        0   \n",
       "2              53.85        108.15                        1   \n",
       "3              42.30       1840.75                        0   \n",
       "4              70.70        151.65                        1   \n",
       "...              ...           ...                      ...   \n",
       "7038           84.80       1990.50                        0   \n",
       "7039          103.20       7362.90                        0   \n",
       "7040           29.60        346.45                        1   \n",
       "7041           74.40        306.60                        1   \n",
       "7042          105.65       6844.50                        0   \n",
       "\n",
       "      Contract_One year  Contract_Two year  \\\n",
       "0                     0                  0   \n",
       "1                     1                  0   \n",
       "2                     0                  0   \n",
       "3                     1                  0   \n",
       "4                     0                  0   \n",
       "...                 ...                ...   \n",
       "7038                  1                  0   \n",
       "7039                  1                  0   \n",
       "7040                  0                  0   \n",
       "7041                  0                  0   \n",
       "7042                  0                  1   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           1   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "7038                                        0   \n",
       "7039                                        0   \n",
       "7040                                        0   \n",
       "7041                                        0   \n",
       "7042                                        1   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                         0                               1   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               1   \n",
       "...                                     ...                             ...   \n",
       "7038                                      0                               0   \n",
       "7039                                      1                               0   \n",
       "7040                                      0                               1   \n",
       "7041                                      0                               0   \n",
       "7042                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  InternetService_DSL  \\\n",
       "0                              0                    1   \n",
       "1                              1                    1   \n",
       "2                              1                    1   \n",
       "3                              0                    1   \n",
       "4                              0                    0   \n",
       "...                          ...                  ...   \n",
       "7038                           1                    1   \n",
       "7039                           0                    0   \n",
       "7040                           0                    1   \n",
       "7041                           1                    0   \n",
       "7042                           0                    0   \n",
       "\n",
       "      InternetService_Fiber optic  InternetService_No  \n",
       "0                               0                   0  \n",
       "1                               0                   0  \n",
       "2                               0                   0  \n",
       "3                               0                   0  \n",
       "4                               1                   0  \n",
       "...                           ...                 ...  \n",
       "7038                            0                   0  \n",
       "7039                            1                   0  \n",
       "7040                            0                   0  \n",
       "7041                            1                   0  \n",
       "7042                            1                   0  \n",
       "\n",
       "[7043 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "7038    0\n",
       "7039    0\n",
       "7040    0\n",
       "7041    1\n",
       "7042    0\n",
       "Name: Churn, Length: 7043, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,y = cleaned_data.loc[:, cleaned_data.columns != 'Churn'], cleaned_data['Churn']\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac01fca",
   "metadata": {},
   "source": [
    "# Note\n",
    "It's important to split the data before applying normalization techniques because we want to keep out test/validation set data completely separate from our training information to avoid introducing future information into our model. `sklearn`'s scalers, like `MinMaxScaler` for example, scale in two distinct steps. First, `fit()` which computes nessecary parameters like `scaler.min_` and `scaler.data_max_`. Then, `transform()` which actually transforms the passed data. So, we'll `fit(X_train)` then `transform()` both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594dcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af5960",
   "metadata": {},
   "source": [
    "## Normalization via scaling between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5567454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b375a914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069756</td>\n",
       "      <td>0.112814</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.116882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578974</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321873</td>\n",
       "      <td>0.374025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498754</td>\n",
       "      <td>0.503116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914798</td>\n",
       "      <td>0.654004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>0.035882</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256104</td>\n",
       "      <td>0.339407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130543</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1409 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
       "185        0              0        1           0  0.013889             0   \n",
       "2715       1              0        0           0  0.569444             1   \n",
       "3825       0              0        1           1  0.722222             1   \n",
       "1807       0              0        0           0  0.013889             1   \n",
       "132        1              0        0           0  0.930556             1   \n",
       "...      ...            ...      ...         ...       ...           ...   \n",
       "6366       0              0        1           0  0.888889             1   \n",
       "315        1              0        1           1  0.708333             1   \n",
       "2439       1              0        1           1  0.236111             1   \n",
       "5002       0              0        1           1  0.958333             0   \n",
       "1161       1              0        0           1  0.013889             0   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  \\\n",
       "185               0               0             0                 0   \n",
       "2715              1               0             0                 0   \n",
       "3825              0               0             0                 0   \n",
       "1807              0               0             0                 1   \n",
       "132               0               0             0                 0   \n",
       "...             ...             ...           ...               ...   \n",
       "6366              0               0             1                 1   \n",
       "315               1               1             1                 0   \n",
       "2439              0               0             0                 0   \n",
       "5002              0               1             0                 1   \n",
       "1161              0               0             1                 0   \n",
       "\n",
       "      TechSupport  StreamingTV  StreamingMovies  PaperlessBilling  \\\n",
       "185             0            0                0                 1   \n",
       "2715            0            0                0                 1   \n",
       "3825            0            0                0                 0   \n",
       "1807            0            0                0                 0   \n",
       "132             1            0                0                 0   \n",
       "...           ...          ...              ...               ...   \n",
       "6366            1            0                1                 1   \n",
       "315             1            1                1                 0   \n",
       "2439            0            0                0                 0   \n",
       "5002            0            0                1                 1   \n",
       "1161            0            0                0                 1   \n",
       "\n",
       "      MonthlyCharges  TotalCharges  Contract_Month-to-month  \\\n",
       "185         0.065272      0.000692                        1   \n",
       "2715        0.069756      0.112814                        1   \n",
       "3825        0.010962      0.116882                        0   \n",
       "1807        0.578974      0.006641                        1   \n",
       "132         0.321873      0.374025                        0   \n",
       "...              ...           ...                      ...   \n",
       "6366        0.498754      0.503116                        0   \n",
       "315         0.914798      0.654004                        0   \n",
       "2439        0.016442      0.035882                        0   \n",
       "5002        0.256104      0.339407                        0   \n",
       "1161        0.130543      0.001448                        1   \n",
       "\n",
       "      Contract_One year  Contract_Two year  \\\n",
       "185                   0                  0   \n",
       "2715                  0                  0   \n",
       "3825                  0                  1   \n",
       "1807                  0                  0   \n",
       "132                   0                  1   \n",
       "...                 ...                ...   \n",
       "6366                  0                  1   \n",
       "315                   1                  0   \n",
       "2439                  1                  0   \n",
       "5002                  0                  1   \n",
       "1161                  0                  0   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "185                                         0   \n",
       "2715                                        1   \n",
       "3825                                        0   \n",
       "1807                                        0   \n",
       "132                                         1   \n",
       "...                                       ...   \n",
       "6366                                        0   \n",
       "315                                         0   \n",
       "2439                                        1   \n",
       "5002                                        0   \n",
       "1161                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "185                                       0                               1   \n",
       "2715                                      0                               0   \n",
       "3825                                      0                               0   \n",
       "1807                                      0                               1   \n",
       "132                                       0                               0   \n",
       "...                                     ...                             ...   \n",
       "6366                                      0                               0   \n",
       "315                                       1                               0   \n",
       "2439                                      0                               0   \n",
       "5002                                      1                               0   \n",
       "1161                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  InternetService_DSL  \\\n",
       "185                            0                    1   \n",
       "2715                           0                    0   \n",
       "3825                           1                    0   \n",
       "1807                           0                    0   \n",
       "132                            0                    1   \n",
       "...                          ...                  ...   \n",
       "6366                           1                    1   \n",
       "315                            0                    0   \n",
       "2439                           0                    0   \n",
       "5002                           0                    1   \n",
       "1161                           1                    1   \n",
       "\n",
       "      InternetService_Fiber optic  InternetService_No  \n",
       "185                             0                   0  \n",
       "2715                            0                   1  \n",
       "3825                            0                   1  \n",
       "1807                            1                   0  \n",
       "132                             0                   0  \n",
       "...                           ...                 ...  \n",
       "6366                            0                   0  \n",
       "315                             1                   0  \n",
       "2439                            0                   1  \n",
       "5002                            0                   0  \n",
       "1161                            0                   0  \n",
       "\n",
       "[1409 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scale_cols = ['tenure', 'TotalCharges', 'MonthlyCharges']\n",
    "min_max_scaler.fit(X_train[scale_cols])\n",
    "X_train_scaled, X_test_scaled = X_train.copy(), X_test.copy()\n",
    "X_train_scaled[scale_cols] = min_max_scaler.transform(X_train[scale_cols])\n",
    "X_test_scaled[scale_cols] = min_max_scaler.transform(X_test[scale_cols])\n",
    "display(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd9749",
   "metadata": {},
   "source": [
    "# Tensor Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdac4cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([26]),\n",
       " (tensor([0.0000, 0.0000, 0.0000, 1.0000, 0.2917, 1.0000, 0.0000, 1.0000, 0.0000,\n",
       "          1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.4644, 0.1521, 0.0000, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000],\n",
       "         requires_grad=True),\n",
       "  tensor(0., requires_grad=True)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = [(torch.tensor(X_data, dtype=torch.float, requires_grad=True), torch.tensor(y_data, dtype=torch.float, requires_grad=True)) for X_data, y_data in zip(X_train_scaled.values, y_train.values)]\n",
    "train_ds[0][0].shape, train_ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c303667c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([26]),\n",
       " (tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.3889e-02, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00, 6.5272e-02, 6.9236e-04, 1.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00], requires_grad=True),\n",
       "  tensor(1., requires_grad=True)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds = [(torch.tensor(X_data, dtype=torch.float, requires_grad=True), torch.tensor(y_data, dtype=torch.float, requires_grad=True)) for X_data, y_data in zip(X_test_scaled.values, y_test.values)]\n",
    "validation_ds[0][0].shape, validation_ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d440f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=len(train_ds) // 10, shuffle=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(validation_ds, batch_size=len(validation_ds) // 10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239f1d8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3283f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neuron_count = len(X.columns)\n",
    "loss_fcn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ed6dc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_neuron_count, input_neuron_count // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(input_neuron_count // 2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2200ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dba48994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_t_info(ts: list[torch.tensor], msg: list[str]=None) -> None:\n",
    "    \"Print all relevant tensor info in a pretty interface\"\n",
    "    if isinstance(ts, torch.Tensor): ts = [ts]\n",
    "    if isinstance(msg, str): msg = [msg]\n",
    "    if not isinstance(ts, list): raise TypeError(f\"Expected tensor or list of tensors got {type(ts)}\")\n",
    "    if not isinstance(msg, list): raise TypeError(f\"Expected str or list of strs, go {type(msg)}\")\n",
    "    for count, tensor in enumerate(ts):\n",
    "        if msg:\n",
    "            try: print(f\"{msg[count]}\", end='')\n",
    "            except IndexError:\n",
    "                print(f\"{msg[-1]}\", end='')\n",
    "            print(f\"\\tShape: {tensor.shape}\\tdtype: {tensor.dtype}\\tContiguous: {tensor.is_contiguous()}\")\n",
    "        else:\n",
    "            print(f\"Tensor #{count:02}\\tShape: {tensor.shape}\\tdtype: {tensor.dtype}\\tContiguous: {tensor.is_contiguous()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbfac02",
   "metadata": {},
   "source": [
    "# Custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "61197d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fcn, optimizer, train_dataloader, val_dataloader,\n",
    "                  *, save_best=True, metrics=True, logging=True):\n",
    "    \"\"\"\n",
    "    Custom training loop\n",
    "    Parameters:\n",
    "        epochs: int, number of epochs to train for\n",
    "        model: nn.Module or subclass thereof, from which to obtain predictions\n",
    "        loss_fcn: any pytorch loss function\n",
    "        optimizer: any optimizer\n",
    "        train_dataloader: PyTorch dataloader from which to pull data\n",
    "        val_dataloader: \"\n",
    "        save_best: bool, WARNING only use on smaller models, cache and serialize best model at end of training\n",
    "        metrics: bool, control calculation and printing of numbers to the screen\n",
    "        logging: bool, control printing of tensor info to screen after each step\n",
    "    Returns: \n",
    "        Trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    highest_accuracy = 0\n",
    "    cached_model = None\n",
    "    for epoch in range(epochs):\n",
    "        for features, labels in train_dataloader:\n",
    "            labels.unsqueeze_(1)\n",
    "            if logging: print_t_info([features, labels], [\"Train Feats: \", \"Train Labels: \"])\n",
    "            \n",
    "            train_predictions = model(features)\n",
    "            \n",
    "            train_loss = loss_fcn(train_predictions, labels)\n",
    "            \n",
    "            if logging: print_t_info([train_predictions, train_loss], [\"Train Preds:\", \"Train Loss:\"])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for features, labels in val_dataloader:\n",
    "            labels.unsqueeze_(1)\n",
    "            if logging: print_t_info([features, labels], ['Val Feats: ', 'Val Labels:'])\n",
    "            \n",
    "            val_predictions = model(features)\n",
    "            \n",
    "            val_loss = loss_fcn(val_predictions, labels)\n",
    "            \n",
    "            if logging: print_t_info([val_predictions, val_loss], ['Val Preds:', 'Val Loss:'])\n",
    "            \n",
    "            break\n",
    "            \n",
    "        if metrics:\n",
    "            total += val_predictions.shape[0]\n",
    "            correct = int(((val_predictions > 0.5) == labels.type(torch.BoolTensor)).sum())\n",
    "            print(f\"Epoch {epoch:03}\\tTrain Loss: {train_loss:.4}\\tVal Loss: {val_loss:.4}\\tAccuracy: {correct/total:%}\")\n",
    "        if save_best:\n",
    "            latest_accuracy = correct/total\n",
    "            if latest_accuracy > highest_accuracy:\n",
    "                highest_accuracy = latest_accuracy\n",
    "                cached_model = model\n",
    "                \n",
    "    model_pth = Path(f'./models/{highest_accuracy * 100:.5}_model')\n",
    "    torch.save(cached_model, model_pth)\n",
    "    print(f\"Model saved to {model_pth}\")\n",
    "        \n",
    "    return model \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c5d0a61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000\tTrain Loss: 0.63\tVal Loss: 0.6318\tAccuracy: 69.285714%\n",
      "Epoch 001\tTrain Loss: 0.5742\tVal Loss: 0.6058\tAccuracy: 69.285714%\n",
      "Epoch 002\tTrain Loss: 0.5367\tVal Loss: 0.5905\tAccuracy: 69.285714%\n",
      "Epoch 003\tTrain Loss: 0.4973\tVal Loss: 0.5728\tAccuracy: 69.285714%\n",
      "Epoch 004\tTrain Loss: 0.4536\tVal Loss: 0.5521\tAccuracy: 69.285714%\n",
      "Epoch 005\tTrain Loss: 0.4061\tVal Loss: 0.5303\tAccuracy: 69.285714%\n",
      "Epoch 006\tTrain Loss: 0.3631\tVal Loss: 0.5111\tAccuracy: 69.285714%\n",
      "Epoch 007\tTrain Loss: 0.3289\tVal Loss: 0.4961\tAccuracy: 69.285714%\n",
      "Epoch 008\tTrain Loss: 0.3028\tVal Loss: 0.4807\tAccuracy: 69.285714%\n",
      "Epoch 009\tTrain Loss: 0.2774\tVal Loss: 0.466\tAccuracy: 69.285714%\n",
      "Epoch 010\tTrain Loss: 0.2515\tVal Loss: 0.4531\tAccuracy: 69.285714%\n",
      "Epoch 011\tTrain Loss: 0.2279\tVal Loss: 0.4421\tAccuracy: 69.285714%\n",
      "Epoch 012\tTrain Loss: 0.2071\tVal Loss: 0.4333\tAccuracy: 70.000000%\n",
      "Epoch 013\tTrain Loss: 0.1896\tVal Loss: 0.4258\tAccuracy: 72.142857%\n",
      "Epoch 014\tTrain Loss: 0.1745\tVal Loss: 0.4198\tAccuracy: 71.428571%\n",
      "Epoch 015\tTrain Loss: 0.1614\tVal Loss: 0.4152\tAccuracy: 71.428571%\n",
      "Epoch 016\tTrain Loss: 0.1504\tVal Loss: 0.4115\tAccuracy: 72.142857%\n",
      "Epoch 017\tTrain Loss: 0.1409\tVal Loss: 0.4086\tAccuracy: 71.428571%\n",
      "Epoch 018\tTrain Loss: 0.1333\tVal Loss: 0.4062\tAccuracy: 72.142857%\n",
      "Epoch 019\tTrain Loss: 0.1269\tVal Loss: 0.4042\tAccuracy: 72.142857%\n",
      "Epoch 020\tTrain Loss: 0.1214\tVal Loss: 0.4025\tAccuracy: 72.857143%\n",
      "Epoch 021\tTrain Loss: 0.1167\tVal Loss: 0.4012\tAccuracy: 72.857143%\n",
      "Epoch 022\tTrain Loss: 0.1137\tVal Loss: 0.397\tAccuracy: 73.571429%\n",
      "Epoch 023\tTrain Loss: 0.1103\tVal Loss: 0.3971\tAccuracy: 73.571429%\n",
      "Epoch 024\tTrain Loss: 0.1091\tVal Loss: 0.3956\tAccuracy: 73.571429%\n",
      "Epoch 025\tTrain Loss: 0.1067\tVal Loss: 0.3937\tAccuracy: 76.428571%\n",
      "Epoch 026\tTrain Loss: 0.1046\tVal Loss: 0.3928\tAccuracy: 76.428571%\n",
      "Epoch 027\tTrain Loss: 0.1028\tVal Loss: 0.392\tAccuracy: 76.428571%\n",
      "Epoch 028\tTrain Loss: 0.1014\tVal Loss: 0.3913\tAccuracy: 76.428571%\n",
      "Epoch 029\tTrain Loss: 0.1001\tVal Loss: 0.3907\tAccuracy: 76.428571%\n",
      "Epoch 030\tTrain Loss: 0.09914\tVal Loss: 0.3912\tAccuracy: 76.428571%\n",
      "Epoch 031\tTrain Loss: 0.09858\tVal Loss: 0.3899\tAccuracy: 76.428571%\n",
      "Epoch 032\tTrain Loss: 0.09767\tVal Loss: 0.3893\tAccuracy: 76.428571%\n",
      "Epoch 033\tTrain Loss: 0.09691\tVal Loss: 0.3889\tAccuracy: 76.428571%\n",
      "Epoch 034\tTrain Loss: 0.09622\tVal Loss: 0.3885\tAccuracy: 75.714286%\n",
      "Epoch 035\tTrain Loss: 0.0956\tVal Loss: 0.3881\tAccuracy: 75.714286%\n",
      "Epoch 036\tTrain Loss: 0.09505\tVal Loss: 0.3878\tAccuracy: 75.714286%\n",
      "Epoch 037\tTrain Loss: 0.09459\tVal Loss: 0.3876\tAccuracy: 75.714286%\n",
      "Epoch 038\tTrain Loss: 0.09429\tVal Loss: 0.3885\tAccuracy: 75.000000%\n",
      "Epoch 039\tTrain Loss: 0.09427\tVal Loss: 0.3874\tAccuracy: 75.714286%\n",
      "Epoch 040\tTrain Loss: 0.09379\tVal Loss: 0.3871\tAccuracy: 76.428571%\n",
      "Epoch 041\tTrain Loss: 0.09338\tVal Loss: 0.3868\tAccuracy: 77.142857%\n",
      "Epoch 042\tTrain Loss: 0.09309\tVal Loss: 0.3866\tAccuracy: 77.857143%\n",
      "Epoch 043\tTrain Loss: 0.09276\tVal Loss: 0.3864\tAccuracy: 77.857143%\n",
      "Epoch 044\tTrain Loss: 0.09248\tVal Loss: 0.3863\tAccuracy: 77.857143%\n",
      "Epoch 045\tTrain Loss: 0.09219\tVal Loss: 0.386\tAccuracy: 78.571429%\n",
      "Epoch 046\tTrain Loss: 0.09195\tVal Loss: 0.3858\tAccuracy: 79.285714%\n",
      "Epoch 047\tTrain Loss: 0.09175\tVal Loss: 0.3857\tAccuracy: 79.285714%\n",
      "Epoch 048\tTrain Loss: 0.09147\tVal Loss: 0.3855\tAccuracy: 79.285714%\n",
      "Epoch 049\tTrain Loss: 0.09127\tVal Loss: 0.3853\tAccuracy: 79.285714%\n",
      "Epoch 050\tTrain Loss: 0.0911\tVal Loss: 0.3852\tAccuracy: 79.285714%\n",
      "Epoch 051\tTrain Loss: 0.09094\tVal Loss: 0.3861\tAccuracy: 77.142857%\n",
      "Epoch 052\tTrain Loss: 0.09121\tVal Loss: 0.3851\tAccuracy: 79.285714%\n",
      "Epoch 053\tTrain Loss: 0.09098\tVal Loss: 0.3849\tAccuracy: 79.285714%\n",
      "Epoch 054\tTrain Loss: 0.09075\tVal Loss: 0.3846\tAccuracy: 79.285714%\n",
      "Epoch 055\tTrain Loss: 0.09056\tVal Loss: 0.3844\tAccuracy: 79.285714%\n",
      "Epoch 056\tTrain Loss: 0.09039\tVal Loss: 0.3843\tAccuracy: 79.285714%\n",
      "Epoch 057\tTrain Loss: 0.0902\tVal Loss: 0.384\tAccuracy: 79.285714%\n",
      "Epoch 058\tTrain Loss: 0.0901\tVal Loss: 0.384\tAccuracy: 79.285714%\n",
      "Epoch 059\tTrain Loss: 0.08993\tVal Loss: 0.3837\tAccuracy: 79.285714%\n",
      "Epoch 060\tTrain Loss: 0.08982\tVal Loss: 0.3837\tAccuracy: 79.285714%\n",
      "Epoch 061\tTrain Loss: 0.0897\tVal Loss: 0.3834\tAccuracy: 79.285714%\n",
      "Epoch 062\tTrain Loss: 0.08958\tVal Loss: 0.3834\tAccuracy: 79.285714%\n",
      "Epoch 063\tTrain Loss: 0.08951\tVal Loss: 0.3832\tAccuracy: 79.285714%\n",
      "Epoch 064\tTrain Loss: 0.08936\tVal Loss: 0.3831\tAccuracy: 79.285714%\n",
      "Epoch 065\tTrain Loss: 0.08929\tVal Loss: 0.3831\tAccuracy: 79.285714%\n",
      "Epoch 066\tTrain Loss: 0.08924\tVal Loss: 0.3829\tAccuracy: 80.000000%\n",
      "Epoch 067\tTrain Loss: 0.08916\tVal Loss: 0.3828\tAccuracy: 80.000000%\n",
      "Epoch 068\tTrain Loss: 0.08909\tVal Loss: 0.3827\tAccuracy: 80.000000%\n",
      "Epoch 069\tTrain Loss: 0.08901\tVal Loss: 0.3827\tAccuracy: 80.000000%\n",
      "Epoch 070\tTrain Loss: 0.08903\tVal Loss: 0.3826\tAccuracy: 80.000000%\n",
      "Epoch 071\tTrain Loss: 0.08891\tVal Loss: 0.3825\tAccuracy: 80.000000%\n",
      "Epoch 072\tTrain Loss: 0.08885\tVal Loss: 0.3824\tAccuracy: 80.000000%\n",
      "Epoch 073\tTrain Loss: 0.08876\tVal Loss: 0.3823\tAccuracy: 80.000000%\n",
      "Epoch 074\tTrain Loss: 0.08871\tVal Loss: 0.3824\tAccuracy: 80.000000%\n",
      "Epoch 075\tTrain Loss: 0.0887\tVal Loss: 0.3822\tAccuracy: 80.000000%\n",
      "Epoch 076\tTrain Loss: 0.08861\tVal Loss: 0.3821\tAccuracy: 80.000000%\n",
      "Epoch 077\tTrain Loss: 0.08857\tVal Loss: 0.3821\tAccuracy: 80.000000%\n",
      "Epoch 078\tTrain Loss: 0.08848\tVal Loss: 0.382\tAccuracy: 80.000000%\n",
      "Epoch 079\tTrain Loss: 0.08843\tVal Loss: 0.3821\tAccuracy: 80.000000%\n",
      "Epoch 080\tTrain Loss: 0.08848\tVal Loss: 0.3819\tAccuracy: 80.000000%\n",
      "Epoch 081\tTrain Loss: 0.0884\tVal Loss: 0.3819\tAccuracy: 80.000000%\n",
      "Epoch 082\tTrain Loss: 0.08834\tVal Loss: 0.3818\tAccuracy: 80.000000%\n",
      "Epoch 083\tTrain Loss: 0.08825\tVal Loss: 0.3817\tAccuracy: 80.000000%\n",
      "Epoch 084\tTrain Loss: 0.08821\tVal Loss: 0.3818\tAccuracy: 80.000000%\n",
      "Epoch 085\tTrain Loss: 0.08823\tVal Loss: 0.3816\tAccuracy: 80.000000%\n",
      "Epoch 086\tTrain Loss: 0.08814\tVal Loss: 0.3816\tAccuracy: 80.000000%\n",
      "Epoch 087\tTrain Loss: 0.08808\tVal Loss: 0.3815\tAccuracy: 80.000000%\n",
      "Epoch 088\tTrain Loss: 0.08801\tVal Loss: 0.3815\tAccuracy: 80.000000%\n",
      "Epoch 089\tTrain Loss: 0.08794\tVal Loss: 0.3815\tAccuracy: 80.000000%\n",
      "Epoch 090\tTrain Loss: 0.08792\tVal Loss: 0.3816\tAccuracy: 80.000000%\n",
      "Epoch 091\tTrain Loss: 0.08792\tVal Loss: 0.3814\tAccuracy: 80.000000%\n",
      "Epoch 092\tTrain Loss: 0.08784\tVal Loss: 0.3814\tAccuracy: 80.000000%\n",
      "Epoch 093\tTrain Loss: 0.08781\tVal Loss: 0.3814\tAccuracy: 80.000000%\n",
      "Epoch 094\tTrain Loss: 0.08775\tVal Loss: 0.3814\tAccuracy: 80.000000%\n",
      "Epoch 095\tTrain Loss: 0.08768\tVal Loss: 0.3813\tAccuracy: 79.285714%\n",
      "Epoch 096\tTrain Loss: 0.08768\tVal Loss: 0.3814\tAccuracy: 79.285714%\n",
      "Epoch 097\tTrain Loss: 0.08769\tVal Loss: 0.3813\tAccuracy: 79.285714%\n",
      "Epoch 098\tTrain Loss: 0.08762\tVal Loss: 0.3812\tAccuracy: 79.285714%\n",
      "Epoch 099\tTrain Loss: 0.08756\tVal Loss: 0.3812\tAccuracy: 79.285714%\n",
      "Model saved to models/80.0_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=26, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(100, model, loss_fcn, optimizer, train_dataloader, val_dataloader, logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ff96c",
   "metadata": {},
   "source": [
    "# 80% Accuracy, not bad\n",
    "I noticed something strange about the number of samples available for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1be5a632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5174\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dab0c8",
   "metadata": {},
   "source": [
    "Class imbalance isn't unusual in datasets, so I want to try and balance these two out, using some for of data augmentation, here I'll be using Synthetic Minority Oversampling (SMOTE) from `imblearn.oversampling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "08647e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sampler = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7af7b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sampler.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "739210c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5174\n",
       "1    5174\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa6cad",
   "metadata": {},
   "source": [
    "## Much better :)\n",
    "Let's proceed to train our next model with oversampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef890d",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "db13ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X_res, y_res, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb656bcb",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "84dd86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bd8e23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_min_max_scaler.fit(X_train_res[scale_cols])\n",
    "X_train_scaled_res, X_test_scaled_res = X_train_res.copy(), X_test_res.copy()\n",
    "X_train_scaled_res[scale_cols] = res_min_max_scaler.transform(X_train_res[scale_cols])\n",
    "X_test_scaled_res[scale_cols] = res_min_max_scaler.transform(X_test_res[scale_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70d9ed",
   "metadata": {},
   "source": [
    "### Same tensor pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "483989c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([26]),\n",
       " (tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6632, 1.0000, 1.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.7523, 0.5185, 1.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
       "         requires_grad=True),\n",
       "  tensor(1., requires_grad=True)))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res_ds = [(torch.tensor(X_data, dtype=torch.float, requires_grad=True), torch.tensor(y_data, dtype=torch.float, requires_grad=True)) for X_data, y_data in zip(X_train_scaled_res.values, y_train_res.values)]\n",
    "train_res_ds[0][0].shape, train_res_ds[0]\n",
    "\n",
    "validation_res_ds = [(torch.tensor(X_data, dtype=torch.float, requires_grad=True), torch.tensor(y_data, dtype=torch.float, requires_grad=True)) for X_data, y_data in zip(X_test_scaled_res.values, y_test_res.values)]\n",
    "validation_res_ds[0][0].shape, validation_res_ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f0884195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_dataloader = torch.utils.data.DataLoader(train_res_ds, batch_size=len(train_res_ds) // 10, shuffle=False)\n",
    "val_res_dataloader = torch.utils.data.DataLoader(validation_res_ds, batch_size=len(validation_res_ds) // 10, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56cce8",
   "metadata": {},
   "source": [
    "## I'll use the exact same architecutre & hyper-parameters to ensure fair comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3baec039",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neuron_count = len(X_res.columns)\n",
    "loss_fcn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "aadee8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_neuron_count, input_neuron_count // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(input_neuron_count // 2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1dfb66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "26313ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000\tTrain Loss: 0.7094\tVal Loss: 0.6685\tAccuracy: 42.028986%\n",
      "Epoch 001\tTrain Loss: 0.6467\tVal Loss: 0.6501\tAccuracy: 42.028986%\n",
      "Epoch 002\tTrain Loss: 0.5938\tVal Loss: 0.6241\tAccuracy: 42.028986%\n",
      "Epoch 003\tTrain Loss: 0.5452\tVal Loss: 0.5892\tAccuracy: 42.028986%\n",
      "Epoch 004\tTrain Loss: 0.4966\tVal Loss: 0.549\tAccuracy: 55.555556%\n",
      "Epoch 005\tTrain Loss: 0.4496\tVal Loss: 0.5085\tAccuracy: 66.183575%\n",
      "Epoch 006\tTrain Loss: 0.4073\tVal Loss: 0.4731\tAccuracy: 73.913043%\n",
      "Epoch 007\tTrain Loss: 0.3711\tVal Loss: 0.4449\tAccuracy: 74.879227%\n",
      "Epoch 008\tTrain Loss: 0.3416\tVal Loss: 0.423\tAccuracy: 76.811594%\n",
      "Epoch 009\tTrain Loss: 0.3189\tVal Loss: 0.4076\tAccuracy: 77.777778%\n",
      "Epoch 010\tTrain Loss: 0.3012\tVal Loss: 0.396\tAccuracy: 77.294686%\n",
      "Epoch 011\tTrain Loss: 0.2872\tVal Loss: 0.3872\tAccuracy: 78.260870%\n",
      "Epoch 012\tTrain Loss: 0.2762\tVal Loss: 0.3803\tAccuracy: 78.260870%\n",
      "Epoch 013\tTrain Loss: 0.2675\tVal Loss: 0.3748\tAccuracy: 78.260870%\n",
      "Epoch 014\tTrain Loss: 0.2605\tVal Loss: 0.3702\tAccuracy: 79.227053%\n",
      "Epoch 015\tTrain Loss: 0.2549\tVal Loss: 0.3661\tAccuracy: 79.227053%\n",
      "Epoch 016\tTrain Loss: 0.2501\tVal Loss: 0.3631\tAccuracy: 80.193237%\n",
      "Epoch 017\tTrain Loss: 0.2457\tVal Loss: 0.3601\tAccuracy: 80.676329%\n",
      "Epoch 018\tTrain Loss: 0.2421\tVal Loss: 0.357\tAccuracy: 80.676329%\n",
      "Epoch 019\tTrain Loss: 0.239\tVal Loss: 0.3548\tAccuracy: 81.159420%\n",
      "Epoch 020\tTrain Loss: 0.2365\tVal Loss: 0.3525\tAccuracy: 82.125604%\n",
      "Epoch 021\tTrain Loss: 0.2344\tVal Loss: 0.3503\tAccuracy: 82.608696%\n",
      "Epoch 022\tTrain Loss: 0.2325\tVal Loss: 0.3483\tAccuracy: 82.608696%\n",
      "Epoch 023\tTrain Loss: 0.231\tVal Loss: 0.3463\tAccuracy: 82.608696%\n",
      "Epoch 024\tTrain Loss: 0.2296\tVal Loss: 0.3443\tAccuracy: 82.608696%\n",
      "Epoch 025\tTrain Loss: 0.2285\tVal Loss: 0.3428\tAccuracy: 82.608696%\n",
      "Epoch 026\tTrain Loss: 0.2274\tVal Loss: 0.3413\tAccuracy: 82.608696%\n",
      "Epoch 027\tTrain Loss: 0.2263\tVal Loss: 0.3398\tAccuracy: 83.091787%\n",
      "Epoch 028\tTrain Loss: 0.2253\tVal Loss: 0.3383\tAccuracy: 83.574879%\n",
      "Epoch 029\tTrain Loss: 0.2244\tVal Loss: 0.337\tAccuracy: 84.057971%\n",
      "Epoch 030\tTrain Loss: 0.2235\tVal Loss: 0.3357\tAccuracy: 84.057971%\n",
      "Epoch 031\tTrain Loss: 0.2226\tVal Loss: 0.3344\tAccuracy: 84.057971%\n",
      "Epoch 032\tTrain Loss: 0.2218\tVal Loss: 0.333\tAccuracy: 84.057971%\n",
      "Epoch 033\tTrain Loss: 0.2211\tVal Loss: 0.3321\tAccuracy: 84.057971%\n",
      "Epoch 034\tTrain Loss: 0.2203\tVal Loss: 0.3311\tAccuracy: 84.541063%\n",
      "Epoch 035\tTrain Loss: 0.2195\tVal Loss: 0.33\tAccuracy: 85.024155%\n",
      "Epoch 036\tTrain Loss: 0.2187\tVal Loss: 0.329\tAccuracy: 85.024155%\n",
      "Epoch 037\tTrain Loss: 0.218\tVal Loss: 0.3281\tAccuracy: 85.024155%\n",
      "Epoch 038\tTrain Loss: 0.2172\tVal Loss: 0.3272\tAccuracy: 85.024155%\n",
      "Epoch 039\tTrain Loss: 0.2164\tVal Loss: 0.3263\tAccuracy: 85.024155%\n",
      "Epoch 040\tTrain Loss: 0.2157\tVal Loss: 0.3254\tAccuracy: 85.024155%\n",
      "Epoch 041\tTrain Loss: 0.2149\tVal Loss: 0.3246\tAccuracy: 85.024155%\n",
      "Epoch 042\tTrain Loss: 0.2142\tVal Loss: 0.3237\tAccuracy: 85.507246%\n",
      "Epoch 043\tTrain Loss: 0.2135\tVal Loss: 0.3229\tAccuracy: 85.507246%\n",
      "Epoch 044\tTrain Loss: 0.2127\tVal Loss: 0.3221\tAccuracy: 85.507246%\n",
      "Epoch 045\tTrain Loss: 0.212\tVal Loss: 0.3214\tAccuracy: 85.507246%\n",
      "Epoch 046\tTrain Loss: 0.2113\tVal Loss: 0.3206\tAccuracy: 85.990338%\n",
      "Epoch 047\tTrain Loss: 0.2106\tVal Loss: 0.3199\tAccuracy: 86.473430%\n",
      "Epoch 048\tTrain Loss: 0.21\tVal Loss: 0.3192\tAccuracy: 86.956522%\n",
      "Epoch 049\tTrain Loss: 0.2093\tVal Loss: 0.3185\tAccuracy: 86.956522%\n",
      "Epoch 050\tTrain Loss: 0.2086\tVal Loss: 0.3179\tAccuracy: 86.956522%\n",
      "Epoch 051\tTrain Loss: 0.2079\tVal Loss: 0.3172\tAccuracy: 86.956522%\n",
      "Epoch 052\tTrain Loss: 0.2073\tVal Loss: 0.3168\tAccuracy: 86.956522%\n",
      "Epoch 053\tTrain Loss: 0.2066\tVal Loss: 0.3162\tAccuracy: 86.956522%\n",
      "Epoch 054\tTrain Loss: 0.2059\tVal Loss: 0.3156\tAccuracy: 86.956522%\n",
      "Epoch 055\tTrain Loss: 0.2052\tVal Loss: 0.315\tAccuracy: 86.956522%\n",
      "Epoch 056\tTrain Loss: 0.2046\tVal Loss: 0.3145\tAccuracy: 86.956522%\n",
      "Epoch 057\tTrain Loss: 0.204\tVal Loss: 0.3139\tAccuracy: 86.956522%\n",
      "Epoch 058\tTrain Loss: 0.2033\tVal Loss: 0.3134\tAccuracy: 86.473430%\n",
      "Epoch 059\tTrain Loss: 0.2027\tVal Loss: 0.3129\tAccuracy: 86.473430%\n",
      "Epoch 060\tTrain Loss: 0.2021\tVal Loss: 0.3124\tAccuracy: 86.473430%\n",
      "Epoch 061\tTrain Loss: 0.2014\tVal Loss: 0.3119\tAccuracy: 86.473430%\n",
      "Epoch 062\tTrain Loss: 0.2008\tVal Loss: 0.3114\tAccuracy: 85.990338%\n",
      "Epoch 063\tTrain Loss: 0.2002\tVal Loss: 0.3109\tAccuracy: 85.990338%\n",
      "Epoch 064\tTrain Loss: 0.1995\tVal Loss: 0.3104\tAccuracy: 85.990338%\n",
      "Epoch 065\tTrain Loss: 0.1989\tVal Loss: 0.31\tAccuracy: 85.990338%\n",
      "Epoch 066\tTrain Loss: 0.1983\tVal Loss: 0.3095\tAccuracy: 85.990338%\n",
      "Epoch 067\tTrain Loss: 0.1977\tVal Loss: 0.3091\tAccuracy: 85.990338%\n",
      "Epoch 068\tTrain Loss: 0.197\tVal Loss: 0.3086\tAccuracy: 85.990338%\n",
      "Epoch 069\tTrain Loss: 0.1964\tVal Loss: 0.3082\tAccuracy: 85.990338%\n",
      "Epoch 070\tTrain Loss: 0.1958\tVal Loss: 0.3078\tAccuracy: 85.990338%\n",
      "Epoch 071\tTrain Loss: 0.1952\tVal Loss: 0.3074\tAccuracy: 85.990338%\n",
      "Epoch 072\tTrain Loss: 0.1945\tVal Loss: 0.307\tAccuracy: 85.990338%\n",
      "Epoch 073\tTrain Loss: 0.1939\tVal Loss: 0.3066\tAccuracy: 85.990338%\n",
      "Epoch 074\tTrain Loss: 0.1933\tVal Loss: 0.3062\tAccuracy: 85.990338%\n",
      "Epoch 075\tTrain Loss: 0.1927\tVal Loss: 0.3058\tAccuracy: 85.990338%\n",
      "Epoch 076\tTrain Loss: 0.192\tVal Loss: 0.3054\tAccuracy: 85.990338%\n",
      "Epoch 077\tTrain Loss: 0.1914\tVal Loss: 0.3051\tAccuracy: 85.990338%\n",
      "Epoch 078\tTrain Loss: 0.1908\tVal Loss: 0.3047\tAccuracy: 85.990338%\n",
      "Epoch 079\tTrain Loss: 0.1902\tVal Loss: 0.3043\tAccuracy: 85.990338%\n",
      "Epoch 080\tTrain Loss: 0.1896\tVal Loss: 0.304\tAccuracy: 85.990338%\n",
      "Epoch 081\tTrain Loss: 0.189\tVal Loss: 0.3036\tAccuracy: 85.990338%\n",
      "Epoch 082\tTrain Loss: 0.1884\tVal Loss: 0.3033\tAccuracy: 85.990338%\n",
      "Epoch 083\tTrain Loss: 0.1878\tVal Loss: 0.303\tAccuracy: 85.990338%\n",
      "Epoch 084\tTrain Loss: 0.1872\tVal Loss: 0.3026\tAccuracy: 85.990338%\n",
      "Epoch 085\tTrain Loss: 0.1866\tVal Loss: 0.3023\tAccuracy: 85.990338%\n",
      "Epoch 086\tTrain Loss: 0.186\tVal Loss: 0.302\tAccuracy: 85.990338%\n",
      "Epoch 087\tTrain Loss: 0.1855\tVal Loss: 0.3017\tAccuracy: 85.990338%\n",
      "Epoch 088\tTrain Loss: 0.1849\tVal Loss: 0.3014\tAccuracy: 85.990338%\n",
      "Epoch 089\tTrain Loss: 0.1844\tVal Loss: 0.3011\tAccuracy: 85.990338%\n",
      "Epoch 090\tTrain Loss: 0.1838\tVal Loss: 0.3008\tAccuracy: 85.990338%\n",
      "Epoch 091\tTrain Loss: 0.1833\tVal Loss: 0.3005\tAccuracy: 85.990338%\n",
      "Epoch 092\tTrain Loss: 0.1827\tVal Loss: 0.3003\tAccuracy: 85.990338%\n",
      "Epoch 093\tTrain Loss: 0.1822\tVal Loss: 0.3\tAccuracy: 85.990338%\n",
      "Epoch 094\tTrain Loss: 0.1817\tVal Loss: 0.2997\tAccuracy: 85.990338%\n",
      "Epoch 095\tTrain Loss: 0.1812\tVal Loss: 0.2994\tAccuracy: 85.990338%\n",
      "Epoch 096\tTrain Loss: 0.1807\tVal Loss: 0.2992\tAccuracy: 85.990338%\n",
      "Epoch 097\tTrain Loss: 0.1802\tVal Loss: 0.2989\tAccuracy: 85.990338%\n",
      "Epoch 098\tTrain Loss: 0.1797\tVal Loss: 0.2987\tAccuracy: 85.990338%\n",
      "Epoch 099\tTrain Loss: 0.1792\tVal Loss: 0.2984\tAccuracy: 85.990338%\n",
      "Model saved to models/86.957_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=26, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(100, model, loss_fcn, optimizer, train_res_dataloader, val_res_dataloader, logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b8914",
   "metadata": {},
   "source": [
    "# 86.95% Accurate!\n",
    "Now I'll run it for an absurd amount of epochs, until it clearly overfits, just to ensure we have the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "21ef8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000\tTrain Loss: 0.1787\tVal Loss: 0.2982\tAccuracy: 85.990338%\n",
      "Epoch 001\tTrain Loss: 0.1782\tVal Loss: 0.2979\tAccuracy: 85.990338%\n",
      "Epoch 002\tTrain Loss: 0.1777\tVal Loss: 0.2977\tAccuracy: 85.990338%\n",
      "Epoch 003\tTrain Loss: 0.1772\tVal Loss: 0.2975\tAccuracy: 85.990338%\n",
      "Epoch 004\tTrain Loss: 0.1768\tVal Loss: 0.2973\tAccuracy: 85.990338%\n",
      "Epoch 005\tTrain Loss: 0.1763\tVal Loss: 0.2971\tAccuracy: 85.990338%\n",
      "Epoch 006\tTrain Loss: 0.1758\tVal Loss: 0.2969\tAccuracy: 86.473430%\n",
      "Epoch 007\tTrain Loss: 0.1753\tVal Loss: 0.2967\tAccuracy: 86.473430%\n",
      "Epoch 008\tTrain Loss: 0.1748\tVal Loss: 0.2965\tAccuracy: 86.473430%\n",
      "Epoch 009\tTrain Loss: 0.1743\tVal Loss: 0.2963\tAccuracy: 86.473430%\n",
      "Epoch 010\tTrain Loss: 0.1738\tVal Loss: 0.2961\tAccuracy: 86.473430%\n",
      "Epoch 011\tTrain Loss: 0.1733\tVal Loss: 0.2959\tAccuracy: 86.473430%\n",
      "Epoch 012\tTrain Loss: 0.1728\tVal Loss: 0.2957\tAccuracy: 86.956522%\n",
      "Epoch 013\tTrain Loss: 0.1723\tVal Loss: 0.2951\tAccuracy: 86.956522%\n",
      "Epoch 014\tTrain Loss: 0.1719\tVal Loss: 0.2954\tAccuracy: 87.439614%\n",
      "Epoch 015\tTrain Loss: 0.1714\tVal Loss: 0.2952\tAccuracy: 87.439614%\n",
      "Epoch 016\tTrain Loss: 0.171\tVal Loss: 0.295\tAccuracy: 87.439614%\n",
      "Epoch 017\tTrain Loss: 0.1705\tVal Loss: 0.2948\tAccuracy: 87.439614%\n",
      "Epoch 018\tTrain Loss: 0.1701\tVal Loss: 0.2946\tAccuracy: 87.439614%\n",
      "Epoch 019\tTrain Loss: 0.1696\tVal Loss: 0.2944\tAccuracy: 87.439614%\n",
      "Epoch 020\tTrain Loss: 0.1692\tVal Loss: 0.2943\tAccuracy: 87.439614%\n",
      "Epoch 021\tTrain Loss: 0.1688\tVal Loss: 0.2941\tAccuracy: 87.439614%\n",
      "Epoch 022\tTrain Loss: 0.1684\tVal Loss: 0.2934\tAccuracy: 87.439614%\n",
      "Epoch 023\tTrain Loss: 0.1681\tVal Loss: 0.2937\tAccuracy: 87.439614%\n",
      "Epoch 024\tTrain Loss: 0.1677\tVal Loss: 0.2936\tAccuracy: 87.439614%\n",
      "Epoch 025\tTrain Loss: 0.1673\tVal Loss: 0.2934\tAccuracy: 87.439614%\n",
      "Epoch 026\tTrain Loss: 0.1669\tVal Loss: 0.2932\tAccuracy: 87.439614%\n",
      "Epoch 027\tTrain Loss: 0.1665\tVal Loss: 0.2931\tAccuracy: 87.439614%\n",
      "Epoch 028\tTrain Loss: 0.1661\tVal Loss: 0.2929\tAccuracy: 87.439614%\n",
      "Epoch 029\tTrain Loss: 0.1657\tVal Loss: 0.2927\tAccuracy: 87.439614%\n",
      "Epoch 030\tTrain Loss: 0.1653\tVal Loss: 0.2926\tAccuracy: 87.439614%\n",
      "Epoch 031\tTrain Loss: 0.1649\tVal Loss: 0.2919\tAccuracy: 87.439614%\n",
      "Epoch 032\tTrain Loss: 0.1646\tVal Loss: 0.2923\tAccuracy: 87.439614%\n",
      "Epoch 033\tTrain Loss: 0.1642\tVal Loss: 0.2921\tAccuracy: 87.439614%\n",
      "Epoch 034\tTrain Loss: 0.1638\tVal Loss: 0.2919\tAccuracy: 87.439614%\n",
      "Epoch 035\tTrain Loss: 0.1634\tVal Loss: 0.2918\tAccuracy: 87.439614%\n",
      "Epoch 036\tTrain Loss: 0.163\tVal Loss: 0.2916\tAccuracy: 87.439614%\n",
      "Epoch 037\tTrain Loss: 0.1626\tVal Loss: 0.2915\tAccuracy: 87.922705%\n",
      "Epoch 038\tTrain Loss: 0.1623\tVal Loss: 0.2914\tAccuracy: 87.922705%\n",
      "Epoch 039\tTrain Loss: 0.1619\tVal Loss: 0.2907\tAccuracy: 87.922705%\n",
      "Epoch 040\tTrain Loss: 0.1616\tVal Loss: 0.291\tAccuracy: 87.922705%\n",
      "Epoch 041\tTrain Loss: 0.1613\tVal Loss: 0.2908\tAccuracy: 87.922705%\n",
      "Epoch 042\tTrain Loss: 0.1609\tVal Loss: 0.2907\tAccuracy: 87.439614%\n",
      "Epoch 043\tTrain Loss: 0.1605\tVal Loss: 0.2905\tAccuracy: 87.439614%\n",
      "Epoch 044\tTrain Loss: 0.1601\tVal Loss: 0.2904\tAccuracy: 87.439614%\n",
      "Epoch 045\tTrain Loss: 0.1598\tVal Loss: 0.2903\tAccuracy: 87.439614%\n",
      "Epoch 046\tTrain Loss: 0.1594\tVal Loss: 0.2901\tAccuracy: 87.439614%\n",
      "Epoch 047\tTrain Loss: 0.1591\tVal Loss: 0.29\tAccuracy: 87.439614%\n",
      "Epoch 048\tTrain Loss: 0.1587\tVal Loss: 0.2893\tAccuracy: 87.922705%\n",
      "Epoch 049\tTrain Loss: 0.1585\tVal Loss: 0.2897\tAccuracy: 87.439614%\n",
      "Epoch 050\tTrain Loss: 0.1581\tVal Loss: 0.2895\tAccuracy: 87.439614%\n",
      "Epoch 051\tTrain Loss: 0.1577\tVal Loss: 0.2894\tAccuracy: 87.439614%\n",
      "Epoch 052\tTrain Loss: 0.1574\tVal Loss: 0.2893\tAccuracy: 87.439614%\n",
      "Epoch 053\tTrain Loss: 0.157\tVal Loss: 0.2891\tAccuracy: 87.439614%\n",
      "Epoch 054\tTrain Loss: 0.1567\tVal Loss: 0.289\tAccuracy: 87.439614%\n",
      "Epoch 055\tTrain Loss: 0.1563\tVal Loss: 0.2889\tAccuracy: 87.439614%\n",
      "Epoch 056\tTrain Loss: 0.156\tVal Loss: 0.2882\tAccuracy: 87.922705%\n",
      "Epoch 057\tTrain Loss: 0.1558\tVal Loss: 0.2886\tAccuracy: 87.922705%\n",
      "Epoch 058\tTrain Loss: 0.1554\tVal Loss: 0.2885\tAccuracy: 87.439614%\n",
      "Epoch 059\tTrain Loss: 0.1551\tVal Loss: 0.2884\tAccuracy: 87.439614%\n",
      "Epoch 060\tTrain Loss: 0.1548\tVal Loss: 0.2882\tAccuracy: 87.439614%\n",
      "Epoch 061\tTrain Loss: 0.1544\tVal Loss: 0.2881\tAccuracy: 87.439614%\n",
      "Epoch 062\tTrain Loss: 0.1541\tVal Loss: 0.288\tAccuracy: 87.439614%\n",
      "Epoch 063\tTrain Loss: 0.1538\tVal Loss: 0.2874\tAccuracy: 87.922705%\n",
      "Epoch 064\tTrain Loss: 0.1536\tVal Loss: 0.2878\tAccuracy: 86.956522%\n",
      "Epoch 065\tTrain Loss: 0.1532\tVal Loss: 0.2877\tAccuracy: 86.956522%\n",
      "Epoch 066\tTrain Loss: 0.1529\tVal Loss: 0.2876\tAccuracy: 86.956522%\n",
      "Epoch 067\tTrain Loss: 0.1526\tVal Loss: 0.2875\tAccuracy: 86.956522%\n",
      "Epoch 068\tTrain Loss: 0.1523\tVal Loss: 0.2868\tAccuracy: 87.439614%\n",
      "Epoch 069\tTrain Loss: 0.152\tVal Loss: 0.2872\tAccuracy: 86.956522%\n",
      "Epoch 070\tTrain Loss: 0.1517\tVal Loss: 0.2871\tAccuracy: 86.956522%\n",
      "Epoch 071\tTrain Loss: 0.1514\tVal Loss: 0.287\tAccuracy: 86.956522%\n",
      "Epoch 072\tTrain Loss: 0.1511\tVal Loss: 0.2869\tAccuracy: 86.956522%\n",
      "Epoch 073\tTrain Loss: 0.1508\tVal Loss: 0.2868\tAccuracy: 86.956522%\n",
      "Epoch 074\tTrain Loss: 0.1505\tVal Loss: 0.2862\tAccuracy: 86.956522%\n",
      "Epoch 075\tTrain Loss: 0.1503\tVal Loss: 0.2866\tAccuracy: 86.956522%\n",
      "Epoch 076\tTrain Loss: 0.1499\tVal Loss: 0.2865\tAccuracy: 86.956522%\n",
      "Epoch 077\tTrain Loss: 0.1496\tVal Loss: 0.2864\tAccuracy: 86.956522%\n",
      "Epoch 078\tTrain Loss: 0.1492\tVal Loss: 0.2863\tAccuracy: 86.956522%\n",
      "Epoch 079\tTrain Loss: 0.1489\tVal Loss: 0.2856\tAccuracy: 86.956522%\n",
      "Epoch 080\tTrain Loss: 0.1487\tVal Loss: 0.2861\tAccuracy: 86.956522%\n",
      "Epoch 081\tTrain Loss: 0.1484\tVal Loss: 0.286\tAccuracy: 86.956522%\n",
      "Epoch 082\tTrain Loss: 0.148\tVal Loss: 0.2858\tAccuracy: 86.956522%\n",
      "Epoch 083\tTrain Loss: 0.1477\tVal Loss: 0.2852\tAccuracy: 86.956522%\n",
      "Epoch 084\tTrain Loss: 0.1475\tVal Loss: 0.2856\tAccuracy: 86.956522%\n",
      "Epoch 085\tTrain Loss: 0.1472\tVal Loss: 0.2855\tAccuracy: 86.956522%\n",
      "Epoch 086\tTrain Loss: 0.1468\tVal Loss: 0.2854\tAccuracy: 86.956522%\n",
      "Epoch 087\tTrain Loss: 0.1465\tVal Loss: 0.2854\tAccuracy: 86.956522%\n",
      "Epoch 088\tTrain Loss: 0.1462\tVal Loss: 0.2846\tAccuracy: 86.956522%\n",
      "Epoch 089\tTrain Loss: 0.146\tVal Loss: 0.2851\tAccuracy: 86.956522%\n",
      "Epoch 090\tTrain Loss: 0.1457\tVal Loss: 0.285\tAccuracy: 86.956522%\n",
      "Epoch 091\tTrain Loss: 0.1454\tVal Loss: 0.2849\tAccuracy: 86.956522%\n",
      "Epoch 092\tTrain Loss: 0.1451\tVal Loss: 0.2848\tAccuracy: 86.956522%\n",
      "Epoch 093\tTrain Loss: 0.1448\tVal Loss: 0.2842\tAccuracy: 86.956522%\n",
      "Epoch 094\tTrain Loss: 0.1446\tVal Loss: 0.2847\tAccuracy: 86.956522%\n",
      "Epoch 095\tTrain Loss: 0.1443\tVal Loss: 0.2845\tAccuracy: 86.956522%\n",
      "Epoch 096\tTrain Loss: 0.144\tVal Loss: 0.2845\tAccuracy: 86.956522%\n",
      "Epoch 097\tTrain Loss: 0.1437\tVal Loss: 0.2845\tAccuracy: 86.956522%\n",
      "Epoch 098\tTrain Loss: 0.1435\tVal Loss: 0.2838\tAccuracy: 86.956522%\n",
      "Epoch 099\tTrain Loss: 0.1433\tVal Loss: 0.2842\tAccuracy: 86.956522%\n",
      "Epoch 100\tTrain Loss: 0.1429\tVal Loss: 0.2842\tAccuracy: 86.956522%\n",
      "Epoch 101\tTrain Loss: 0.1427\tVal Loss: 0.284\tAccuracy: 86.956522%\n",
      "Epoch 102\tTrain Loss: 0.1423\tVal Loss: 0.284\tAccuracy: 86.956522%\n",
      "Epoch 103\tTrain Loss: 0.142\tVal Loss: 0.2833\tAccuracy: 86.956522%\n",
      "Epoch 104\tTrain Loss: 0.1418\tVal Loss: 0.2838\tAccuracy: 86.956522%\n",
      "Epoch 105\tTrain Loss: 0.1415\tVal Loss: 0.2837\tAccuracy: 86.956522%\n",
      "Epoch 106\tTrain Loss: 0.1412\tVal Loss: 0.2836\tAccuracy: 86.956522%\n",
      "Epoch 107\tTrain Loss: 0.1409\tVal Loss: 0.2835\tAccuracy: 86.956522%\n",
      "Epoch 108\tTrain Loss: 0.1406\tVal Loss: 0.283\tAccuracy: 86.956522%\n",
      "Epoch 109\tTrain Loss: 0.1404\tVal Loss: 0.2833\tAccuracy: 86.956522%\n",
      "Epoch 110\tTrain Loss: 0.14\tVal Loss: 0.2832\tAccuracy: 86.956522%\n",
      "Epoch 111\tTrain Loss: 0.1397\tVal Loss: 0.2832\tAccuracy: 86.956522%\n",
      "Epoch 112\tTrain Loss: 0.1394\tVal Loss: 0.2825\tAccuracy: 86.956522%\n",
      "Epoch 113\tTrain Loss: 0.1392\tVal Loss: 0.283\tAccuracy: 86.956522%\n",
      "Epoch 114\tTrain Loss: 0.1388\tVal Loss: 0.283\tAccuracy: 86.956522%\n",
      "Epoch 115\tTrain Loss: 0.1385\tVal Loss: 0.2823\tAccuracy: 86.956522%\n",
      "Epoch 116\tTrain Loss: 0.1383\tVal Loss: 0.2827\tAccuracy: 86.956522%\n",
      "Epoch 117\tTrain Loss: 0.1379\tVal Loss: 0.2827\tAccuracy: 86.956522%\n",
      "Epoch 118\tTrain Loss: 0.1377\tVal Loss: 0.2821\tAccuracy: 86.956522%\n",
      "Epoch 119\tTrain Loss: 0.1373\tVal Loss: 0.2818\tAccuracy: 86.956522%\n",
      "Epoch 120\tTrain Loss: 0.1371\tVal Loss: 0.2824\tAccuracy: 86.956522%\n",
      "Epoch 121\tTrain Loss: 0.1368\tVal Loss: 0.2822\tAccuracy: 86.956522%\n",
      "Epoch 122\tTrain Loss: 0.1365\tVal Loss: 0.2818\tAccuracy: 86.956522%\n",
      "Epoch 123\tTrain Loss: 0.1362\tVal Loss: 0.2815\tAccuracy: 86.956522%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124\tTrain Loss: 0.136\tVal Loss: 0.282\tAccuracy: 86.956522%\n",
      "Epoch 125\tTrain Loss: 0.1358\tVal Loss: 0.2815\tAccuracy: 86.956522%\n",
      "Epoch 126\tTrain Loss: 0.1354\tVal Loss: 0.2817\tAccuracy: 86.956522%\n",
      "Epoch 127\tTrain Loss: 0.1352\tVal Loss: 0.2812\tAccuracy: 86.956522%\n",
      "Epoch 128\tTrain Loss: 0.135\tVal Loss: 0.2812\tAccuracy: 86.956522%\n",
      "Epoch 129\tTrain Loss: 0.1346\tVal Loss: 0.2814\tAccuracy: 86.956522%\n",
      "Epoch 130\tTrain Loss: 0.1344\tVal Loss: 0.2809\tAccuracy: 86.956522%\n",
      "Epoch 131\tTrain Loss: 0.1343\tVal Loss: 0.2809\tAccuracy: 86.956522%\n",
      "Epoch 132\tTrain Loss: 0.1338\tVal Loss: 0.2812\tAccuracy: 86.956522%\n",
      "Epoch 133\tTrain Loss: 0.1336\tVal Loss: 0.2812\tAccuracy: 86.956522%\n",
      "Epoch 134\tTrain Loss: 0.1334\tVal Loss: 0.2802\tAccuracy: 86.956522%\n",
      "Epoch 135\tTrain Loss: 0.1331\tVal Loss: 0.2809\tAccuracy: 86.956522%\n",
      "Epoch 136\tTrain Loss: 0.1328\tVal Loss: 0.2809\tAccuracy: 86.956522%\n",
      "Epoch 137\tTrain Loss: 0.1326\tVal Loss: 0.2804\tAccuracy: 86.956522%\n",
      "Epoch 138\tTrain Loss: 0.1323\tVal Loss: 0.2802\tAccuracy: 86.956522%\n",
      "Epoch 139\tTrain Loss: 0.1321\tVal Loss: 0.2803\tAccuracy: 86.956522%\n",
      "Epoch 140\tTrain Loss: 0.1317\tVal Loss: 0.2805\tAccuracy: 86.956522%\n",
      "Epoch 141\tTrain Loss: 0.1315\tVal Loss: 0.2799\tAccuracy: 86.956522%\n",
      "Epoch 142\tTrain Loss: 0.1313\tVal Loss: 0.28\tAccuracy: 86.956522%\n",
      "Epoch 143\tTrain Loss: 0.131\tVal Loss: 0.2797\tAccuracy: 86.956522%\n",
      "Epoch 144\tTrain Loss: 0.1308\tVal Loss: 0.2802\tAccuracy: 86.956522%\n",
      "Epoch 145\tTrain Loss: 0.1305\tVal Loss: 0.2792\tAccuracy: 86.956522%\n",
      "Epoch 146\tTrain Loss: 0.1302\tVal Loss: 0.2801\tAccuracy: 86.956522%\n",
      "Epoch 147\tTrain Loss: 0.1299\tVal Loss: 0.2799\tAccuracy: 86.956522%\n",
      "Epoch 148\tTrain Loss: 0.1297\tVal Loss: 0.279\tAccuracy: 86.956522%\n",
      "Epoch 149\tTrain Loss: 0.1294\tVal Loss: 0.2798\tAccuracy: 86.956522%\n",
      "Epoch 150\tTrain Loss: 0.1292\tVal Loss: 0.2788\tAccuracy: 87.439614%\n",
      "Epoch 151\tTrain Loss: 0.1289\tVal Loss: 0.2796\tAccuracy: 86.956522%\n",
      "Epoch 152\tTrain Loss: 0.1287\tVal Loss: 0.279\tAccuracy: 86.956522%\n",
      "Epoch 153\tTrain Loss: 0.1285\tVal Loss: 0.2791\tAccuracy: 86.956522%\n",
      "Epoch 154\tTrain Loss: 0.1281\tVal Loss: 0.2788\tAccuracy: 86.956522%\n",
      "Epoch 155\tTrain Loss: 0.128\tVal Loss: 0.2789\tAccuracy: 86.956522%\n",
      "Epoch 156\tTrain Loss: 0.1276\tVal Loss: 0.2787\tAccuracy: 86.956522%\n",
      "Epoch 157\tTrain Loss: 0.1275\tVal Loss: 0.2787\tAccuracy: 86.956522%\n",
      "Epoch 158\tTrain Loss: 0.1271\tVal Loss: 0.279\tAccuracy: 86.956522%\n",
      "Epoch 159\tTrain Loss: 0.1269\tVal Loss: 0.2781\tAccuracy: 87.922705%\n",
      "Epoch 160\tTrain Loss: 0.1266\tVal Loss: 0.2788\tAccuracy: 86.956522%\n",
      "Epoch 161\tTrain Loss: 0.1265\tVal Loss: 0.2779\tAccuracy: 87.922705%\n",
      "Epoch 162\tTrain Loss: 0.1261\tVal Loss: 0.2787\tAccuracy: 86.956522%\n",
      "Epoch 163\tTrain Loss: 0.126\tVal Loss: 0.2777\tAccuracy: 87.922705%\n",
      "Epoch 164\tTrain Loss: 0.1257\tVal Loss: 0.2785\tAccuracy: 86.956522%\n",
      "Epoch 165\tTrain Loss: 0.1256\tVal Loss: 0.2775\tAccuracy: 87.922705%\n",
      "Epoch 166\tTrain Loss: 0.1252\tVal Loss: 0.2783\tAccuracy: 86.956522%\n",
      "Epoch 167\tTrain Loss: 0.1251\tVal Loss: 0.2773\tAccuracy: 87.922705%\n",
      "Epoch 168\tTrain Loss: 0.1247\tVal Loss: 0.2777\tAccuracy: 86.956522%\n",
      "Epoch 169\tTrain Loss: 0.1246\tVal Loss: 0.2776\tAccuracy: 86.956522%\n",
      "Epoch 170\tTrain Loss: 0.1242\tVal Loss: 0.2775\tAccuracy: 86.956522%\n",
      "Epoch 171\tTrain Loss: 0.1241\tVal Loss: 0.2774\tAccuracy: 87.922705%\n",
      "Epoch 172\tTrain Loss: 0.1238\tVal Loss: 0.2773\tAccuracy: 87.439614%\n",
      "Epoch 173\tTrain Loss: 0.1236\tVal Loss: 0.2768\tAccuracy: 87.922705%\n",
      "Epoch 174\tTrain Loss: 0.1233\tVal Loss: 0.2775\tAccuracy: 86.956522%\n",
      "Epoch 175\tTrain Loss: 0.1231\tVal Loss: 0.2767\tAccuracy: 87.922705%\n",
      "Epoch 176\tTrain Loss: 0.1228\tVal Loss: 0.2769\tAccuracy: 87.922705%\n",
      "Epoch 177\tTrain Loss: 0.1227\tVal Loss: 0.2769\tAccuracy: 87.922705%\n",
      "Epoch 178\tTrain Loss: 0.1224\tVal Loss: 0.2767\tAccuracy: 87.922705%\n",
      "Epoch 179\tTrain Loss: 0.1222\tVal Loss: 0.2763\tAccuracy: 87.922705%\n",
      "Epoch 180\tTrain Loss: 0.122\tVal Loss: 0.2769\tAccuracy: 87.439614%\n",
      "Epoch 181\tTrain Loss: 0.1218\tVal Loss: 0.2762\tAccuracy: 87.922705%\n",
      "Epoch 182\tTrain Loss: 0.1215\tVal Loss: 0.2768\tAccuracy: 87.439614%\n",
      "Epoch 183\tTrain Loss: 0.1214\tVal Loss: 0.276\tAccuracy: 87.922705%\n",
      "Epoch 184\tTrain Loss: 0.1211\tVal Loss: 0.2762\tAccuracy: 87.922705%\n",
      "Epoch 185\tTrain Loss: 0.121\tVal Loss: 0.2762\tAccuracy: 87.922705%\n",
      "Epoch 186\tTrain Loss: 0.1207\tVal Loss: 0.2756\tAccuracy: 87.922705%\n",
      "Epoch 187\tTrain Loss: 0.1204\tVal Loss: 0.2764\tAccuracy: 87.439614%\n",
      "Epoch 188\tTrain Loss: 0.1203\tVal Loss: 0.2755\tAccuracy: 87.922705%\n",
      "Epoch 189\tTrain Loss: 0.12\tVal Loss: 0.2762\tAccuracy: 87.439614%\n",
      "Epoch 190\tTrain Loss: 0.1199\tVal Loss: 0.2753\tAccuracy: 87.922705%\n",
      "Epoch 191\tTrain Loss: 0.1196\tVal Loss: 0.2757\tAccuracy: 87.922705%\n",
      "Epoch 192\tTrain Loss: 0.1195\tVal Loss: 0.2755\tAccuracy: 87.922705%\n",
      "Epoch 193\tTrain Loss: 0.1192\tVal Loss: 0.2755\tAccuracy: 87.922705%\n",
      "Epoch 194\tTrain Loss: 0.119\tVal Loss: 0.275\tAccuracy: 87.922705%\n",
      "Epoch 195\tTrain Loss: 0.1187\tVal Loss: 0.2754\tAccuracy: 87.922705%\n",
      "Epoch 196\tTrain Loss: 0.1185\tVal Loss: 0.2752\tAccuracy: 87.922705%\n",
      "Epoch 197\tTrain Loss: 0.1183\tVal Loss: 0.2749\tAccuracy: 87.922705%\n",
      "Epoch 198\tTrain Loss: 0.1181\tVal Loss: 0.275\tAccuracy: 87.922705%\n",
      "Epoch 199\tTrain Loss: 0.1179\tVal Loss: 0.2751\tAccuracy: 87.922705%\n",
      "Epoch 200\tTrain Loss: 0.1177\tVal Loss: 0.2749\tAccuracy: 87.922705%\n",
      "Epoch 201\tTrain Loss: 0.1175\tVal Loss: 0.2746\tAccuracy: 87.922705%\n",
      "Epoch 202\tTrain Loss: 0.1172\tVal Loss: 0.2747\tAccuracy: 87.922705%\n",
      "Epoch 203\tTrain Loss: 0.117\tVal Loss: 0.2748\tAccuracy: 87.922705%\n",
      "Epoch 204\tTrain Loss: 0.1169\tVal Loss: 0.2742\tAccuracy: 87.922705%\n",
      "Epoch 205\tTrain Loss: 0.1165\tVal Loss: 0.2743\tAccuracy: 87.922705%\n",
      "Epoch 206\tTrain Loss: 0.1163\tVal Loss: 0.2748\tAccuracy: 87.922705%\n",
      "Epoch 207\tTrain Loss: 0.1162\tVal Loss: 0.2741\tAccuracy: 87.922705%\n",
      "Epoch 208\tTrain Loss: 0.116\tVal Loss: 0.2741\tAccuracy: 87.922705%\n",
      "Epoch 209\tTrain Loss: 0.1157\tVal Loss: 0.2742\tAccuracy: 87.922705%\n",
      "Epoch 210\tTrain Loss: 0.1156\tVal Loss: 0.2739\tAccuracy: 87.922705%\n",
      "Epoch 211\tTrain Loss: 0.1154\tVal Loss: 0.2737\tAccuracy: 87.922705%\n",
      "Epoch 212\tTrain Loss: 0.1151\tVal Loss: 0.2741\tAccuracy: 87.922705%\n",
      "Epoch 213\tTrain Loss: 0.115\tVal Loss: 0.274\tAccuracy: 87.922705%\n",
      "Epoch 214\tTrain Loss: 0.1147\tVal Loss: 0.2737\tAccuracy: 87.922705%\n",
      "Epoch 215\tTrain Loss: 0.1145\tVal Loss: 0.2738\tAccuracy: 87.922705%\n",
      "Epoch 216\tTrain Loss: 0.1144\tVal Loss: 0.2734\tAccuracy: 88.405797%\n",
      "Epoch 217\tTrain Loss: 0.1141\tVal Loss: 0.2738\tAccuracy: 87.922705%\n",
      "Epoch 218\tTrain Loss: 0.1139\tVal Loss: 0.2737\tAccuracy: 88.405797%\n",
      "Epoch 219\tTrain Loss: 0.1138\tVal Loss: 0.2734\tAccuracy: 88.405797%\n",
      "Epoch 220\tTrain Loss: 0.1136\tVal Loss: 0.2732\tAccuracy: 88.405797%\n",
      "Epoch 221\tTrain Loss: 0.1133\tVal Loss: 0.2736\tAccuracy: 88.405797%\n",
      "Epoch 222\tTrain Loss: 0.1132\tVal Loss: 0.273\tAccuracy: 88.405797%\n",
      "Epoch 223\tTrain Loss: 0.1129\tVal Loss: 0.2731\tAccuracy: 88.405797%\n",
      "Epoch 224\tTrain Loss: 0.1127\tVal Loss: 0.2729\tAccuracy: 88.405797%\n",
      "Epoch 225\tTrain Loss: 0.1125\tVal Loss: 0.2732\tAccuracy: 88.405797%\n",
      "Epoch 226\tTrain Loss: 0.1124\tVal Loss: 0.2733\tAccuracy: 88.405797%\n",
      "Epoch 227\tTrain Loss: 0.1122\tVal Loss: 0.2728\tAccuracy: 88.405797%\n",
      "Epoch 228\tTrain Loss: 0.112\tVal Loss: 0.2729\tAccuracy: 88.405797%\n",
      "Epoch 229\tTrain Loss: 0.1118\tVal Loss: 0.2731\tAccuracy: 88.405797%\n",
      "Epoch 230\tTrain Loss: 0.1117\tVal Loss: 0.273\tAccuracy: 88.405797%\n",
      "Epoch 231\tTrain Loss: 0.1115\tVal Loss: 0.2726\tAccuracy: 88.405797%\n",
      "Epoch 232\tTrain Loss: 0.1112\tVal Loss: 0.2726\tAccuracy: 88.405797%\n",
      "Epoch 233\tTrain Loss: 0.111\tVal Loss: 0.2732\tAccuracy: 88.405797%\n",
      "Epoch 234\tTrain Loss: 0.111\tVal Loss: 0.2725\tAccuracy: 88.405797%\n",
      "Epoch 235\tTrain Loss: 0.1107\tVal Loss: 0.2727\tAccuracy: 88.405797%\n",
      "Epoch 236\tTrain Loss: 0.1105\tVal Loss: 0.2723\tAccuracy: 88.405797%\n",
      "Epoch 237\tTrain Loss: 0.1103\tVal Loss: 0.2723\tAccuracy: 88.405797%\n",
      "Epoch 238\tTrain Loss: 0.1101\tVal Loss: 0.2725\tAccuracy: 88.405797%\n",
      "Epoch 239\tTrain Loss: 0.11\tVal Loss: 0.2721\tAccuracy: 88.405797%\n",
      "Epoch 240\tTrain Loss: 0.1098\tVal Loss: 0.272\tAccuracy: 88.405797%\n",
      "Epoch 241\tTrain Loss: 0.1096\tVal Loss: 0.272\tAccuracy: 88.405797%\n",
      "Epoch 242\tTrain Loss: 0.1094\tVal Loss: 0.2721\tAccuracy: 88.405797%\n",
      "Epoch 243\tTrain Loss: 0.1092\tVal Loss: 0.2719\tAccuracy: 88.405797%\n",
      "Epoch 244\tTrain Loss: 0.1091\tVal Loss: 0.2717\tAccuracy: 87.922705%\n",
      "Epoch 245\tTrain Loss: 0.1089\tVal Loss: 0.2718\tAccuracy: 88.405797%\n",
      "Epoch 246\tTrain Loss: 0.1087\tVal Loss: 0.2716\tAccuracy: 87.922705%\n",
      "Epoch 247\tTrain Loss: 0.1086\tVal Loss: 0.2714\tAccuracy: 87.922705%\n",
      "Epoch 248\tTrain Loss: 0.1084\tVal Loss: 0.2716\tAccuracy: 87.922705%\n",
      "Epoch 249\tTrain Loss: 0.1082\tVal Loss: 0.2713\tAccuracy: 87.922705%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\tTrain Loss: 0.108\tVal Loss: 0.2712\tAccuracy: 87.922705%\n",
      "Epoch 251\tTrain Loss: 0.1078\tVal Loss: 0.2713\tAccuracy: 87.922705%\n",
      "Epoch 252\tTrain Loss: 0.1076\tVal Loss: 0.2711\tAccuracy: 87.922705%\n",
      "Epoch 253\tTrain Loss: 0.1074\tVal Loss: 0.2709\tAccuracy: 87.922705%\n",
      "Epoch 254\tTrain Loss: 0.1072\tVal Loss: 0.2711\tAccuracy: 87.922705%\n",
      "Epoch 255\tTrain Loss: 0.107\tVal Loss: 0.2708\tAccuracy: 87.922705%\n",
      "Epoch 256\tTrain Loss: 0.1068\tVal Loss: 0.2707\tAccuracy: 87.922705%\n",
      "Epoch 257\tTrain Loss: 0.1065\tVal Loss: 0.2709\tAccuracy: 87.439614%\n",
      "Epoch 258\tTrain Loss: 0.1064\tVal Loss: 0.2704\tAccuracy: 87.922705%\n",
      "Epoch 259\tTrain Loss: 0.1061\tVal Loss: 0.2704\tAccuracy: 87.922705%\n",
      "Epoch 260\tTrain Loss: 0.1059\tVal Loss: 0.2707\tAccuracy: 87.439614%\n",
      "Epoch 261\tTrain Loss: 0.1058\tVal Loss: 0.2705\tAccuracy: 87.439614%\n",
      "Epoch 262\tTrain Loss: 0.1057\tVal Loss: 0.2702\tAccuracy: 87.922705%\n",
      "Epoch 263\tTrain Loss: 0.1055\tVal Loss: 0.2704\tAccuracy: 87.439614%\n",
      "Epoch 264\tTrain Loss: 0.1053\tVal Loss: 0.27\tAccuracy: 87.922705%\n",
      "Epoch 265\tTrain Loss: 0.1051\tVal Loss: 0.27\tAccuracy: 87.439614%\n",
      "Epoch 266\tTrain Loss: 0.1049\tVal Loss: 0.2698\tAccuracy: 87.439614%\n",
      "Epoch 267\tTrain Loss: 0.1047\tVal Loss: 0.27\tAccuracy: 87.439614%\n",
      "Epoch 268\tTrain Loss: 0.1045\tVal Loss: 0.2697\tAccuracy: 87.439614%\n",
      "Epoch 269\tTrain Loss: 0.1043\tVal Loss: 0.2695\tAccuracy: 87.439614%\n",
      "Epoch 270\tTrain Loss: 0.1041\tVal Loss: 0.2694\tAccuracy: 87.439614%\n",
      "Epoch 271\tTrain Loss: 0.104\tVal Loss: 0.2695\tAccuracy: 87.439614%\n",
      "Epoch 272\tTrain Loss: 0.1038\tVal Loss: 0.2695\tAccuracy: 87.439614%\n",
      "Epoch 273\tTrain Loss: 0.1036\tVal Loss: 0.2693\tAccuracy: 87.439614%\n",
      "Epoch 274\tTrain Loss: 0.1035\tVal Loss: 0.2691\tAccuracy: 87.439614%\n",
      "Epoch 275\tTrain Loss: 0.1033\tVal Loss: 0.269\tAccuracy: 87.439614%\n",
      "Epoch 276\tTrain Loss: 0.1031\tVal Loss: 0.269\tAccuracy: 87.439614%\n",
      "Epoch 277\tTrain Loss: 0.103\tVal Loss: 0.2688\tAccuracy: 87.439614%\n",
      "Epoch 278\tTrain Loss: 0.1028\tVal Loss: 0.2691\tAccuracy: 87.439614%\n",
      "Epoch 279\tTrain Loss: 0.1027\tVal Loss: 0.2686\tAccuracy: 87.439614%\n",
      "Epoch 280\tTrain Loss: 0.1025\tVal Loss: 0.2686\tAccuracy: 87.439614%\n",
      "Epoch 281\tTrain Loss: 0.1023\tVal Loss: 0.2686\tAccuracy: 87.439614%\n",
      "Epoch 282\tTrain Loss: 0.1022\tVal Loss: 0.2684\tAccuracy: 87.439614%\n",
      "Epoch 283\tTrain Loss: 0.102\tVal Loss: 0.2686\tAccuracy: 87.439614%\n",
      "Epoch 284\tTrain Loss: 0.1019\tVal Loss: 0.2684\tAccuracy: 87.439614%\n",
      "Epoch 285\tTrain Loss: 0.1017\tVal Loss: 0.2682\tAccuracy: 87.439614%\n",
      "Epoch 286\tTrain Loss: 0.1015\tVal Loss: 0.2685\tAccuracy: 87.439614%\n",
      "Epoch 287\tTrain Loss: 0.1014\tVal Loss: 0.2683\tAccuracy: 87.439614%\n",
      "Epoch 288\tTrain Loss: 0.1012\tVal Loss: 0.268\tAccuracy: 87.439614%\n",
      "Epoch 289\tTrain Loss: 0.1011\tVal Loss: 0.2683\tAccuracy: 87.439614%\n",
      "Epoch 290\tTrain Loss: 0.1009\tVal Loss: 0.2679\tAccuracy: 87.439614%\n",
      "Epoch 291\tTrain Loss: 0.1007\tVal Loss: 0.2681\tAccuracy: 87.439614%\n",
      "Epoch 292\tTrain Loss: 0.1005\tVal Loss: 0.2677\tAccuracy: 87.439614%\n",
      "Epoch 293\tTrain Loss: 0.1003\tVal Loss: 0.268\tAccuracy: 86.956522%\n",
      "Epoch 294\tTrain Loss: 0.1002\tVal Loss: 0.2675\tAccuracy: 87.439614%\n",
      "Epoch 295\tTrain Loss: 0.09998\tVal Loss: 0.2675\tAccuracy: 87.439614%\n",
      "Epoch 296\tTrain Loss: 0.09984\tVal Loss: 0.2678\tAccuracy: 86.956522%\n",
      "Epoch 297\tTrain Loss: 0.09972\tVal Loss: 0.2673\tAccuracy: 87.439614%\n",
      "Epoch 298\tTrain Loss: 0.09955\tVal Loss: 0.2675\tAccuracy: 87.439614%\n",
      "Epoch 299\tTrain Loss: 0.09945\tVal Loss: 0.2673\tAccuracy: 87.439614%\n",
      "Epoch 300\tTrain Loss: 0.09933\tVal Loss: 0.2671\tAccuracy: 87.439614%\n",
      "Epoch 301\tTrain Loss: 0.09915\tVal Loss: 0.2673\tAccuracy: 87.439614%\n",
      "Epoch 302\tTrain Loss: 0.09905\tVal Loss: 0.2671\tAccuracy: 87.439614%\n",
      "Epoch 303\tTrain Loss: 0.0989\tVal Loss: 0.2669\tAccuracy: 87.439614%\n",
      "Epoch 304\tTrain Loss: 0.09872\tVal Loss: 0.2672\tAccuracy: 86.956522%\n",
      "Epoch 305\tTrain Loss: 0.09864\tVal Loss: 0.2667\tAccuracy: 87.439614%\n",
      "Epoch 306\tTrain Loss: 0.09845\tVal Loss: 0.2667\tAccuracy: 87.439614%\n",
      "Epoch 307\tTrain Loss: 0.09833\tVal Loss: 0.267\tAccuracy: 86.956522%\n",
      "Epoch 308\tTrain Loss: 0.09821\tVal Loss: 0.2665\tAccuracy: 87.439614%\n",
      "Epoch 309\tTrain Loss: 0.098\tVal Loss: 0.2665\tAccuracy: 87.439614%\n",
      "Epoch 310\tTrain Loss: 0.0979\tVal Loss: 0.2668\tAccuracy: 86.956522%\n",
      "Epoch 311\tTrain Loss: 0.0978\tVal Loss: 0.2663\tAccuracy: 87.439614%\n",
      "Epoch 312\tTrain Loss: 0.09759\tVal Loss: 0.2662\tAccuracy: 87.439614%\n",
      "Epoch 313\tTrain Loss: 0.09751\tVal Loss: 0.2667\tAccuracy: 86.956522%\n",
      "Epoch 314\tTrain Loss: 0.09739\tVal Loss: 0.2661\tAccuracy: 87.439614%\n",
      "Epoch 315\tTrain Loss: 0.09721\tVal Loss: 0.266\tAccuracy: 87.439614%\n",
      "Epoch 316\tTrain Loss: 0.09712\tVal Loss: 0.2665\tAccuracy: 86.956522%\n",
      "Epoch 317\tTrain Loss: 0.097\tVal Loss: 0.2659\tAccuracy: 87.439614%\n",
      "Epoch 318\tTrain Loss: 0.09681\tVal Loss: 0.2659\tAccuracy: 86.956522%\n",
      "Epoch 319\tTrain Loss: 0.09675\tVal Loss: 0.266\tAccuracy: 86.956522%\n",
      "Epoch 320\tTrain Loss: 0.09658\tVal Loss: 0.2659\tAccuracy: 86.956522%\n",
      "Epoch 321\tTrain Loss: 0.09647\tVal Loss: 0.2657\tAccuracy: 86.956522%\n",
      "Epoch 322\tTrain Loss: 0.09638\tVal Loss: 0.2658\tAccuracy: 86.956522%\n",
      "Epoch 323\tTrain Loss: 0.09623\tVal Loss: 0.2656\tAccuracy: 86.956522%\n",
      "Epoch 324\tTrain Loss: 0.09616\tVal Loss: 0.2653\tAccuracy: 86.956522%\n",
      "Epoch 325\tTrain Loss: 0.09598\tVal Loss: 0.2655\tAccuracy: 86.956522%\n",
      "Epoch 326\tTrain Loss: 0.09588\tVal Loss: 0.2653\tAccuracy: 86.956522%\n",
      "Epoch 327\tTrain Loss: 0.09576\tVal Loss: 0.2651\tAccuracy: 86.956522%\n",
      "Epoch 328\tTrain Loss: 0.09559\tVal Loss: 0.2652\tAccuracy: 86.956522%\n",
      "Epoch 329\tTrain Loss: 0.09553\tVal Loss: 0.2652\tAccuracy: 86.956522%\n",
      "Epoch 330\tTrain Loss: 0.09534\tVal Loss: 0.2649\tAccuracy: 86.956522%\n",
      "Epoch 331\tTrain Loss: 0.09524\tVal Loss: 0.2649\tAccuracy: 86.956522%\n",
      "Epoch 332\tTrain Loss: 0.09513\tVal Loss: 0.2647\tAccuracy: 86.956522%\n",
      "Epoch 333\tTrain Loss: 0.09494\tVal Loss: 0.2647\tAccuracy: 86.956522%\n",
      "Epoch 334\tTrain Loss: 0.09486\tVal Loss: 0.2647\tAccuracy: 86.956522%\n",
      "Epoch 335\tTrain Loss: 0.09476\tVal Loss: 0.2645\tAccuracy: 86.956522%\n",
      "Epoch 336\tTrain Loss: 0.09461\tVal Loss: 0.2646\tAccuracy: 86.956522%\n",
      "Epoch 337\tTrain Loss: 0.09456\tVal Loss: 0.2646\tAccuracy: 86.956522%\n",
      "Epoch 338\tTrain Loss: 0.09439\tVal Loss: 0.2643\tAccuracy: 86.956522%\n",
      "Epoch 339\tTrain Loss: 0.09429\tVal Loss: 0.2644\tAccuracy: 86.956522%\n",
      "Epoch 340\tTrain Loss: 0.09424\tVal Loss: 0.2644\tAccuracy: 86.956522%\n",
      "Epoch 341\tTrain Loss: 0.0941\tVal Loss: 0.2641\tAccuracy: 86.956522%\n",
      "Epoch 342\tTrain Loss: 0.09402\tVal Loss: 0.2642\tAccuracy: 86.956522%\n",
      "Epoch 343\tTrain Loss: 0.09395\tVal Loss: 0.2639\tAccuracy: 86.956522%\n",
      "Epoch 344\tTrain Loss: 0.0938\tVal Loss: 0.2642\tAccuracy: 86.956522%\n",
      "Epoch 345\tTrain Loss: 0.09369\tVal Loss: 0.264\tAccuracy: 86.956522%\n",
      "Epoch 346\tTrain Loss: 0.09361\tVal Loss: 0.2638\tAccuracy: 86.956522%\n",
      "Epoch 347\tTrain Loss: 0.09345\tVal Loss: 0.2639\tAccuracy: 86.956522%\n",
      "Epoch 348\tTrain Loss: 0.09332\tVal Loss: 0.2638\tAccuracy: 86.956522%\n",
      "Epoch 349\tTrain Loss: 0.09325\tVal Loss: 0.2638\tAccuracy: 86.956522%\n",
      "Epoch 350\tTrain Loss: 0.09311\tVal Loss: 0.2636\tAccuracy: 86.956522%\n",
      "Epoch 351\tTrain Loss: 0.093\tVal Loss: 0.2636\tAccuracy: 86.956522%\n",
      "Epoch 352\tTrain Loss: 0.09294\tVal Loss: 0.2637\tAccuracy: 86.956522%\n",
      "Epoch 353\tTrain Loss: 0.09277\tVal Loss: 0.2634\tAccuracy: 86.956522%\n",
      "Epoch 354\tTrain Loss: 0.09265\tVal Loss: 0.2636\tAccuracy: 86.956522%\n",
      "Epoch 355\tTrain Loss: 0.09257\tVal Loss: 0.2632\tAccuracy: 86.956522%\n",
      "Epoch 356\tTrain Loss: 0.09243\tVal Loss: 0.2635\tAccuracy: 86.956522%\n",
      "Epoch 357\tTrain Loss: 0.09236\tVal Loss: 0.2633\tAccuracy: 86.956522%\n",
      "Epoch 358\tTrain Loss: 0.0923\tVal Loss: 0.2631\tAccuracy: 86.956522%\n",
      "Epoch 359\tTrain Loss: 0.09214\tVal Loss: 0.263\tAccuracy: 86.956522%\n",
      "Epoch 360\tTrain Loss: 0.09207\tVal Loss: 0.2631\tAccuracy: 86.956522%\n",
      "Epoch 361\tTrain Loss: 0.09199\tVal Loss: 0.2632\tAccuracy: 86.956522%\n",
      "Epoch 362\tTrain Loss: 0.09183\tVal Loss: 0.2629\tAccuracy: 86.956522%\n",
      "Epoch 363\tTrain Loss: 0.09177\tVal Loss: 0.2629\tAccuracy: 86.956522%\n",
      "Epoch 364\tTrain Loss: 0.09166\tVal Loss: 0.2629\tAccuracy: 86.956522%\n",
      "Epoch 365\tTrain Loss: 0.09152\tVal Loss: 0.2631\tAccuracy: 86.956522%\n",
      "Epoch 366\tTrain Loss: 0.09143\tVal Loss: 0.2626\tAccuracy: 86.956522%\n",
      "Epoch 367\tTrain Loss: 0.0913\tVal Loss: 0.2626\tAccuracy: 86.956522%\n",
      "Epoch 368\tTrain Loss: 0.0912\tVal Loss: 0.2627\tAccuracy: 86.956522%\n",
      "Epoch 369\tTrain Loss: 0.0911\tVal Loss: 0.2627\tAccuracy: 86.956522%\n",
      "Epoch 370\tTrain Loss: 0.09096\tVal Loss: 0.2624\tAccuracy: 86.956522%\n",
      "Epoch 371\tTrain Loss: 0.09085\tVal Loss: 0.2625\tAccuracy: 86.956522%\n",
      "Epoch 372\tTrain Loss: 0.09076\tVal Loss: 0.2625\tAccuracy: 86.956522%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373\tTrain Loss: 0.09061\tVal Loss: 0.2624\tAccuracy: 86.956522%\n",
      "Epoch 374\tTrain Loss: 0.09055\tVal Loss: 0.2622\tAccuracy: 86.956522%\n",
      "Epoch 375\tTrain Loss: 0.09038\tVal Loss: 0.2622\tAccuracy: 86.956522%\n",
      "Epoch 376\tTrain Loss: 0.09032\tVal Loss: 0.2625\tAccuracy: 86.956522%\n",
      "Epoch 377\tTrain Loss: 0.09021\tVal Loss: 0.262\tAccuracy: 86.956522%\n",
      "Epoch 378\tTrain Loss: 0.09004\tVal Loss: 0.2622\tAccuracy: 86.956522%\n",
      "Epoch 379\tTrain Loss: 0.08997\tVal Loss: 0.2621\tAccuracy: 86.956522%\n",
      "Epoch 380\tTrain Loss: 0.08989\tVal Loss: 0.2621\tAccuracy: 86.956522%\n",
      "Epoch 381\tTrain Loss: 0.0897\tVal Loss: 0.262\tAccuracy: 87.439614%\n",
      "Epoch 382\tTrain Loss: 0.08967\tVal Loss: 0.2617\tAccuracy: 87.439614%\n",
      "Epoch 383\tTrain Loss: 0.08949\tVal Loss: 0.2619\tAccuracy: 86.956522%\n",
      "Epoch 384\tTrain Loss: 0.08942\tVal Loss: 0.2618\tAccuracy: 87.439614%\n",
      "Epoch 385\tTrain Loss: 0.08935\tVal Loss: 0.2618\tAccuracy: 87.439614%\n",
      "Epoch 386\tTrain Loss: 0.08919\tVal Loss: 0.262\tAccuracy: 86.956522%\n",
      "Epoch 387\tTrain Loss: 0.08919\tVal Loss: 0.2615\tAccuracy: 87.439614%\n",
      "Epoch 388\tTrain Loss: 0.08904\tVal Loss: 0.2617\tAccuracy: 87.439614%\n",
      "Epoch 389\tTrain Loss: 0.08895\tVal Loss: 0.2616\tAccuracy: 87.439614%\n",
      "Epoch 390\tTrain Loss: 0.08891\tVal Loss: 0.2614\tAccuracy: 87.439614%\n",
      "Epoch 391\tTrain Loss: 0.08876\tVal Loss: 0.2616\tAccuracy: 87.439614%\n",
      "Epoch 392\tTrain Loss: 0.08872\tVal Loss: 0.2616\tAccuracy: 87.439614%\n",
      "Epoch 393\tTrain Loss: 0.08865\tVal Loss: 0.2615\tAccuracy: 87.439614%\n",
      "Epoch 394\tTrain Loss: 0.08852\tVal Loss: 0.2612\tAccuracy: 87.439614%\n",
      "Epoch 395\tTrain Loss: 0.08843\tVal Loss: 0.2613\tAccuracy: 87.439614%\n",
      "Epoch 396\tTrain Loss: 0.08837\tVal Loss: 0.2613\tAccuracy: 87.439614%\n",
      "Epoch 397\tTrain Loss: 0.08824\tVal Loss: 0.2613\tAccuracy: 87.439614%\n",
      "Epoch 398\tTrain Loss: 0.08815\tVal Loss: 0.2614\tAccuracy: 87.439614%\n",
      "Epoch 399\tTrain Loss: 0.08811\tVal Loss: 0.261\tAccuracy: 87.439614%\n",
      "Epoch 400\tTrain Loss: 0.08797\tVal Loss: 0.2612\tAccuracy: 87.439614%\n",
      "Epoch 401\tTrain Loss: 0.08789\tVal Loss: 0.2612\tAccuracy: 87.439614%\n",
      "Epoch 402\tTrain Loss: 0.08781\tVal Loss: 0.2608\tAccuracy: 87.439614%\n",
      "Epoch 403\tTrain Loss: 0.08766\tVal Loss: 0.2608\tAccuracy: 87.439614%\n",
      "Epoch 404\tTrain Loss: 0.08757\tVal Loss: 0.2611\tAccuracy: 87.439614%\n",
      "Epoch 405\tTrain Loss: 0.08756\tVal Loss: 0.2608\tAccuracy: 87.439614%\n",
      "Epoch 406\tTrain Loss: 0.08739\tVal Loss: 0.2606\tAccuracy: 87.439614%\n",
      "Epoch 407\tTrain Loss: 0.08729\tVal Loss: 0.2608\tAccuracy: 87.439614%\n",
      "Epoch 408\tTrain Loss: 0.08721\tVal Loss: 0.2607\tAccuracy: 87.439614%\n",
      "Epoch 409\tTrain Loss: 0.08719\tVal Loss: 0.2607\tAccuracy: 87.439614%\n",
      "Epoch 410\tTrain Loss: 0.08707\tVal Loss: 0.2604\tAccuracy: 87.439614%\n",
      "Epoch 411\tTrain Loss: 0.08697\tVal Loss: 0.2604\tAccuracy: 87.439614%\n",
      "Epoch 412\tTrain Loss: 0.08694\tVal Loss: 0.2607\tAccuracy: 87.439614%\n",
      "Epoch 413\tTrain Loss: 0.08688\tVal Loss: 0.2603\tAccuracy: 87.439614%\n",
      "Epoch 414\tTrain Loss: 0.08675\tVal Loss: 0.2602\tAccuracy: 87.439614%\n",
      "Epoch 415\tTrain Loss: 0.0867\tVal Loss: 0.2608\tAccuracy: 87.439614%\n",
      "Epoch 416\tTrain Loss: 0.08665\tVal Loss: 0.2602\tAccuracy: 87.439614%\n",
      "Epoch 417\tTrain Loss: 0.0865\tVal Loss: 0.2601\tAccuracy: 87.439614%\n",
      "Epoch 418\tTrain Loss: 0.08639\tVal Loss: 0.2601\tAccuracy: 87.439614%\n",
      "Epoch 419\tTrain Loss: 0.08635\tVal Loss: 0.2604\tAccuracy: 87.439614%\n",
      "Epoch 420\tTrain Loss: 0.08636\tVal Loss: 0.26\tAccuracy: 87.439614%\n",
      "Epoch 421\tTrain Loss: 0.08619\tVal Loss: 0.2599\tAccuracy: 87.439614%\n",
      "Epoch 422\tTrain Loss: 0.08616\tVal Loss: 0.2605\tAccuracy: 87.439614%\n",
      "Epoch 423\tTrain Loss: 0.0861\tVal Loss: 0.2598\tAccuracy: 87.439614%\n",
      "Epoch 424\tTrain Loss: 0.08598\tVal Loss: 0.2598\tAccuracy: 87.439614%\n",
      "Epoch 425\tTrain Loss: 0.0859\tVal Loss: 0.26\tAccuracy: 87.439614%\n",
      "Epoch 426\tTrain Loss: 0.08588\tVal Loss: 0.2601\tAccuracy: 87.439614%\n",
      "Epoch 427\tTrain Loss: 0.08578\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 428\tTrain Loss: 0.08564\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 429\tTrain Loss: 0.08557\tVal Loss: 0.26\tAccuracy: 87.439614%\n",
      "Epoch 430\tTrain Loss: 0.08559\tVal Loss: 0.2596\tAccuracy: 87.439614%\n",
      "Epoch 431\tTrain Loss: 0.08538\tVal Loss: 0.2596\tAccuracy: 87.439614%\n",
      "Epoch 432\tTrain Loss: 0.08532\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 433\tTrain Loss: 0.08528\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 434\tTrain Loss: 0.0852\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 435\tTrain Loss: 0.08506\tVal Loss: 0.2594\tAccuracy: 87.439614%\n",
      "Epoch 436\tTrain Loss: 0.08498\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 437\tTrain Loss: 0.08495\tVal Loss: 0.2595\tAccuracy: 87.439614%\n",
      "Epoch 438\tTrain Loss: 0.08487\tVal Loss: 0.2593\tAccuracy: 87.439614%\n",
      "Epoch 439\tTrain Loss: 0.08476\tVal Loss: 0.2597\tAccuracy: 87.439614%\n",
      "Epoch 440\tTrain Loss: 0.08476\tVal Loss: 0.2592\tAccuracy: 87.439614%\n",
      "Epoch 441\tTrain Loss: 0.08458\tVal Loss: 0.2591\tAccuracy: 87.439614%\n",
      "Epoch 442\tTrain Loss: 0.08452\tVal Loss: 0.2593\tAccuracy: 87.439614%\n",
      "Epoch 443\tTrain Loss: 0.08444\tVal Loss: 0.2595\tAccuracy: 87.439614%\n",
      "Epoch 444\tTrain Loss: 0.08442\tVal Loss: 0.259\tAccuracy: 87.439614%\n",
      "Epoch 445\tTrain Loss: 0.08424\tVal Loss: 0.259\tAccuracy: 87.439614%\n",
      "Epoch 446\tTrain Loss: 0.08419\tVal Loss: 0.2595\tAccuracy: 87.439614%\n",
      "Epoch 447\tTrain Loss: 0.08417\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 448\tTrain Loss: 0.08402\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 449\tTrain Loss: 0.084\tVal Loss: 0.2592\tAccuracy: 87.439614%\n",
      "Epoch 450\tTrain Loss: 0.08396\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 451\tTrain Loss: 0.08379\tVal Loss: 0.2587\tAccuracy: 87.439614%\n",
      "Epoch 452\tTrain Loss: 0.08376\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 453\tTrain Loss: 0.08374\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 454\tTrain Loss: 0.08357\tVal Loss: 0.2586\tAccuracy: 87.439614%\n",
      "Epoch 455\tTrain Loss: 0.08352\tVal Loss: 0.2588\tAccuracy: 87.439614%\n",
      "Epoch 456\tTrain Loss: 0.0835\tVal Loss: 0.2586\tAccuracy: 87.439614%\n",
      "Epoch 457\tTrain Loss: 0.08334\tVal Loss: 0.2586\tAccuracy: 87.439614%\n",
      "Epoch 458\tTrain Loss: 0.08327\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 459\tTrain Loss: 0.08329\tVal Loss: 0.2584\tAccuracy: 87.439614%\n",
      "Epoch 460\tTrain Loss: 0.08312\tVal Loss: 0.2584\tAccuracy: 87.439614%\n",
      "Epoch 461\tTrain Loss: 0.08306\tVal Loss: 0.2586\tAccuracy: 87.439614%\n",
      "Epoch 462\tTrain Loss: 0.08305\tVal Loss: 0.2587\tAccuracy: 87.439614%\n",
      "Epoch 463\tTrain Loss: 0.08295\tVal Loss: 0.2583\tAccuracy: 87.439614%\n",
      "Epoch 464\tTrain Loss: 0.08281\tVal Loss: 0.2583\tAccuracy: 87.439614%\n",
      "Epoch 465\tTrain Loss: 0.08276\tVal Loss: 0.2585\tAccuracy: 87.439614%\n",
      "Epoch 466\tTrain Loss: 0.08273\tVal Loss: 0.2584\tAccuracy: 87.439614%\n",
      "Epoch 467\tTrain Loss: 0.0826\tVal Loss: 0.2581\tAccuracy: 87.439614%\n",
      "Epoch 468\tTrain Loss: 0.08252\tVal Loss: 0.2587\tAccuracy: 87.439614%\n",
      "Epoch 469\tTrain Loss: 0.08251\tVal Loss: 0.258\tAccuracy: 87.439614%\n",
      "Epoch 470\tTrain Loss: 0.08237\tVal Loss: 0.258\tAccuracy: 87.439614%\n",
      "Epoch 471\tTrain Loss: 0.08227\tVal Loss: 0.258\tAccuracy: 87.439614%\n",
      "Epoch 472\tTrain Loss: 0.08223\tVal Loss: 0.2583\tAccuracy: 87.439614%\n",
      "Epoch 473\tTrain Loss: 0.08219\tVal Loss: 0.258\tAccuracy: 87.439614%\n",
      "Epoch 474\tTrain Loss: 0.08202\tVal Loss: 0.2578\tAccuracy: 87.439614%\n",
      "Epoch 475\tTrain Loss: 0.08194\tVal Loss: 0.2581\tAccuracy: 87.439614%\n",
      "Epoch 476\tTrain Loss: 0.08189\tVal Loss: 0.2579\tAccuracy: 87.439614%\n",
      "Epoch 477\tTrain Loss: 0.08185\tVal Loss: 0.2581\tAccuracy: 87.439614%\n",
      "Epoch 478\tTrain Loss: 0.0817\tVal Loss: 0.2577\tAccuracy: 87.439614%\n",
      "Epoch 479\tTrain Loss: 0.08159\tVal Loss: 0.2577\tAccuracy: 87.439614%\n",
      "Epoch 480\tTrain Loss: 0.08158\tVal Loss: 0.2578\tAccuracy: 87.439614%\n",
      "Epoch 481\tTrain Loss: 0.08153\tVal Loss: 0.2577\tAccuracy: 87.439614%\n",
      "Epoch 482\tTrain Loss: 0.0814\tVal Loss: 0.2578\tAccuracy: 87.439614%\n",
      "Epoch 483\tTrain Loss: 0.0813\tVal Loss: 0.2576\tAccuracy: 87.439614%\n",
      "Epoch 484\tTrain Loss: 0.08131\tVal Loss: 0.2575\tAccuracy: 87.439614%\n",
      "Epoch 485\tTrain Loss: 0.08118\tVal Loss: 0.2574\tAccuracy: 87.439614%\n",
      "Epoch 486\tTrain Loss: 0.0811\tVal Loss: 0.2573\tAccuracy: 87.439614%\n",
      "Epoch 487\tTrain Loss: 0.08108\tVal Loss: 0.2579\tAccuracy: 87.439614%\n",
      "Epoch 488\tTrain Loss: 0.08104\tVal Loss: 0.2572\tAccuracy: 87.439614%\n",
      "Epoch 489\tTrain Loss: 0.0809\tVal Loss: 0.2574\tAccuracy: 87.439614%\n",
      "Epoch 490\tTrain Loss: 0.08082\tVal Loss: 0.2573\tAccuracy: 87.439614%\n",
      "Epoch 491\tTrain Loss: 0.08082\tVal Loss: 0.2571\tAccuracy: 87.439614%\n",
      "Epoch 492\tTrain Loss: 0.08069\tVal Loss: 0.2571\tAccuracy: 87.439614%\n",
      "Epoch 493\tTrain Loss: 0.08059\tVal Loss: 0.2573\tAccuracy: 87.439614%\n",
      "Epoch 494\tTrain Loss: 0.08061\tVal Loss: 0.257\tAccuracy: 87.439614%\n",
      "Epoch 495\tTrain Loss: 0.08049\tVal Loss: 0.2569\tAccuracy: 87.439614%\n",
      "Epoch 496\tTrain Loss: 0.08041\tVal Loss: 0.2573\tAccuracy: 87.439614%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497\tTrain Loss: 0.08044\tVal Loss: 0.257\tAccuracy: 87.439614%\n",
      "Epoch 498\tTrain Loss: 0.0803\tVal Loss: 0.2568\tAccuracy: 87.439614%\n",
      "Epoch 499\tTrain Loss: 0.08026\tVal Loss: 0.2571\tAccuracy: 87.439614%\n",
      "Epoch 500\tTrain Loss: 0.08025\tVal Loss: 0.2567\tAccuracy: 87.439614%\n",
      "Epoch 501\tTrain Loss: 0.08013\tVal Loss: 0.257\tAccuracy: 87.439614%\n",
      "Epoch 502\tTrain Loss: 0.0801\tVal Loss: 0.2569\tAccuracy: 87.439614%\n",
      "Epoch 503\tTrain Loss: 0.08007\tVal Loss: 0.2565\tAccuracy: 87.439614%\n",
      "Epoch 504\tTrain Loss: 0.07997\tVal Loss: 0.2567\tAccuracy: 87.439614%\n",
      "Epoch 505\tTrain Loss: 0.07986\tVal Loss: 0.2567\tAccuracy: 87.439614%\n",
      "Epoch 506\tTrain Loss: 0.07991\tVal Loss: 0.2565\tAccuracy: 87.439614%\n",
      "Epoch 507\tTrain Loss: 0.07974\tVal Loss: 0.2565\tAccuracy: 87.439614%\n",
      "Epoch 508\tTrain Loss: 0.07973\tVal Loss: 0.2565\tAccuracy: 87.439614%\n",
      "Epoch 509\tTrain Loss: 0.07973\tVal Loss: 0.2564\tAccuracy: 87.439614%\n",
      "Epoch 510\tTrain Loss: 0.07955\tVal Loss: 0.2563\tAccuracy: 87.439614%\n",
      "Epoch 511\tTrain Loss: 0.07951\tVal Loss: 0.2564\tAccuracy: 87.439614%\n",
      "Epoch 512\tTrain Loss: 0.07952\tVal Loss: 0.2562\tAccuracy: 87.439614%\n",
      "Epoch 513\tTrain Loss: 0.07937\tVal Loss: 0.2561\tAccuracy: 87.922705%\n",
      "Epoch 514\tTrain Loss: 0.07935\tVal Loss: 0.2563\tAccuracy: 87.922705%\n",
      "Epoch 515\tTrain Loss: 0.07933\tVal Loss: 0.2561\tAccuracy: 87.922705%\n",
      "Epoch 516\tTrain Loss: 0.07915\tVal Loss: 0.2561\tAccuracy: 87.922705%\n",
      "Epoch 517\tTrain Loss: 0.07913\tVal Loss: 0.2562\tAccuracy: 87.922705%\n",
      "Epoch 518\tTrain Loss: 0.07912\tVal Loss: 0.256\tAccuracy: 87.922705%\n",
      "Epoch 519\tTrain Loss: 0.079\tVal Loss: 0.2561\tAccuracy: 87.922705%\n",
      "Epoch 520\tTrain Loss: 0.07901\tVal Loss: 0.2559\tAccuracy: 87.922705%\n",
      "Epoch 521\tTrain Loss: 0.07887\tVal Loss: 0.2559\tAccuracy: 87.922705%\n",
      "Epoch 522\tTrain Loss: 0.0788\tVal Loss: 0.2561\tAccuracy: 87.922705%\n",
      "Epoch 523\tTrain Loss: 0.07885\tVal Loss: 0.2558\tAccuracy: 87.922705%\n",
      "Epoch 524\tTrain Loss: 0.0787\tVal Loss: 0.2557\tAccuracy: 87.922705%\n",
      "Epoch 525\tTrain Loss: 0.07865\tVal Loss: 0.2559\tAccuracy: 87.922705%\n",
      "Epoch 526\tTrain Loss: 0.07864\tVal Loss: 0.2556\tAccuracy: 87.922705%\n",
      "Epoch 527\tTrain Loss: 0.0785\tVal Loss: 0.2559\tAccuracy: 87.922705%\n",
      "Epoch 528\tTrain Loss: 0.07849\tVal Loss: 0.2557\tAccuracy: 87.922705%\n",
      "Epoch 529\tTrain Loss: 0.07845\tVal Loss: 0.2555\tAccuracy: 87.922705%\n",
      "Epoch 530\tTrain Loss: 0.07835\tVal Loss: 0.2557\tAccuracy: 87.922705%\n",
      "Epoch 531\tTrain Loss: 0.07828\tVal Loss: 0.2557\tAccuracy: 87.922705%\n",
      "Epoch 532\tTrain Loss: 0.07828\tVal Loss: 0.2554\tAccuracy: 87.922705%\n",
      "Epoch 533\tTrain Loss: 0.07813\tVal Loss: 0.2555\tAccuracy: 87.922705%\n",
      "Epoch 534\tTrain Loss: 0.07813\tVal Loss: 0.2557\tAccuracy: 87.922705%\n",
      "Epoch 535\tTrain Loss: 0.07808\tVal Loss: 0.2554\tAccuracy: 87.922705%\n",
      "Epoch 536\tTrain Loss: 0.07797\tVal Loss: 0.2554\tAccuracy: 87.922705%\n",
      "Epoch 537\tTrain Loss: 0.07793\tVal Loss: 0.2556\tAccuracy: 87.922705%\n",
      "Epoch 538\tTrain Loss: 0.07795\tVal Loss: 0.2553\tAccuracy: 87.922705%\n",
      "Epoch 539\tTrain Loss: 0.07777\tVal Loss: 0.2552\tAccuracy: 87.922705%\n",
      "Epoch 540\tTrain Loss: 0.07774\tVal Loss: 0.2556\tAccuracy: 87.922705%\n",
      "Epoch 541\tTrain Loss: 0.07776\tVal Loss: 0.255\tAccuracy: 87.922705%\n",
      "Epoch 542\tTrain Loss: 0.07762\tVal Loss: 0.2553\tAccuracy: 87.922705%\n",
      "Epoch 543\tTrain Loss: 0.07759\tVal Loss: 0.2554\tAccuracy: 87.922705%\n",
      "Epoch 544\tTrain Loss: 0.07759\tVal Loss: 0.2551\tAccuracy: 87.922705%\n",
      "Epoch 545\tTrain Loss: 0.07745\tVal Loss: 0.2549\tAccuracy: 87.922705%\n",
      "Epoch 546\tTrain Loss: 0.07738\tVal Loss: 0.255\tAccuracy: 87.922705%\n",
      "Epoch 547\tTrain Loss: 0.07727\tVal Loss: 0.2553\tAccuracy: 88.405797%\n",
      "Epoch 548\tTrain Loss: 0.07726\tVal Loss: 0.2548\tAccuracy: 87.922705%\n",
      "Epoch 549\tTrain Loss: 0.07712\tVal Loss: 0.2551\tAccuracy: 88.405797%\n",
      "Epoch 550\tTrain Loss: 0.07712\tVal Loss: 0.2549\tAccuracy: 88.405797%\n",
      "Epoch 551\tTrain Loss: 0.07708\tVal Loss: 0.2548\tAccuracy: 88.405797%\n",
      "Epoch 552\tTrain Loss: 0.07689\tVal Loss: 0.2546\tAccuracy: 88.405797%\n",
      "Epoch 553\tTrain Loss: 0.0769\tVal Loss: 0.2549\tAccuracy: 88.405797%\n",
      "Epoch 554\tTrain Loss: 0.07685\tVal Loss: 0.2549\tAccuracy: 88.405797%\n",
      "Epoch 555\tTrain Loss: 0.0768\tVal Loss: 0.2547\tAccuracy: 88.405797%\n",
      "Epoch 556\tTrain Loss: 0.07672\tVal Loss: 0.2547\tAccuracy: 88.405797%\n",
      "Epoch 557\tTrain Loss: 0.07656\tVal Loss: 0.2547\tAccuracy: 88.405797%\n",
      "Epoch 558\tTrain Loss: 0.0766\tVal Loss: 0.2545\tAccuracy: 88.405797%\n",
      "Epoch 559\tTrain Loss: 0.07647\tVal Loss: 0.2544\tAccuracy: 88.405797%\n",
      "Epoch 560\tTrain Loss: 0.0764\tVal Loss: 0.2549\tAccuracy: 88.405797%\n",
      "Epoch 561\tTrain Loss: 0.0764\tVal Loss: 0.2542\tAccuracy: 88.405797%\n",
      "Epoch 562\tTrain Loss: 0.07631\tVal Loss: 0.2544\tAccuracy: 88.405797%\n",
      "Epoch 563\tTrain Loss: 0.0762\tVal Loss: 0.2547\tAccuracy: 88.405797%\n",
      "Epoch 564\tTrain Loss: 0.07622\tVal Loss: 0.2543\tAccuracy: 88.405797%\n",
      "Epoch 565\tTrain Loss: 0.07604\tVal Loss: 0.2542\tAccuracy: 88.405797%\n",
      "Epoch 566\tTrain Loss: 0.07601\tVal Loss: 0.2547\tAccuracy: 88.405797%\n",
      "Epoch 567\tTrain Loss: 0.076\tVal Loss: 0.254\tAccuracy: 88.405797%\n",
      "Epoch 568\tTrain Loss: 0.07587\tVal Loss: 0.2542\tAccuracy: 88.405797%\n",
      "Epoch 569\tTrain Loss: 0.07583\tVal Loss: 0.2541\tAccuracy: 88.405797%\n",
      "Epoch 570\tTrain Loss: 0.07583\tVal Loss: 0.2541\tAccuracy: 88.405797%\n",
      "Epoch 571\tTrain Loss: 0.07567\tVal Loss: 0.2542\tAccuracy: 88.405797%\n",
      "Epoch 572\tTrain Loss: 0.0757\tVal Loss: 0.2541\tAccuracy: 88.405797%\n",
      "Epoch 573\tTrain Loss: 0.0756\tVal Loss: 0.2538\tAccuracy: 88.405797%\n",
      "Epoch 574\tTrain Loss: 0.0755\tVal Loss: 0.2541\tAccuracy: 88.405797%\n",
      "Epoch 575\tTrain Loss: 0.07549\tVal Loss: 0.2539\tAccuracy: 88.405797%\n",
      "Epoch 576\tTrain Loss: 0.07541\tVal Loss: 0.2539\tAccuracy: 88.405797%\n",
      "Epoch 577\tTrain Loss: 0.07532\tVal Loss: 0.2539\tAccuracy: 88.405797%\n",
      "Epoch 578\tTrain Loss: 0.07529\tVal Loss: 0.2539\tAccuracy: 88.405797%\n",
      "Epoch 579\tTrain Loss: 0.0752\tVal Loss: 0.2538\tAccuracy: 88.405797%\n",
      "Epoch 580\tTrain Loss: 0.07514\tVal Loss: 0.2537\tAccuracy: 88.405797%\n",
      "Epoch 581\tTrain Loss: 0.075\tVal Loss: 0.2537\tAccuracy: 88.405797%\n",
      "Epoch 582\tTrain Loss: 0.075\tVal Loss: 0.2538\tAccuracy: 88.405797%\n",
      "Epoch 583\tTrain Loss: 0.07495\tVal Loss: 0.2537\tAccuracy: 88.405797%\n",
      "Epoch 584\tTrain Loss: 0.07483\tVal Loss: 0.2536\tAccuracy: 88.405797%\n",
      "Epoch 585\tTrain Loss: 0.07486\tVal Loss: 0.2533\tAccuracy: 88.405797%\n",
      "Epoch 586\tTrain Loss: 0.0747\tVal Loss: 0.2535\tAccuracy: 88.405797%\n",
      "Epoch 587\tTrain Loss: 0.07469\tVal Loss: 0.2534\tAccuracy: 88.405797%\n",
      "Epoch 588\tTrain Loss: 0.07467\tVal Loss: 0.2535\tAccuracy: 88.405797%\n",
      "Epoch 589\tTrain Loss: 0.07457\tVal Loss: 0.2536\tAccuracy: 88.405797%\n",
      "Epoch 590\tTrain Loss: 0.07454\tVal Loss: 0.2532\tAccuracy: 88.405797%\n",
      "Epoch 591\tTrain Loss: 0.07441\tVal Loss: 0.2532\tAccuracy: 88.405797%\n",
      "Epoch 592\tTrain Loss: 0.0744\tVal Loss: 0.2536\tAccuracy: 88.405797%\n",
      "Epoch 593\tTrain Loss: 0.07437\tVal Loss: 0.253\tAccuracy: 88.405797%\n",
      "Epoch 594\tTrain Loss: 0.07426\tVal Loss: 0.2533\tAccuracy: 88.405797%\n",
      "Epoch 595\tTrain Loss: 0.07424\tVal Loss: 0.253\tAccuracy: 88.405797%\n",
      "Epoch 596\tTrain Loss: 0.07418\tVal Loss: 0.2535\tAccuracy: 88.405797%\n",
      "Epoch 597\tTrain Loss: 0.07415\tVal Loss: 0.2531\tAccuracy: 88.405797%\n",
      "Epoch 598\tTrain Loss: 0.074\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 599\tTrain Loss: 0.07403\tVal Loss: 0.2534\tAccuracy: 88.405797%\n",
      "Epoch 600\tTrain Loss: 0.07398\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 601\tTrain Loss: 0.0739\tVal Loss: 0.2533\tAccuracy: 88.405797%\n",
      "Epoch 602\tTrain Loss: 0.0739\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 603\tTrain Loss: 0.07379\tVal Loss: 0.2531\tAccuracy: 88.405797%\n",
      "Epoch 604\tTrain Loss: 0.07377\tVal Loss: 0.253\tAccuracy: 88.405797%\n",
      "Epoch 605\tTrain Loss: 0.07378\tVal Loss: 0.2531\tAccuracy: 88.405797%\n",
      "Epoch 606\tTrain Loss: 0.07361\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 607\tTrain Loss: 0.07364\tVal Loss: 0.2527\tAccuracy: 88.405797%\n",
      "Epoch 608\tTrain Loss: 0.07356\tVal Loss: 0.2528\tAccuracy: 88.405797%\n",
      "Epoch 609\tTrain Loss: 0.07351\tVal Loss: 0.2531\tAccuracy: 88.405797%\n",
      "Epoch 610\tTrain Loss: 0.07347\tVal Loss: 0.2525\tAccuracy: 88.405797%\n",
      "Epoch 611\tTrain Loss: 0.0734\tVal Loss: 0.253\tAccuracy: 88.405797%\n",
      "Epoch 612\tTrain Loss: 0.07334\tVal Loss: 0.2526\tAccuracy: 88.405797%\n",
      "Epoch 613\tTrain Loss: 0.07324\tVal Loss: 0.2526\tAccuracy: 88.405797%\n",
      "Epoch 614\tTrain Loss: 0.0732\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 615\tTrain Loss: 0.07314\tVal Loss: 0.2525\tAccuracy: 88.405797%\n",
      "Epoch 616\tTrain Loss: 0.07306\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 617\tTrain Loss: 0.073\tVal Loss: 0.2525\tAccuracy: 88.405797%\n",
      "Epoch 618\tTrain Loss: 0.07289\tVal Loss: 0.2525\tAccuracy: 88.405797%\n",
      "Epoch 619\tTrain Loss: 0.07293\tVal Loss: 0.2524\tAccuracy: 88.405797%\n",
      "Epoch 620\tTrain Loss: 0.07278\tVal Loss: 0.2524\tAccuracy: 88.405797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621\tTrain Loss: 0.07277\tVal Loss: 0.2523\tAccuracy: 88.405797%\n",
      "Epoch 622\tTrain Loss: 0.07277\tVal Loss: 0.2524\tAccuracy: 88.405797%\n",
      "Epoch 623\tTrain Loss: 0.07266\tVal Loss: 0.2523\tAccuracy: 88.405797%\n",
      "Epoch 624\tTrain Loss: 0.07265\tVal Loss: 0.2521\tAccuracy: 88.405797%\n",
      "Epoch 625\tTrain Loss: 0.07252\tVal Loss: 0.2521\tAccuracy: 88.405797%\n",
      "Epoch 626\tTrain Loss: 0.07249\tVal Loss: 0.2523\tAccuracy: 88.405797%\n",
      "Epoch 627\tTrain Loss: 0.07248\tVal Loss: 0.252\tAccuracy: 88.405797%\n",
      "Epoch 628\tTrain Loss: 0.07233\tVal Loss: 0.2519\tAccuracy: 88.405797%\n",
      "Epoch 629\tTrain Loss: 0.0723\tVal Loss: 0.252\tAccuracy: 88.405797%\n",
      "Epoch 630\tTrain Loss: 0.07228\tVal Loss: 0.2519\tAccuracy: 88.405797%\n",
      "Epoch 631\tTrain Loss: 0.07212\tVal Loss: 0.2519\tAccuracy: 88.405797%\n",
      "Epoch 632\tTrain Loss: 0.07215\tVal Loss: 0.2519\tAccuracy: 88.405797%\n",
      "Epoch 633\tTrain Loss: 0.072\tVal Loss: 0.2518\tAccuracy: 88.405797%\n",
      "Epoch 634\tTrain Loss: 0.07198\tVal Loss: 0.2517\tAccuracy: 88.405797%\n",
      "Epoch 635\tTrain Loss: 0.07195\tVal Loss: 0.2516\tAccuracy: 88.405797%\n",
      "Epoch 636\tTrain Loss: 0.07183\tVal Loss: 0.2518\tAccuracy: 88.405797%\n",
      "Epoch 637\tTrain Loss: 0.07178\tVal Loss: 0.2517\tAccuracy: 88.405797%\n",
      "Epoch 638\tTrain Loss: 0.07173\tVal Loss: 0.2515\tAccuracy: 88.405797%\n",
      "Epoch 639\tTrain Loss: 0.07163\tVal Loss: 0.2516\tAccuracy: 88.405797%\n",
      "Epoch 640\tTrain Loss: 0.07159\tVal Loss: 0.2517\tAccuracy: 88.405797%\n",
      "Epoch 641\tTrain Loss: 0.07158\tVal Loss: 0.2515\tAccuracy: 88.405797%\n",
      "Epoch 642\tTrain Loss: 0.07142\tVal Loss: 0.2514\tAccuracy: 88.405797%\n",
      "Epoch 643\tTrain Loss: 0.07143\tVal Loss: 0.2517\tAccuracy: 88.405797%\n",
      "Epoch 644\tTrain Loss: 0.07139\tVal Loss: 0.2514\tAccuracy: 88.405797%\n",
      "Epoch 645\tTrain Loss: 0.07126\tVal Loss: 0.2514\tAccuracy: 88.405797%\n",
      "Epoch 646\tTrain Loss: 0.07127\tVal Loss: 0.2512\tAccuracy: 88.405797%\n",
      "Epoch 647\tTrain Loss: 0.07115\tVal Loss: 0.2513\tAccuracy: 88.405797%\n",
      "Epoch 648\tTrain Loss: 0.07113\tVal Loss: 0.2514\tAccuracy: 88.405797%\n",
      "Epoch 649\tTrain Loss: 0.07113\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 650\tTrain Loss: 0.07104\tVal Loss: 0.2514\tAccuracy: 88.405797%\n",
      "Epoch 651\tTrain Loss: 0.07102\tVal Loss: 0.2512\tAccuracy: 88.405797%\n",
      "Epoch 652\tTrain Loss: 0.07098\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 653\tTrain Loss: 0.07095\tVal Loss: 0.2512\tAccuracy: 88.405797%\n",
      "Epoch 654\tTrain Loss: 0.07095\tVal Loss: 0.2512\tAccuracy: 88.405797%\n",
      "Epoch 655\tTrain Loss: 0.07079\tVal Loss: 0.2509\tAccuracy: 88.405797%\n",
      "Epoch 656\tTrain Loss: 0.07078\tVal Loss: 0.2511\tAccuracy: 88.405797%\n",
      "Epoch 657\tTrain Loss: 0.07077\tVal Loss: 0.2509\tAccuracy: 88.405797%\n",
      "Epoch 658\tTrain Loss: 0.07067\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 659\tTrain Loss: 0.07065\tVal Loss: 0.2507\tAccuracy: 88.405797%\n",
      "Epoch 660\tTrain Loss: 0.07057\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 661\tTrain Loss: 0.07054\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 662\tTrain Loss: 0.07053\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 663\tTrain Loss: 0.07041\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 664\tTrain Loss: 0.07042\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 665\tTrain Loss: 0.07035\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 666\tTrain Loss: 0.07023\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 667\tTrain Loss: 0.07022\tVal Loss: 0.2509\tAccuracy: 88.405797%\n",
      "Epoch 668\tTrain Loss: 0.07014\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 669\tTrain Loss: 0.07007\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 670\tTrain Loss: 0.07009\tVal Loss: 0.2504\tAccuracy: 88.405797%\n",
      "Epoch 671\tTrain Loss: 0.06996\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 672\tTrain Loss: 0.06996\tVal Loss: 0.2506\tAccuracy: 88.405797%\n",
      "Epoch 673\tTrain Loss: 0.06993\tVal Loss: 0.2502\tAccuracy: 88.405797%\n",
      "Epoch 674\tTrain Loss: 0.06985\tVal Loss: 0.2508\tAccuracy: 88.405797%\n",
      "Epoch 675\tTrain Loss: 0.06987\tVal Loss: 0.2502\tAccuracy: 88.405797%\n",
      "Epoch 676\tTrain Loss: 0.06976\tVal Loss: 0.2505\tAccuracy: 88.405797%\n",
      "Epoch 677\tTrain Loss: 0.06974\tVal Loss: 0.2507\tAccuracy: 88.405797%\n",
      "Epoch 678\tTrain Loss: 0.06969\tVal Loss: 0.2501\tAccuracy: 88.405797%\n",
      "Epoch 679\tTrain Loss: 0.06961\tVal Loss: 0.2505\tAccuracy: 88.405797%\n",
      "Epoch 680\tTrain Loss: 0.06959\tVal Loss: 0.2502\tAccuracy: 88.405797%\n",
      "Epoch 681\tTrain Loss: 0.06958\tVal Loss: 0.25\tAccuracy: 88.405797%\n",
      "Epoch 682\tTrain Loss: 0.06944\tVal Loss: 0.2501\tAccuracy: 88.405797%\n",
      "Epoch 683\tTrain Loss: 0.06945\tVal Loss: 0.2502\tAccuracy: 88.405797%\n",
      "Epoch 684\tTrain Loss: 0.06941\tVal Loss: 0.25\tAccuracy: 88.405797%\n",
      "Epoch 685\tTrain Loss: 0.06929\tVal Loss: 0.2502\tAccuracy: 88.405797%\n",
      "Epoch 686\tTrain Loss: 0.0693\tVal Loss: 0.2499\tAccuracy: 88.405797%\n",
      "Epoch 687\tTrain Loss: 0.06918\tVal Loss: 0.2498\tAccuracy: 88.405797%\n",
      "Epoch 688\tTrain Loss: 0.06917\tVal Loss: 0.2501\tAccuracy: 88.405797%\n",
      "Epoch 689\tTrain Loss: 0.06914\tVal Loss: 0.2497\tAccuracy: 88.405797%\n",
      "Epoch 690\tTrain Loss: 0.06899\tVal Loss: 0.25\tAccuracy: 88.405797%\n",
      "Epoch 691\tTrain Loss: 0.06902\tVal Loss: 0.2498\tAccuracy: 88.405797%\n",
      "Epoch 692\tTrain Loss: 0.06898\tVal Loss: 0.2497\tAccuracy: 88.405797%\n",
      "Epoch 693\tTrain Loss: 0.06886\tVal Loss: 0.2499\tAccuracy: 88.405797%\n",
      "Epoch 694\tTrain Loss: 0.06886\tVal Loss: 0.2495\tAccuracy: 88.405797%\n",
      "Epoch 695\tTrain Loss: 0.06876\tVal Loss: 0.2497\tAccuracy: 88.405797%\n",
      "Epoch 696\tTrain Loss: 0.06871\tVal Loss: 0.2497\tAccuracy: 88.405797%\n",
      "Epoch 697\tTrain Loss: 0.06869\tVal Loss: 0.2494\tAccuracy: 88.405797%\n",
      "Epoch 698\tTrain Loss: 0.06858\tVal Loss: 0.2497\tAccuracy: 88.405797%\n",
      "Epoch 699\tTrain Loss: 0.06851\tVal Loss: 0.2495\tAccuracy: 88.405797%\n",
      "Epoch 700\tTrain Loss: 0.06854\tVal Loss: 0.2496\tAccuracy: 88.405797%\n",
      "Epoch 701\tTrain Loss: 0.06841\tVal Loss: 0.2493\tAccuracy: 88.405797%\n",
      "Epoch 702\tTrain Loss: 0.06841\tVal Loss: 0.2497\tAccuracy: 88.405797%\n",
      "Epoch 703\tTrain Loss: 0.06838\tVal Loss: 0.2492\tAccuracy: 88.405797%\n",
      "Epoch 704\tTrain Loss: 0.06828\tVal Loss: 0.2493\tAccuracy: 88.405797%\n",
      "Epoch 705\tTrain Loss: 0.06827\tVal Loss: 0.2495\tAccuracy: 88.405797%\n",
      "Epoch 706\tTrain Loss: 0.06823\tVal Loss: 0.2491\tAccuracy: 88.405797%\n",
      "Epoch 707\tTrain Loss: 0.06813\tVal Loss: 0.2493\tAccuracy: 88.405797%\n",
      "Epoch 708\tTrain Loss: 0.06809\tVal Loss: 0.2492\tAccuracy: 88.405797%\n",
      "Epoch 709\tTrain Loss: 0.06806\tVal Loss: 0.249\tAccuracy: 88.405797%\n",
      "Epoch 710\tTrain Loss: 0.06797\tVal Loss: 0.249\tAccuracy: 88.405797%\n",
      "Epoch 711\tTrain Loss: 0.06794\tVal Loss: 0.2492\tAccuracy: 88.405797%\n",
      "Epoch 712\tTrain Loss: 0.06795\tVal Loss: 0.2492\tAccuracy: 88.405797%\n",
      "Epoch 713\tTrain Loss: 0.06782\tVal Loss: 0.2489\tAccuracy: 88.405797%\n",
      "Epoch 714\tTrain Loss: 0.06781\tVal Loss: 0.2491\tAccuracy: 88.405797%\n",
      "Epoch 715\tTrain Loss: 0.06776\tVal Loss: 0.2487\tAccuracy: 88.405797%\n",
      "Epoch 716\tTrain Loss: 0.06769\tVal Loss: 0.249\tAccuracy: 88.405797%\n",
      "Epoch 717\tTrain Loss: 0.06761\tVal Loss: 0.2488\tAccuracy: 88.405797%\n",
      "Epoch 718\tTrain Loss: 0.06761\tVal Loss: 0.249\tAccuracy: 88.405797%\n",
      "Epoch 719\tTrain Loss: 0.06752\tVal Loss: 0.2486\tAccuracy: 88.405797%\n",
      "Epoch 720\tTrain Loss: 0.06751\tVal Loss: 0.249\tAccuracy: 88.405797%\n",
      "Epoch 721\tTrain Loss: 0.06749\tVal Loss: 0.2486\tAccuracy: 88.405797%\n",
      "Epoch 722\tTrain Loss: 0.0674\tVal Loss: 0.2488\tAccuracy: 88.405797%\n",
      "Epoch 723\tTrain Loss: 0.0674\tVal Loss: 0.2488\tAccuracy: 88.405797%\n",
      "Epoch 724\tTrain Loss: 0.06741\tVal Loss: 0.2486\tAccuracy: 88.405797%\n",
      "Epoch 725\tTrain Loss: 0.0673\tVal Loss: 0.2486\tAccuracy: 88.405797%\n",
      "Epoch 726\tTrain Loss: 0.06724\tVal Loss: 0.2488\tAccuracy: 88.405797%\n",
      "Epoch 727\tTrain Loss: 0.06722\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 728\tTrain Loss: 0.06714\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 729\tTrain Loss: 0.0671\tVal Loss: 0.2488\tAccuracy: 88.405797%\n",
      "Epoch 730\tTrain Loss: 0.06709\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 731\tTrain Loss: 0.06695\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 732\tTrain Loss: 0.06693\tVal Loss: 0.2483\tAccuracy: 88.405797%\n",
      "Epoch 733\tTrain Loss: 0.06698\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 734\tTrain Loss: 0.06684\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 735\tTrain Loss: 0.06679\tVal Loss: 0.2486\tAccuracy: 88.405797%\n",
      "Epoch 736\tTrain Loss: 0.06676\tVal Loss: 0.248\tAccuracy: 88.405797%\n",
      "Epoch 737\tTrain Loss: 0.06671\tVal Loss: 0.2484\tAccuracy: 88.405797%\n",
      "Epoch 738\tTrain Loss: 0.0666\tVal Loss: 0.2482\tAccuracy: 88.405797%\n",
      "Epoch 739\tTrain Loss: 0.06667\tVal Loss: 0.2482\tAccuracy: 88.405797%\n",
      "Epoch 740\tTrain Loss: 0.06653\tVal Loss: 0.2482\tAccuracy: 88.405797%\n",
      "Epoch 741\tTrain Loss: 0.06645\tVal Loss: 0.2481\tAccuracy: 88.405797%\n",
      "Epoch 742\tTrain Loss: 0.06639\tVal Loss: 0.2482\tAccuracy: 88.405797%\n",
      "Epoch 743\tTrain Loss: 0.06639\tVal Loss: 0.2481\tAccuracy: 88.405797%\n",
      "Epoch 744\tTrain Loss: 0.06629\tVal Loss: 0.2481\tAccuracy: 88.405797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745\tTrain Loss: 0.06621\tVal Loss: 0.248\tAccuracy: 88.405797%\n",
      "Epoch 746\tTrain Loss: 0.0662\tVal Loss: 0.2481\tAccuracy: 88.405797%\n",
      "Epoch 747\tTrain Loss: 0.06615\tVal Loss: 0.248\tAccuracy: 88.405797%\n",
      "Epoch 748\tTrain Loss: 0.06603\tVal Loss: 0.2477\tAccuracy: 88.405797%\n",
      "Epoch 749\tTrain Loss: 0.06595\tVal Loss: 0.2481\tAccuracy: 88.405797%\n",
      "Epoch 750\tTrain Loss: 0.06598\tVal Loss: 0.2478\tAccuracy: 88.405797%\n",
      "Epoch 751\tTrain Loss: 0.06587\tVal Loss: 0.2477\tAccuracy: 88.405797%\n",
      "Epoch 752\tTrain Loss: 0.06579\tVal Loss: 0.2478\tAccuracy: 88.405797%\n",
      "Epoch 753\tTrain Loss: 0.06574\tVal Loss: 0.2478\tAccuracy: 88.405797%\n",
      "Epoch 754\tTrain Loss: 0.06574\tVal Loss: 0.2477\tAccuracy: 88.405797%\n",
      "Epoch 755\tTrain Loss: 0.0657\tVal Loss: 0.2478\tAccuracy: 88.405797%\n",
      "Epoch 756\tTrain Loss: 0.06561\tVal Loss: 0.2477\tAccuracy: 88.405797%\n",
      "Epoch 757\tTrain Loss: 0.0656\tVal Loss: 0.2479\tAccuracy: 88.405797%\n",
      "Epoch 758\tTrain Loss: 0.06552\tVal Loss: 0.2477\tAccuracy: 88.405797%\n",
      "Epoch 759\tTrain Loss: 0.06542\tVal Loss: 0.2476\tAccuracy: 88.405797%\n",
      "Epoch 760\tTrain Loss: 0.0654\tVal Loss: 0.2478\tAccuracy: 88.405797%\n",
      "Epoch 761\tTrain Loss: 0.0654\tVal Loss: 0.2475\tAccuracy: 88.405797%\n",
      "Epoch 762\tTrain Loss: 0.06529\tVal Loss: 0.2476\tAccuracy: 88.405797%\n",
      "Epoch 763\tTrain Loss: 0.06521\tVal Loss: 0.2475\tAccuracy: 88.405797%\n",
      "Epoch 764\tTrain Loss: 0.06517\tVal Loss: 0.2475\tAccuracy: 88.405797%\n",
      "Epoch 765\tTrain Loss: 0.06515\tVal Loss: 0.2475\tAccuracy: 88.405797%\n",
      "Epoch 766\tTrain Loss: 0.06503\tVal Loss: 0.2474\tAccuracy: 88.405797%\n",
      "Epoch 767\tTrain Loss: 0.06501\tVal Loss: 0.2476\tAccuracy: 88.405797%\n",
      "Epoch 768\tTrain Loss: 0.065\tVal Loss: 0.2473\tAccuracy: 88.405797%\n",
      "Epoch 769\tTrain Loss: 0.06487\tVal Loss: 0.2475\tAccuracy: 88.405797%\n",
      "Epoch 770\tTrain Loss: 0.06482\tVal Loss: 0.2474\tAccuracy: 88.405797%\n",
      "Epoch 771\tTrain Loss: 0.0648\tVal Loss: 0.2475\tAccuracy: 88.405797%\n",
      "Epoch 772\tTrain Loss: 0.06481\tVal Loss: 0.2473\tAccuracy: 88.405797%\n",
      "Epoch 773\tTrain Loss: 0.06467\tVal Loss: 0.2472\tAccuracy: 88.405797%\n",
      "Epoch 774\tTrain Loss: 0.06462\tVal Loss: 0.2473\tAccuracy: 88.405797%\n",
      "Epoch 775\tTrain Loss: 0.06456\tVal Loss: 0.2473\tAccuracy: 88.405797%\n",
      "Epoch 776\tTrain Loss: 0.0645\tVal Loss: 0.2472\tAccuracy: 88.405797%\n",
      "Epoch 777\tTrain Loss: 0.06443\tVal Loss: 0.2474\tAccuracy: 88.405797%\n",
      "Epoch 778\tTrain Loss: 0.06436\tVal Loss: 0.2472\tAccuracy: 88.405797%\n",
      "Epoch 779\tTrain Loss: 0.06434\tVal Loss: 0.2473\tAccuracy: 88.405797%\n",
      "Epoch 780\tTrain Loss: 0.06424\tVal Loss: 0.2471\tAccuracy: 88.405797%\n",
      "Epoch 781\tTrain Loss: 0.0642\tVal Loss: 0.2472\tAccuracy: 88.405797%\n",
      "Epoch 782\tTrain Loss: 0.06412\tVal Loss: 0.2471\tAccuracy: 88.405797%\n",
      "Epoch 783\tTrain Loss: 0.0641\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 784\tTrain Loss: 0.06401\tVal Loss: 0.2471\tAccuracy: 88.405797%\n",
      "Epoch 785\tTrain Loss: 0.06397\tVal Loss: 0.2473\tAccuracy: 88.405797%\n",
      "Epoch 786\tTrain Loss: 0.06391\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 787\tTrain Loss: 0.06386\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 788\tTrain Loss: 0.06383\tVal Loss: 0.2472\tAccuracy: 88.405797%\n",
      "Epoch 789\tTrain Loss: 0.06378\tVal Loss: 0.2471\tAccuracy: 88.405797%\n",
      "Epoch 790\tTrain Loss: 0.0638\tVal Loss: 0.2471\tAccuracy: 88.405797%\n",
      "Epoch 791\tTrain Loss: 0.06368\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 792\tTrain Loss: 0.06363\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 793\tTrain Loss: 0.06365\tVal Loss: 0.2469\tAccuracy: 88.405797%\n",
      "Epoch 794\tTrain Loss: 0.06357\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 795\tTrain Loss: 0.06349\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 796\tTrain Loss: 0.06352\tVal Loss: 0.2469\tAccuracy: 88.405797%\n",
      "Epoch 797\tTrain Loss: 0.06333\tVal Loss: 0.2469\tAccuracy: 88.405797%\n",
      "Epoch 798\tTrain Loss: 0.0634\tVal Loss: 0.2471\tAccuracy: 88.405797%\n",
      "Epoch 799\tTrain Loss: 0.06332\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 800\tTrain Loss: 0.06321\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 801\tTrain Loss: 0.06322\tVal Loss: 0.2469\tAccuracy: 88.405797%\n",
      "Epoch 802\tTrain Loss: 0.06319\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 803\tTrain Loss: 0.06305\tVal Loss: 0.2469\tAccuracy: 88.405797%\n",
      "Epoch 804\tTrain Loss: 0.0631\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 805\tTrain Loss: 0.06297\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 806\tTrain Loss: 0.06289\tVal Loss: 0.247\tAccuracy: 88.405797%\n",
      "Epoch 807\tTrain Loss: 0.06295\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 808\tTrain Loss: 0.06281\tVal Loss: 0.2469\tAccuracy: 88.405797%\n",
      "Epoch 809\tTrain Loss: 0.0628\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 810\tTrain Loss: 0.06279\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 811\tTrain Loss: 0.06272\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 812\tTrain Loss: 0.06268\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 813\tTrain Loss: 0.06263\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 814\tTrain Loss: 0.0626\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 815\tTrain Loss: 0.06259\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 816\tTrain Loss: 0.06244\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 817\tTrain Loss: 0.06243\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 818\tTrain Loss: 0.0624\tVal Loss: 0.2466\tAccuracy: 88.405797%\n",
      "Epoch 819\tTrain Loss: 0.06243\tVal Loss: 0.2468\tAccuracy: 88.405797%\n",
      "Epoch 820\tTrain Loss: 0.06233\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 821\tTrain Loss: 0.06224\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 822\tTrain Loss: 0.06233\tVal Loss: 0.2466\tAccuracy: 88.405797%\n",
      "Epoch 823\tTrain Loss: 0.06215\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 824\tTrain Loss: 0.06219\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 825\tTrain Loss: 0.06215\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 826\tTrain Loss: 0.06205\tVal Loss: 0.2467\tAccuracy: 88.405797%\n",
      "Epoch 827\tTrain Loss: 0.06209\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 828\tTrain Loss: 0.06201\tVal Loss: 0.2466\tAccuracy: 88.405797%\n",
      "Epoch 829\tTrain Loss: 0.06199\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 830\tTrain Loss: 0.06195\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 831\tTrain Loss: 0.06186\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 832\tTrain Loss: 0.06187\tVal Loss: 0.2466\tAccuracy: 88.405797%\n",
      "Epoch 833\tTrain Loss: 0.0618\tVal Loss: 0.2463\tAccuracy: 88.405797%\n",
      "Epoch 834\tTrain Loss: 0.06167\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 835\tTrain Loss: 0.06165\tVal Loss: 0.2466\tAccuracy: 88.405797%\n",
      "Epoch 836\tTrain Loss: 0.0616\tVal Loss: 0.2463\tAccuracy: 88.405797%\n",
      "Epoch 837\tTrain Loss: 0.06154\tVal Loss: 0.2466\tAccuracy: 88.405797%\n",
      "Epoch 838\tTrain Loss: 0.0615\tVal Loss: 0.2463\tAccuracy: 88.405797%\n",
      "Epoch 839\tTrain Loss: 0.06148\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 840\tTrain Loss: 0.0614\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 841\tTrain Loss: 0.06138\tVal Loss: 0.2463\tAccuracy: 88.405797%\n",
      "Epoch 842\tTrain Loss: 0.06131\tVal Loss: 0.2465\tAccuracy: 88.405797%\n",
      "Epoch 843\tTrain Loss: 0.06125\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 844\tTrain Loss: 0.06124\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 845\tTrain Loss: 0.06114\tVal Loss: 0.2464\tAccuracy: 88.405797%\n",
      "Epoch 846\tTrain Loss: 0.06117\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 847\tTrain Loss: 0.06103\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 848\tTrain Loss: 0.06104\tVal Loss: 0.2466\tAccuracy: 87.922705%\n",
      "Epoch 849\tTrain Loss: 0.06105\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 850\tTrain Loss: 0.06094\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 851\tTrain Loss: 0.0609\tVal Loss: 0.2465\tAccuracy: 87.922705%\n",
      "Epoch 852\tTrain Loss: 0.06089\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 853\tTrain Loss: 0.06085\tVal Loss: 0.2465\tAccuracy: 87.922705%\n",
      "Epoch 854\tTrain Loss: 0.06082\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 855\tTrain Loss: 0.06079\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 856\tTrain Loss: 0.06064\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 857\tTrain Loss: 0.06069\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 858\tTrain Loss: 0.06058\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 859\tTrain Loss: 0.06051\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 860\tTrain Loss: 0.06057\tVal Loss: 0.2461\tAccuracy: 87.922705%\n",
      "Epoch 861\tTrain Loss: 0.06047\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 862\tTrain Loss: 0.06041\tVal Loss: 0.2465\tAccuracy: 87.922705%\n",
      "Epoch 863\tTrain Loss: 0.06045\tVal Loss: 0.2461\tAccuracy: 87.922705%\n",
      "Epoch 864\tTrain Loss: 0.06035\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 865\tTrain Loss: 0.06032\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 866\tTrain Loss: 0.06032\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 867\tTrain Loss: 0.06021\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 868\tTrain Loss: 0.06026\tVal Loss: 0.2462\tAccuracy: 87.922705%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869\tTrain Loss: 0.0602\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 870\tTrain Loss: 0.06012\tVal Loss: 0.2464\tAccuracy: 87.922705%\n",
      "Epoch 871\tTrain Loss: 0.06015\tVal Loss: 0.246\tAccuracy: 87.922705%\n",
      "Epoch 872\tTrain Loss: 0.06006\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 873\tTrain Loss: 0.05999\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 874\tTrain Loss: 0.06003\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 875\tTrain Loss: 0.05989\tVal Loss: 0.2461\tAccuracy: 87.922705%\n",
      "Epoch 876\tTrain Loss: 0.05991\tVal Loss: 0.2463\tAccuracy: 87.922705%\n",
      "Epoch 877\tTrain Loss: 0.0599\tVal Loss: 0.2459\tAccuracy: 87.922705%\n",
      "Epoch 878\tTrain Loss: 0.05981\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 879\tTrain Loss: 0.0598\tVal Loss: 0.2461\tAccuracy: 87.922705%\n",
      "Epoch 880\tTrain Loss: 0.05982\tVal Loss: 0.2461\tAccuracy: 87.922705%\n",
      "Epoch 881\tTrain Loss: 0.05968\tVal Loss: 0.246\tAccuracy: 87.922705%\n",
      "Epoch 882\tTrain Loss: 0.05969\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 883\tTrain Loss: 0.05966\tVal Loss: 0.2459\tAccuracy: 87.922705%\n",
      "Epoch 884\tTrain Loss: 0.0596\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 885\tTrain Loss: 0.05957\tVal Loss: 0.246\tAccuracy: 87.922705%\n",
      "Epoch 886\tTrain Loss: 0.05954\tVal Loss: 0.2459\tAccuracy: 87.922705%\n",
      "Epoch 887\tTrain Loss: 0.05948\tVal Loss: 0.2462\tAccuracy: 87.922705%\n",
      "Epoch 888\tTrain Loss: 0.0595\tVal Loss: 0.2458\tAccuracy: 87.922705%\n",
      "Epoch 889\tTrain Loss: 0.05933\tVal Loss: 0.246\tAccuracy: 87.922705%\n",
      "Epoch 890\tTrain Loss: 0.0593\tVal Loss: 0.246\tAccuracy: 87.922705%\n",
      "Epoch 891\tTrain Loss: 0.05938\tVal Loss: 0.2457\tAccuracy: 88.405797%\n",
      "Epoch 892\tTrain Loss: 0.05926\tVal Loss: 0.246\tAccuracy: 88.405797%\n",
      "Epoch 893\tTrain Loss: 0.05918\tVal Loss: 0.2459\tAccuracy: 88.405797%\n",
      "Epoch 894\tTrain Loss: 0.05921\tVal Loss: 0.2459\tAccuracy: 88.405797%\n",
      "Epoch 895\tTrain Loss: 0.0591\tVal Loss: 0.2458\tAccuracy: 88.405797%\n",
      "Epoch 896\tTrain Loss: 0.05914\tVal Loss: 0.2459\tAccuracy: 88.405797%\n",
      "Epoch 897\tTrain Loss: 0.05913\tVal Loss: 0.2456\tAccuracy: 88.405797%\n",
      "Epoch 898\tTrain Loss: 0.05905\tVal Loss: 0.2459\tAccuracy: 88.405797%\n",
      "Epoch 899\tTrain Loss: 0.05893\tVal Loss: 0.2455\tAccuracy: 88.405797%\n",
      "Epoch 900\tTrain Loss: 0.05901\tVal Loss: 0.2457\tAccuracy: 88.405797%\n",
      "Epoch 901\tTrain Loss: 0.05893\tVal Loss: 0.2456\tAccuracy: 88.405797%\n",
      "Epoch 902\tTrain Loss: 0.05893\tVal Loss: 0.2458\tAccuracy: 88.405797%\n",
      "Epoch 903\tTrain Loss: 0.05894\tVal Loss: 0.2455\tAccuracy: 88.405797%\n",
      "Epoch 904\tTrain Loss: 0.05882\tVal Loss: 0.2457\tAccuracy: 88.405797%\n",
      "Epoch 905\tTrain Loss: 0.05878\tVal Loss: 0.2454\tAccuracy: 88.405797%\n",
      "Epoch 906\tTrain Loss: 0.05887\tVal Loss: 0.2456\tAccuracy: 88.405797%\n",
      "Epoch 907\tTrain Loss: 0.05875\tVal Loss: 0.2454\tAccuracy: 88.405797%\n",
      "Epoch 908\tTrain Loss: 0.05876\tVal Loss: 0.2457\tAccuracy: 88.405797%\n",
      "Epoch 909\tTrain Loss: 0.05879\tVal Loss: 0.2453\tAccuracy: 88.405797%\n",
      "Epoch 910\tTrain Loss: 0.05867\tVal Loss: 0.2456\tAccuracy: 88.405797%\n",
      "Epoch 911\tTrain Loss: 0.05863\tVal Loss: 0.2454\tAccuracy: 88.405797%\n",
      "Epoch 912\tTrain Loss: 0.05865\tVal Loss: 0.2455\tAccuracy: 88.405797%\n",
      "Epoch 913\tTrain Loss: 0.05857\tVal Loss: 0.2454\tAccuracy: 88.405797%\n",
      "Epoch 914\tTrain Loss: 0.05856\tVal Loss: 0.2456\tAccuracy: 88.405797%\n",
      "Epoch 915\tTrain Loss: 0.05862\tVal Loss: 0.2452\tAccuracy: 88.405797%\n",
      "Epoch 916\tTrain Loss: 0.05846\tVal Loss: 0.2455\tAccuracy: 88.405797%\n",
      "Epoch 917\tTrain Loss: 0.05846\tVal Loss: 0.2453\tAccuracy: 88.405797%\n",
      "Epoch 918\tTrain Loss: 0.05852\tVal Loss: 0.2453\tAccuracy: 88.405797%\n",
      "Epoch 919\tTrain Loss: 0.0584\tVal Loss: 0.2452\tAccuracy: 88.405797%\n",
      "Epoch 920\tTrain Loss: 0.05839\tVal Loss: 0.2453\tAccuracy: 88.405797%\n",
      "Epoch 921\tTrain Loss: 0.0584\tVal Loss: 0.2453\tAccuracy: 88.405797%\n",
      "Epoch 922\tTrain Loss: 0.05829\tVal Loss: 0.2452\tAccuracy: 88.405797%\n",
      "Epoch 923\tTrain Loss: 0.05827\tVal Loss: 0.2452\tAccuracy: 88.405797%\n",
      "Epoch 924\tTrain Loss: 0.05834\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 925\tTrain Loss: 0.0582\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 926\tTrain Loss: 0.05821\tVal Loss: 0.2452\tAccuracy: 88.405797%\n",
      "Epoch 927\tTrain Loss: 0.05819\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 928\tTrain Loss: 0.0581\tVal Loss: 0.2453\tAccuracy: 88.405797%\n",
      "Epoch 929\tTrain Loss: 0.05812\tVal Loss: 0.2451\tAccuracy: 88.405797%\n",
      "Epoch 930\tTrain Loss: 0.05812\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 931\tTrain Loss: 0.05806\tVal Loss: 0.2451\tAccuracy: 88.405797%\n",
      "Epoch 932\tTrain Loss: 0.05808\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 933\tTrain Loss: 0.05799\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 934\tTrain Loss: 0.05792\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 935\tTrain Loss: 0.05797\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 936\tTrain Loss: 0.05785\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 937\tTrain Loss: 0.05793\tVal Loss: 0.2452\tAccuracy: 88.405797%\n",
      "Epoch 938\tTrain Loss: 0.05785\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 939\tTrain Loss: 0.05776\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 940\tTrain Loss: 0.05783\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 941\tTrain Loss: 0.05779\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 942\tTrain Loss: 0.05768\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 943\tTrain Loss: 0.05774\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 944\tTrain Loss: 0.05772\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 945\tTrain Loss: 0.05762\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 946\tTrain Loss: 0.05764\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 947\tTrain Loss: 0.05749\tVal Loss: 0.2447\tAccuracy: 88.405797%\n",
      "Epoch 948\tTrain Loss: 0.05757\tVal Loss: 0.2451\tAccuracy: 88.405797%\n",
      "Epoch 949\tTrain Loss: 0.05749\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 950\tTrain Loss: 0.05748\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 951\tTrain Loss: 0.05737\tVal Loss: 0.2447\tAccuracy: 88.405797%\n",
      "Epoch 952\tTrain Loss: 0.05743\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 953\tTrain Loss: 0.05735\tVal Loss: 0.2447\tAccuracy: 88.405797%\n",
      "Epoch 954\tTrain Loss: 0.05734\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 955\tTrain Loss: 0.05729\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 956\tTrain Loss: 0.05731\tVal Loss: 0.245\tAccuracy: 88.405797%\n",
      "Epoch 957\tTrain Loss: 0.05724\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 958\tTrain Loss: 0.05722\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 959\tTrain Loss: 0.05717\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 960\tTrain Loss: 0.0572\tVal Loss: 0.2449\tAccuracy: 88.405797%\n",
      "Epoch 961\tTrain Loss: 0.05707\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 962\tTrain Loss: 0.05712\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 963\tTrain Loss: 0.05705\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 964\tTrain Loss: 0.05696\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 965\tTrain Loss: 0.05704\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 966\tTrain Loss: 0.05698\tVal Loss: 0.2447\tAccuracy: 88.405797%\n",
      "Epoch 967\tTrain Loss: 0.05693\tVal Loss: 0.2447\tAccuracy: 88.405797%\n",
      "Epoch 968\tTrain Loss: 0.05691\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 969\tTrain Loss: 0.05691\tVal Loss: 0.2447\tAccuracy: 88.405797%\n",
      "Epoch 970\tTrain Loss: 0.05685\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 971\tTrain Loss: 0.05689\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 972\tTrain Loss: 0.05675\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 973\tTrain Loss: 0.05682\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 974\tTrain Loss: 0.05673\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 975\tTrain Loss: 0.0567\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 976\tTrain Loss: 0.05673\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 977\tTrain Loss: 0.05663\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 978\tTrain Loss: 0.05658\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 979\tTrain Loss: 0.05665\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 980\tTrain Loss: 0.05657\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 981\tTrain Loss: 0.05649\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 982\tTrain Loss: 0.05648\tVal Loss: 0.2443\tAccuracy: 88.405797%\n",
      "Epoch 983\tTrain Loss: 0.05648\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 984\tTrain Loss: 0.05646\tVal Loss: 0.2443\tAccuracy: 88.405797%\n",
      "Epoch 985\tTrain Loss: 0.05645\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 986\tTrain Loss: 0.05636\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 987\tTrain Loss: 0.05638\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 988\tTrain Loss: 0.05639\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 989\tTrain Loss: 0.05635\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 990\tTrain Loss: 0.05633\tVal Loss: 0.2443\tAccuracy: 88.405797%\n",
      "Epoch 991\tTrain Loss: 0.05624\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 992\tTrain Loss: 0.05624\tVal Loss: 0.2444\tAccuracy: 88.405797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993\tTrain Loss: 0.05628\tVal Loss: 0.2445\tAccuracy: 88.405797%\n",
      "Epoch 994\tTrain Loss: 0.0562\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 995\tTrain Loss: 0.05619\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 996\tTrain Loss: 0.05615\tVal Loss: 0.2443\tAccuracy: 88.405797%\n",
      "Epoch 997\tTrain Loss: 0.05613\tVal Loss: 0.2444\tAccuracy: 88.405797%\n",
      "Epoch 998\tTrain Loss: 0.05615\tVal Loss: 0.2446\tAccuracy: 88.405797%\n",
      "Epoch 999\tTrain Loss: 0.05605\tVal Loss: 0.2443\tAccuracy: 88.405797%\n",
      "Model saved to models/88.406_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=26, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(1000, model, loss_fcn, optimizer, train_res_dataloader, val_res_dataloader, logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163daf1",
   "metadata": {},
   "source": [
    "### This model doesn't have enough capacity to overfit. Let's create one that does and upgrade the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4451d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_model = nn.Sequential(\n",
    "    nn.Linear(input_neuron_count, input_neuron_count // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(input_neuron_count // 2, input_neuron_count // 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(input_neuron_count // 4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "567d09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = nn.BCEWithLogitsLoss()\n",
    "new_optim = optim.Adam(deeper_model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6138cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000\tTrain Loss: 0.5184\tVal Loss: 0.5617\tAccuracy: 56.521739%\n",
      "Epoch 001\tTrain Loss: 0.3043\tVal Loss: 0.3864\tAccuracy: 79.710145%\n",
      "Epoch 002\tTrain Loss: 0.2337\tVal Loss: 0.3391\tAccuracy: 83.574879%\n",
      "Epoch 003\tTrain Loss: 0.2331\tVal Loss: 0.3265\tAccuracy: 85.507246%\n",
      "Epoch 004\tTrain Loss: 0.234\tVal Loss: 0.3267\tAccuracy: 87.439614%\n",
      "Epoch 005\tTrain Loss: 0.2249\tVal Loss: 0.3216\tAccuracy: 87.922705%\n",
      "Epoch 006\tTrain Loss: 0.2171\tVal Loss: 0.316\tAccuracy: 88.405797%\n",
      "Epoch 007\tTrain Loss: 0.2131\tVal Loss: 0.312\tAccuracy: 87.922705%\n",
      "Epoch 008\tTrain Loss: 0.213\tVal Loss: 0.3092\tAccuracy: 87.922705%\n",
      "Epoch 009\tTrain Loss: 0.2055\tVal Loss: 0.307\tAccuracy: 87.922705%\n",
      "Epoch 010\tTrain Loss: 0.1979\tVal Loss: 0.3054\tAccuracy: 87.439614%\n",
      "Epoch 011\tTrain Loss: 0.1912\tVal Loss: 0.3036\tAccuracy: 86.956522%\n",
      "Epoch 012\tTrain Loss: 0.1818\tVal Loss: 0.3003\tAccuracy: 86.956522%\n",
      "Epoch 013\tTrain Loss: 0.1775\tVal Loss: 0.2959\tAccuracy: 86.956522%\n",
      "Epoch 014\tTrain Loss: 0.1685\tVal Loss: 0.2937\tAccuracy: 86.956522%\n",
      "Epoch 015\tTrain Loss: 0.1636\tVal Loss: 0.2929\tAccuracy: 86.473430%\n",
      "Epoch 016\tTrain Loss: 0.1583\tVal Loss: 0.2937\tAccuracy: 86.473430%\n",
      "Epoch 017\tTrain Loss: 0.1518\tVal Loss: 0.2937\tAccuracy: 86.473430%\n",
      "Epoch 018\tTrain Loss: 0.1518\tVal Loss: 0.2973\tAccuracy: 85.990338%\n",
      "Epoch 019\tTrain Loss: 0.1446\tVal Loss: 0.3007\tAccuracy: 85.507246%\n",
      "Epoch 020\tTrain Loss: 0.1398\tVal Loss: 0.3008\tAccuracy: 84.541063%\n",
      "Epoch 021\tTrain Loss: 0.1411\tVal Loss: 0.3\tAccuracy: 85.024155%\n",
      "Epoch 022\tTrain Loss: 0.1369\tVal Loss: 0.2958\tAccuracy: 85.024155%\n",
      "Epoch 023\tTrain Loss: 0.1379\tVal Loss: 0.2951\tAccuracy: 85.024155%\n",
      "Epoch 024\tTrain Loss: 0.1328\tVal Loss: 0.2904\tAccuracy: 85.024155%\n",
      "Epoch 025\tTrain Loss: 0.1303\tVal Loss: 0.2825\tAccuracy: 85.507246%\n",
      "Epoch 026\tTrain Loss: 0.1335\tVal Loss: 0.2761\tAccuracy: 87.439614%\n",
      "Epoch 027\tTrain Loss: 0.1308\tVal Loss: 0.2699\tAccuracy: 87.922705%\n",
      "Epoch 028\tTrain Loss: 0.1286\tVal Loss: 0.2663\tAccuracy: 87.922705%\n",
      "Epoch 029\tTrain Loss: 0.1306\tVal Loss: 0.2648\tAccuracy: 87.922705%\n",
      "Epoch 030\tTrain Loss: 0.1266\tVal Loss: 0.2621\tAccuracy: 87.922705%\n",
      "Epoch 031\tTrain Loss: 0.1242\tVal Loss: 0.2596\tAccuracy: 88.405797%\n",
      "Epoch 032\tTrain Loss: 0.1267\tVal Loss: 0.2588\tAccuracy: 87.922705%\n",
      "Epoch 033\tTrain Loss: 0.12\tVal Loss: 0.2591\tAccuracy: 88.405797%\n",
      "Epoch 034\tTrain Loss: 0.1188\tVal Loss: 0.2569\tAccuracy: 88.888889%\n",
      "Epoch 035\tTrain Loss: 0.1177\tVal Loss: 0.2562\tAccuracy: 88.405797%\n",
      "Epoch 036\tTrain Loss: 0.1205\tVal Loss: 0.257\tAccuracy: 88.405797%\n",
      "Epoch 037\tTrain Loss: 0.1124\tVal Loss: 0.2579\tAccuracy: 88.888889%\n",
      "Epoch 038\tTrain Loss: 0.1119\tVal Loss: 0.2556\tAccuracy: 88.888889%\n",
      "Epoch 039\tTrain Loss: 0.1134\tVal Loss: 0.2556\tAccuracy: 88.888889%\n",
      "Epoch 040\tTrain Loss: 0.1132\tVal Loss: 0.2556\tAccuracy: 88.888889%\n",
      "Epoch 041\tTrain Loss: 0.1111\tVal Loss: 0.2539\tAccuracy: 88.888889%\n",
      "Epoch 042\tTrain Loss: 0.1095\tVal Loss: 0.2533\tAccuracy: 88.888889%\n",
      "Epoch 043\tTrain Loss: 0.1086\tVal Loss: 0.2547\tAccuracy: 88.888889%\n",
      "Epoch 044\tTrain Loss: 0.1065\tVal Loss: 0.255\tAccuracy: 88.888889%\n",
      "Epoch 045\tTrain Loss: 0.1067\tVal Loss: 0.2528\tAccuracy: 88.888889%\n",
      "Epoch 046\tTrain Loss: 0.1053\tVal Loss: 0.2524\tAccuracy: 88.888889%\n",
      "Epoch 047\tTrain Loss: 0.1055\tVal Loss: 0.2535\tAccuracy: 88.888889%\n",
      "Epoch 048\tTrain Loss: 0.1012\tVal Loss: 0.2547\tAccuracy: 88.405797%\n",
      "Epoch 049\tTrain Loss: 0.1019\tVal Loss: 0.2521\tAccuracy: 88.405797%\n",
      "Epoch 050\tTrain Loss: 0.09999\tVal Loss: 0.252\tAccuracy: 88.405797%\n",
      "Epoch 051\tTrain Loss: 0.1017\tVal Loss: 0.254\tAccuracy: 87.922705%\n",
      "Epoch 052\tTrain Loss: 0.09638\tVal Loss: 0.2547\tAccuracy: 87.922705%\n",
      "Epoch 053\tTrain Loss: 0.09807\tVal Loss: 0.2535\tAccuracy: 88.888889%\n",
      "Epoch 054\tTrain Loss: 0.09619\tVal Loss: 0.2533\tAccuracy: 88.888889%\n",
      "Epoch 055\tTrain Loss: 0.09821\tVal Loss: 0.2553\tAccuracy: 89.371981%\n",
      "Epoch 056\tTrain Loss: 0.09181\tVal Loss: 0.2567\tAccuracy: 89.371981%\n",
      "Epoch 057\tTrain Loss: 0.09371\tVal Loss: 0.2544\tAccuracy: 88.888889%\n",
      "Epoch 058\tTrain Loss: 0.09206\tVal Loss: 0.2544\tAccuracy: 88.888889%\n",
      "Epoch 059\tTrain Loss: 0.09451\tVal Loss: 0.2568\tAccuracy: 88.405797%\n",
      "Epoch 060\tTrain Loss: 0.08694\tVal Loss: 0.2548\tAccuracy: 88.888889%\n",
      "Epoch 061\tTrain Loss: 0.104\tVal Loss: 0.2519\tAccuracy: 88.405797%\n",
      "Epoch 062\tTrain Loss: 0.08984\tVal Loss: 0.2576\tAccuracy: 87.922705%\n",
      "Epoch 063\tTrain Loss: 0.08855\tVal Loss: 0.2608\tAccuracy: 86.956522%\n",
      "Epoch 064\tTrain Loss: 0.08456\tVal Loss: 0.2608\tAccuracy: 86.956522%\n",
      "Epoch 065\tTrain Loss: 0.08679\tVal Loss: 0.2585\tAccuracy: 87.439614%\n",
      "Epoch 066\tTrain Loss: 0.08575\tVal Loss: 0.2553\tAccuracy: 87.439614%\n",
      "Epoch 067\tTrain Loss: 0.1005\tVal Loss: 0.2556\tAccuracy: 87.439614%\n",
      "Epoch 068\tTrain Loss: 0.08822\tVal Loss: 0.2591\tAccuracy: 87.439614%\n",
      "Epoch 069\tTrain Loss: 0.08651\tVal Loss: 0.256\tAccuracy: 88.405797%\n",
      "Epoch 070\tTrain Loss: 0.08714\tVal Loss: 0.2538\tAccuracy: 87.922705%\n",
      "Epoch 071\tTrain Loss: 0.08514\tVal Loss: 0.2516\tAccuracy: 88.888889%\n",
      "Epoch 072\tTrain Loss: 0.09648\tVal Loss: 0.2501\tAccuracy: 88.405797%\n",
      "Epoch 073\tTrain Loss: 0.08264\tVal Loss: 0.2537\tAccuracy: 88.405797%\n",
      "Epoch 074\tTrain Loss: 0.08248\tVal Loss: 0.2516\tAccuracy: 88.405797%\n",
      "Epoch 075\tTrain Loss: 0.09381\tVal Loss: 0.2503\tAccuracy: 88.405797%\n",
      "Epoch 076\tTrain Loss: 0.08378\tVal Loss: 0.2565\tAccuracy: 88.888889%\n",
      "Epoch 077\tTrain Loss: 0.07867\tVal Loss: 0.2532\tAccuracy: 87.439614%\n",
      "Epoch 078\tTrain Loss: 0.09756\tVal Loss: 0.2515\tAccuracy: 89.371981%\n",
      "Epoch 079\tTrain Loss: 0.08173\tVal Loss: 0.2566\tAccuracy: 88.405797%\n",
      "Epoch 080\tTrain Loss: 0.07595\tVal Loss: 0.255\tAccuracy: 87.922705%\n",
      "Epoch 081\tTrain Loss: 0.09141\tVal Loss: 0.255\tAccuracy: 88.888889%\n",
      "Epoch 082\tTrain Loss: 0.07711\tVal Loss: 0.261\tAccuracy: 87.922705%\n",
      "Epoch 083\tTrain Loss: 0.07615\tVal Loss: 0.2549\tAccuracy: 87.922705%\n",
      "Epoch 084\tTrain Loss: 0.09484\tVal Loss: 0.2547\tAccuracy: 88.888889%\n",
      "Epoch 085\tTrain Loss: 0.07922\tVal Loss: 0.2591\tAccuracy: 88.405797%\n",
      "Epoch 086\tTrain Loss: 0.07201\tVal Loss: 0.2562\tAccuracy: 88.888889%\n",
      "Epoch 087\tTrain Loss: 0.08846\tVal Loss: 0.255\tAccuracy: 88.405797%\n",
      "Epoch 088\tTrain Loss: 0.07455\tVal Loss: 0.2614\tAccuracy: 88.405797%\n",
      "Epoch 089\tTrain Loss: 0.07241\tVal Loss: 0.2582\tAccuracy: 88.405797%\n",
      "Epoch 090\tTrain Loss: 0.07558\tVal Loss: 0.2564\tAccuracy: 88.888889%\n",
      "Epoch 091\tTrain Loss: 0.0751\tVal Loss: 0.2527\tAccuracy: 88.405797%\n",
      "Epoch 092\tTrain Loss: 0.08596\tVal Loss: 0.253\tAccuracy: 89.371981%\n",
      "Epoch 093\tTrain Loss: 0.07384\tVal Loss: 0.2568\tAccuracy: 88.888889%\n",
      "Epoch 094\tTrain Loss: 0.07285\tVal Loss: 0.2529\tAccuracy: 88.888889%\n",
      "Epoch 095\tTrain Loss: 0.09052\tVal Loss: 0.2518\tAccuracy: 89.371981%\n",
      "Epoch 096\tTrain Loss: 0.06977\tVal Loss: 0.2592\tAccuracy: 87.922705%\n",
      "Epoch 097\tTrain Loss: 0.06865\tVal Loss: 0.2551\tAccuracy: 88.888889%\n",
      "Epoch 098\tTrain Loss: 0.08362\tVal Loss: 0.2545\tAccuracy: 87.922705%\n",
      "Epoch 099\tTrain Loss: 0.06946\tVal Loss: 0.2634\tAccuracy: 87.922705%\n",
      "Epoch 100\tTrain Loss: 0.06557\tVal Loss: 0.2563\tAccuracy: 88.405797%\n",
      "Epoch 101\tTrain Loss: 0.09139\tVal Loss: 0.2558\tAccuracy: 87.922705%\n",
      "Epoch 102\tTrain Loss: 0.06703\tVal Loss: 0.2638\tAccuracy: 87.439614%\n",
      "Epoch 103\tTrain Loss: 0.06374\tVal Loss: 0.2623\tAccuracy: 87.439614%\n",
      "Epoch 104\tTrain Loss: 0.07498\tVal Loss: 0.26\tAccuracy: 87.922705%\n",
      "Epoch 105\tTrain Loss: 0.06824\tVal Loss: 0.2645\tAccuracy: 87.922705%\n",
      "Epoch 106\tTrain Loss: 0.0658\tVal Loss: 0.2608\tAccuracy: 88.405797%\n",
      "Epoch 107\tTrain Loss: 0.07652\tVal Loss: 0.2599\tAccuracy: 87.439614%\n",
      "Epoch 108\tTrain Loss: 0.06601\tVal Loss: 0.2671\tAccuracy: 87.439614%\n",
      "Epoch 109\tTrain Loss: 0.06234\tVal Loss: 0.2593\tAccuracy: 87.922705%\n",
      "Epoch 110\tTrain Loss: 0.07957\tVal Loss: 0.2606\tAccuracy: 87.922705%\n",
      "Epoch 111\tTrain Loss: 0.06137\tVal Loss: 0.2651\tAccuracy: 87.439614%\n",
      "Epoch 112\tTrain Loss: 0.06415\tVal Loss: 0.2624\tAccuracy: 87.922705%\n",
      "Epoch 113\tTrain Loss: 0.06843\tVal Loss: 0.2614\tAccuracy: 87.922705%\n",
      "Epoch 114\tTrain Loss: 0.06647\tVal Loss: 0.2597\tAccuracy: 87.922705%\n",
      "Epoch 115\tTrain Loss: 0.07654\tVal Loss: 0.2604\tAccuracy: 87.439614%\n",
      "Epoch 116\tTrain Loss: 0.0641\tVal Loss: 0.2644\tAccuracy: 87.922705%\n",
      "Epoch 117\tTrain Loss: 0.06568\tVal Loss: 0.2561\tAccuracy: 88.405797%\n",
      "Epoch 118\tTrain Loss: 0.08119\tVal Loss: 0.2547\tAccuracy: 88.888889%\n",
      "Epoch 119\tTrain Loss: 0.0597\tVal Loss: 0.258\tAccuracy: 87.922705%\n",
      "Epoch 120\tTrain Loss: 0.07561\tVal Loss: 0.2545\tAccuracy: 88.405797%\n",
      "Epoch 121\tTrain Loss: 0.06126\tVal Loss: 0.2603\tAccuracy: 87.439614%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122\tTrain Loss: 0.06411\tVal Loss: 0.2521\tAccuracy: 88.405797%\n",
      "Epoch 123\tTrain Loss: 0.08407\tVal Loss: 0.249\tAccuracy: 88.888889%\n",
      "Epoch 124\tTrain Loss: 0.05844\tVal Loss: 0.2607\tAccuracy: 87.922705%\n",
      "Epoch 125\tTrain Loss: 0.06133\tVal Loss: 0.2502\tAccuracy: 88.888889%\n",
      "Epoch 126\tTrain Loss: 0.07938\tVal Loss: 0.2503\tAccuracy: 88.405797%\n",
      "Epoch 127\tTrain Loss: 0.05837\tVal Loss: 0.2538\tAccuracy: 88.405797%\n",
      "Epoch 128\tTrain Loss: 0.07603\tVal Loss: 0.2494\tAccuracy: 88.888889%\n",
      "Epoch 129\tTrain Loss: 0.0608\tVal Loss: 0.2545\tAccuracy: 88.405797%\n",
      "Epoch 130\tTrain Loss: 0.06327\tVal Loss: 0.2479\tAccuracy: 88.888889%\n",
      "Epoch 131\tTrain Loss: 0.08164\tVal Loss: 0.2448\tAccuracy: 88.405797%\n",
      "Epoch 132\tTrain Loss: 0.05973\tVal Loss: 0.2512\tAccuracy: 87.922705%\n",
      "Epoch 133\tTrain Loss: 0.0668\tVal Loss: 0.248\tAccuracy: 88.888889%\n",
      "Epoch 134\tTrain Loss: 0.05934\tVal Loss: 0.2499\tAccuracy: 88.405797%\n",
      "Epoch 135\tTrain Loss: 0.0728\tVal Loss: 0.248\tAccuracy: 88.888889%\n",
      "Epoch 136\tTrain Loss: 0.05885\tVal Loss: 0.2515\tAccuracy: 88.405797%\n",
      "Epoch 137\tTrain Loss: 0.07103\tVal Loss: 0.2491\tAccuracy: 88.888889%\n",
      "Epoch 138\tTrain Loss: 0.05611\tVal Loss: 0.256\tAccuracy: 88.405797%\n",
      "Epoch 139\tTrain Loss: 0.06371\tVal Loss: 0.2551\tAccuracy: 88.405797%\n",
      "Epoch 140\tTrain Loss: 0.05785\tVal Loss: 0.2566\tAccuracy: 88.405797%\n",
      "Epoch 141\tTrain Loss: 0.06273\tVal Loss: 0.2562\tAccuracy: 88.888889%\n",
      "Epoch 142\tTrain Loss: 0.0598\tVal Loss: 0.2571\tAccuracy: 88.405797%\n",
      "Epoch 143\tTrain Loss: 0.06414\tVal Loss: 0.2591\tAccuracy: 87.922705%\n",
      "Epoch 144\tTrain Loss: 0.05861\tVal Loss: 0.2662\tAccuracy: 86.956522%\n",
      "Epoch 145\tTrain Loss: 0.06299\tVal Loss: 0.2696\tAccuracy: 85.507246%\n",
      "Epoch 146\tTrain Loss: 0.05434\tVal Loss: 0.2688\tAccuracy: 86.956522%\n",
      "Epoch 147\tTrain Loss: 0.06483\tVal Loss: 0.2652\tAccuracy: 86.473430%\n",
      "Epoch 148\tTrain Loss: 0.05712\tVal Loss: 0.2677\tAccuracy: 86.956522%\n",
      "Epoch 149\tTrain Loss: 0.05947\tVal Loss: 0.2592\tAccuracy: 88.405797%\n",
      "Epoch 150\tTrain Loss: 0.06825\tVal Loss: 0.2634\tAccuracy: 86.956522%\n",
      "Epoch 151\tTrain Loss: 0.05262\tVal Loss: 0.2669\tAccuracy: 86.956522%\n",
      "Epoch 152\tTrain Loss: 0.06259\tVal Loss: 0.2586\tAccuracy: 87.922705%\n",
      "Epoch 153\tTrain Loss: 0.0563\tVal Loss: 0.2608\tAccuracy: 87.922705%\n",
      "Epoch 154\tTrain Loss: 0.06102\tVal Loss: 0.2516\tAccuracy: 88.405797%\n",
      "Epoch 155\tTrain Loss: 0.07312\tVal Loss: 0.2513\tAccuracy: 88.405797%\n",
      "Epoch 156\tTrain Loss: 0.05496\tVal Loss: 0.2553\tAccuracy: 88.405797%\n",
      "Epoch 157\tTrain Loss: 0.05954\tVal Loss: 0.2503\tAccuracy: 89.371981%\n",
      "Epoch 158\tTrain Loss: 0.05685\tVal Loss: 0.2508\tAccuracy: 88.888889%\n",
      "Epoch 159\tTrain Loss: 0.06183\tVal Loss: 0.2475\tAccuracy: 88.888889%\n",
      "Epoch 160\tTrain Loss: 0.05676\tVal Loss: 0.2501\tAccuracy: 88.888889%\n",
      "Epoch 161\tTrain Loss: 0.05965\tVal Loss: 0.2454\tAccuracy: 88.888889%\n",
      "Epoch 162\tTrain Loss: 0.0569\tVal Loss: 0.2508\tAccuracy: 88.888889%\n",
      "Epoch 163\tTrain Loss: 0.05756\tVal Loss: 0.2458\tAccuracy: 88.888889%\n",
      "Epoch 164\tTrain Loss: 0.06448\tVal Loss: 0.2526\tAccuracy: 88.405797%\n",
      "Epoch 165\tTrain Loss: 0.05116\tVal Loss: 0.2586\tAccuracy: 88.405797%\n",
      "Epoch 166\tTrain Loss: 0.05673\tVal Loss: 0.2542\tAccuracy: 88.888889%\n",
      "Epoch 167\tTrain Loss: 0.05265\tVal Loss: 0.261\tAccuracy: 87.439614%\n",
      "Epoch 168\tTrain Loss: 0.0549\tVal Loss: 0.2607\tAccuracy: 87.922705%\n",
      "Epoch 169\tTrain Loss: 0.05618\tVal Loss: 0.2619\tAccuracy: 87.439614%\n",
      "Epoch 170\tTrain Loss: 0.05409\tVal Loss: 0.2659\tAccuracy: 87.439614%\n",
      "Epoch 171\tTrain Loss: 0.05588\tVal Loss: 0.2575\tAccuracy: 88.405797%\n",
      "Epoch 172\tTrain Loss: 0.06083\tVal Loss: 0.2653\tAccuracy: 86.956522%\n",
      "Epoch 173\tTrain Loss: 0.04765\tVal Loss: 0.2711\tAccuracy: 85.990338%\n",
      "Epoch 174\tTrain Loss: 0.05388\tVal Loss: 0.2663\tAccuracy: 86.956522%\n",
      "Epoch 175\tTrain Loss: 0.04924\tVal Loss: 0.2693\tAccuracy: 86.956522%\n",
      "Epoch 176\tTrain Loss: 0.05603\tVal Loss: 0.2652\tAccuracy: 87.439614%\n",
      "Epoch 177\tTrain Loss: 0.05075\tVal Loss: 0.2679\tAccuracy: 86.473430%\n",
      "Epoch 178\tTrain Loss: 0.05258\tVal Loss: 0.2646\tAccuracy: 87.439614%\n",
      "Epoch 179\tTrain Loss: 0.04942\tVal Loss: 0.2684\tAccuracy: 86.473430%\n",
      "Epoch 180\tTrain Loss: 0.05209\tVal Loss: 0.2663\tAccuracy: 87.439614%\n",
      "Epoch 181\tTrain Loss: 0.04992\tVal Loss: 0.2686\tAccuracy: 86.956522%\n",
      "Epoch 182\tTrain Loss: 0.05607\tVal Loss: 0.2643\tAccuracy: 87.439614%\n",
      "Epoch 183\tTrain Loss: 0.05012\tVal Loss: 0.268\tAccuracy: 87.439614%\n",
      "Epoch 184\tTrain Loss: 0.05233\tVal Loss: 0.2624\tAccuracy: 88.405797%\n",
      "Epoch 185\tTrain Loss: 0.04926\tVal Loss: 0.2672\tAccuracy: 87.439614%\n",
      "Epoch 186\tTrain Loss: 0.05337\tVal Loss: 0.2656\tAccuracy: 86.473430%\n",
      "Epoch 187\tTrain Loss: 0.0512\tVal Loss: 0.2694\tAccuracy: 86.473430%\n",
      "Epoch 188\tTrain Loss: 0.05158\tVal Loss: 0.2715\tAccuracy: 86.473430%\n",
      "Epoch 189\tTrain Loss: 0.05265\tVal Loss: 0.2603\tAccuracy: 88.405797%\n",
      "Epoch 190\tTrain Loss: 0.05843\tVal Loss: 0.2664\tAccuracy: 87.439614%\n",
      "Epoch 191\tTrain Loss: 0.04631\tVal Loss: 0.2709\tAccuracy: 86.473430%\n",
      "Epoch 192\tTrain Loss: 0.05167\tVal Loss: 0.263\tAccuracy: 88.405797%\n",
      "Epoch 193\tTrain Loss: 0.05242\tVal Loss: 0.2702\tAccuracy: 86.473430%\n",
      "Epoch 194\tTrain Loss: 0.05048\tVal Loss: 0.27\tAccuracy: 86.473430%\n",
      "Epoch 195\tTrain Loss: 0.05318\tVal Loss: 0.2601\tAccuracy: 88.405797%\n",
      "Epoch 196\tTrain Loss: 0.05779\tVal Loss: 0.2642\tAccuracy: 87.922705%\n",
      "Epoch 197\tTrain Loss: 0.04628\tVal Loss: 0.2694\tAccuracy: 86.473430%\n",
      "Epoch 198\tTrain Loss: 0.05038\tVal Loss: 0.2599\tAccuracy: 88.888889%\n",
      "Epoch 199\tTrain Loss: 0.04843\tVal Loss: 0.2685\tAccuracy: 86.956522%\n",
      "Epoch 200\tTrain Loss: 0.0495\tVal Loss: 0.263\tAccuracy: 88.888889%\n",
      "Epoch 201\tTrain Loss: 0.04796\tVal Loss: 0.2687\tAccuracy: 86.956522%\n",
      "Epoch 202\tTrain Loss: 0.05327\tVal Loss: 0.2616\tAccuracy: 88.888889%\n",
      "Epoch 203\tTrain Loss: 0.0488\tVal Loss: 0.2669\tAccuracy: 86.956522%\n",
      "Epoch 204\tTrain Loss: 0.04987\tVal Loss: 0.2575\tAccuracy: 88.405797%\n",
      "Epoch 205\tTrain Loss: 0.05929\tVal Loss: 0.2638\tAccuracy: 87.922705%\n",
      "Epoch 206\tTrain Loss: 0.04484\tVal Loss: 0.2708\tAccuracy: 86.473430%\n",
      "Epoch 207\tTrain Loss: 0.04806\tVal Loss: 0.2594\tAccuracy: 88.405797%\n",
      "Epoch 208\tTrain Loss: 0.05891\tVal Loss: 0.2658\tAccuracy: 86.956522%\n",
      "Epoch 209\tTrain Loss: 0.0442\tVal Loss: 0.2737\tAccuracy: 86.473430%\n",
      "Epoch 210\tTrain Loss: 0.04825\tVal Loss: 0.2634\tAccuracy: 88.405797%\n",
      "Epoch 211\tTrain Loss: 0.05029\tVal Loss: 0.2719\tAccuracy: 85.990338%\n",
      "Epoch 212\tTrain Loss: 0.04776\tVal Loss: 0.2716\tAccuracy: 86.473430%\n",
      "Epoch 213\tTrain Loss: 0.04996\tVal Loss: 0.2613\tAccuracy: 88.405797%\n",
      "Epoch 214\tTrain Loss: 0.05283\tVal Loss: 0.2668\tAccuracy: 86.956522%\n",
      "Epoch 215\tTrain Loss: 0.04587\tVal Loss: 0.2694\tAccuracy: 86.956522%\n",
      "Epoch 216\tTrain Loss: 0.04894\tVal Loss: 0.26\tAccuracy: 88.405797%\n",
      "Epoch 217\tTrain Loss: 0.05436\tVal Loss: 0.2642\tAccuracy: 88.405797%\n",
      "Epoch 218\tTrain Loss: 0.04486\tVal Loss: 0.2699\tAccuracy: 86.473430%\n",
      "Epoch 219\tTrain Loss: 0.04745\tVal Loss: 0.2598\tAccuracy: 88.405797%\n",
      "Epoch 220\tTrain Loss: 0.05481\tVal Loss: 0.2658\tAccuracy: 87.922705%\n",
      "Epoch 221\tTrain Loss: 0.04485\tVal Loss: 0.2688\tAccuracy: 86.473430%\n",
      "Epoch 222\tTrain Loss: 0.04976\tVal Loss: 0.2585\tAccuracy: 88.405797%\n",
      "Epoch 223\tTrain Loss: 0.06068\tVal Loss: 0.2616\tAccuracy: 88.405797%\n",
      "Epoch 224\tTrain Loss: 0.04373\tVal Loss: 0.2694\tAccuracy: 86.473430%\n",
      "Epoch 225\tTrain Loss: 0.04831\tVal Loss: 0.2558\tAccuracy: 89.371981%\n",
      "Epoch 226\tTrain Loss: 0.0546\tVal Loss: 0.2604\tAccuracy: 88.405797%\n",
      "Epoch 227\tTrain Loss: 0.04452\tVal Loss: 0.2662\tAccuracy: 87.439614%\n",
      "Epoch 228\tTrain Loss: 0.04928\tVal Loss: 0.2559\tAccuracy: 88.888889%\n",
      "Epoch 229\tTrain Loss: 0.05244\tVal Loss: 0.2625\tAccuracy: 88.405797%\n",
      "Epoch 230\tTrain Loss: 0.04387\tVal Loss: 0.2667\tAccuracy: 86.956522%\n",
      "Epoch 231\tTrain Loss: 0.04844\tVal Loss: 0.2607\tAccuracy: 88.888889%\n",
      "Epoch 232\tTrain Loss: 0.04605\tVal Loss: 0.2627\tAccuracy: 88.405797%\n",
      "Epoch 233\tTrain Loss: 0.04893\tVal Loss: 0.2607\tAccuracy: 88.405797%\n",
      "Epoch 234\tTrain Loss: 0.05241\tVal Loss: 0.2612\tAccuracy: 89.371981%\n",
      "Epoch 235\tTrain Loss: 0.0446\tVal Loss: 0.2674\tAccuracy: 86.473430%\n",
      "Epoch 236\tTrain Loss: 0.04775\tVal Loss: 0.2571\tAccuracy: 89.371981%\n",
      "Epoch 237\tTrain Loss: 0.05026\tVal Loss: 0.2635\tAccuracy: 88.405797%\n",
      "Epoch 238\tTrain Loss: 0.04369\tVal Loss: 0.2663\tAccuracy: 86.956522%\n",
      "Epoch 239\tTrain Loss: 0.04769\tVal Loss: 0.2584\tAccuracy: 89.371981%\n",
      "Epoch 240\tTrain Loss: 0.04986\tVal Loss: 0.2622\tAccuracy: 88.888889%\n",
      "Epoch 241\tTrain Loss: 0.04426\tVal Loss: 0.2663\tAccuracy: 87.922705%\n",
      "Epoch 242\tTrain Loss: 0.04839\tVal Loss: 0.2564\tAccuracy: 89.371981%\n",
      "Epoch 243\tTrain Loss: 0.0535\tVal Loss: 0.2603\tAccuracy: 88.888889%\n",
      "Epoch 244\tTrain Loss: 0.04443\tVal Loss: 0.2669\tAccuracy: 87.439614%\n",
      "Epoch 245\tTrain Loss: 0.04753\tVal Loss: 0.2545\tAccuracy: 89.371981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246\tTrain Loss: 0.04849\tVal Loss: 0.26\tAccuracy: 88.405797%\n",
      "Epoch 247\tTrain Loss: 0.04483\tVal Loss: 0.2643\tAccuracy: 87.922705%\n",
      "Epoch 248\tTrain Loss: 0.04713\tVal Loss: 0.256\tAccuracy: 89.371981%\n",
      "Epoch 249\tTrain Loss: 0.04666\tVal Loss: 0.2575\tAccuracy: 88.405797%\n",
      "Epoch 250\tTrain Loss: 0.04551\tVal Loss: 0.2575\tAccuracy: 88.405797%\n",
      "Epoch 251\tTrain Loss: 0.04655\tVal Loss: 0.259\tAccuracy: 89.371981%\n",
      "Epoch 252\tTrain Loss: 0.04339\tVal Loss: 0.2633\tAccuracy: 88.888889%\n",
      "Epoch 253\tTrain Loss: 0.04682\tVal Loss: 0.2548\tAccuracy: 88.405797%\n",
      "Epoch 254\tTrain Loss: 0.04747\tVal Loss: 0.2597\tAccuracy: 88.405797%\n",
      "Epoch 255\tTrain Loss: 0.0441\tVal Loss: 0.2639\tAccuracy: 88.405797%\n",
      "Epoch 256\tTrain Loss: 0.04668\tVal Loss: 0.2567\tAccuracy: 89.371981%\n",
      "Epoch 257\tTrain Loss: 0.04825\tVal Loss: 0.2591\tAccuracy: 88.405797%\n",
      "Epoch 258\tTrain Loss: 0.04355\tVal Loss: 0.2662\tAccuracy: 87.922705%\n",
      "Epoch 259\tTrain Loss: 0.04733\tVal Loss: 0.2566\tAccuracy: 89.371981%\n",
      "Epoch 260\tTrain Loss: 0.04602\tVal Loss: 0.259\tAccuracy: 88.405797%\n",
      "Epoch 261\tTrain Loss: 0.04482\tVal Loss: 0.2598\tAccuracy: 88.405797%\n",
      "Epoch 262\tTrain Loss: 0.04459\tVal Loss: 0.2604\tAccuracy: 89.371981%\n",
      "Epoch 263\tTrain Loss: 0.04348\tVal Loss: 0.2663\tAccuracy: 87.922705%\n",
      "Epoch 264\tTrain Loss: 0.04547\tVal Loss: 0.2573\tAccuracy: 89.371981%\n",
      "Epoch 265\tTrain Loss: 0.04554\tVal Loss: 0.2592\tAccuracy: 88.405797%\n",
      "Epoch 266\tTrain Loss: 0.04389\tVal Loss: 0.26\tAccuracy: 88.405797%\n",
      "Epoch 267\tTrain Loss: 0.04547\tVal Loss: 0.2609\tAccuracy: 89.371981%\n",
      "Epoch 268\tTrain Loss: 0.04299\tVal Loss: 0.2673\tAccuracy: 87.922705%\n",
      "Epoch 269\tTrain Loss: 0.04495\tVal Loss: 0.2577\tAccuracy: 89.371981%\n",
      "Epoch 270\tTrain Loss: 0.0455\tVal Loss: 0.2618\tAccuracy: 88.405797%\n",
      "Epoch 271\tTrain Loss: 0.04384\tVal Loss: 0.2625\tAccuracy: 89.371981%\n",
      "Epoch 272\tTrain Loss: 0.04304\tVal Loss: 0.2661\tAccuracy: 87.922705%\n",
      "Epoch 273\tTrain Loss: 0.04531\tVal Loss: 0.2585\tAccuracy: 89.371981%\n",
      "Epoch 274\tTrain Loss: 0.04516\tVal Loss: 0.2617\tAccuracy: 88.405797%\n",
      "Epoch 275\tTrain Loss: 0.04346\tVal Loss: 0.2617\tAccuracy: 88.405797%\n",
      "Epoch 276\tTrain Loss: 0.04352\tVal Loss: 0.2589\tAccuracy: 88.405797%\n",
      "Epoch 277\tTrain Loss: 0.04618\tVal Loss: 0.2615\tAccuracy: 88.888889%\n",
      "Epoch 278\tTrain Loss: 0.04238\tVal Loss: 0.2678\tAccuracy: 87.439614%\n",
      "Epoch 279\tTrain Loss: 0.04429\tVal Loss: 0.2575\tAccuracy: 88.888889%\n",
      "Epoch 280\tTrain Loss: 0.0453\tVal Loss: 0.2588\tAccuracy: 88.405797%\n",
      "Epoch 281\tTrain Loss: 0.04381\tVal Loss: 0.26\tAccuracy: 88.405797%\n",
      "Epoch 282\tTrain Loss: 0.04319\tVal Loss: 0.2574\tAccuracy: 88.405797%\n",
      "Epoch 283\tTrain Loss: 0.04482\tVal Loss: 0.2602\tAccuracy: 88.405797%\n",
      "Epoch 284\tTrain Loss: 0.04271\tVal Loss: 0.2632\tAccuracy: 88.405797%\n",
      "Epoch 285\tTrain Loss: 0.04457\tVal Loss: 0.2585\tAccuracy: 88.405797%\n",
      "Epoch 286\tTrain Loss: 0.04404\tVal Loss: 0.2598\tAccuracy: 88.888889%\n",
      "Epoch 287\tTrain Loss: 0.04292\tVal Loss: 0.2663\tAccuracy: 87.439614%\n",
      "Epoch 288\tTrain Loss: 0.04504\tVal Loss: 0.2568\tAccuracy: 88.888889%\n",
      "Epoch 289\tTrain Loss: 0.04491\tVal Loss: 0.2591\tAccuracy: 88.405797%\n",
      "Epoch 290\tTrain Loss: 0.04279\tVal Loss: 0.2581\tAccuracy: 88.405797%\n",
      "Epoch 291\tTrain Loss: 0.04314\tVal Loss: 0.2565\tAccuracy: 88.405797%\n",
      "Epoch 292\tTrain Loss: 0.04394\tVal Loss: 0.2591\tAccuracy: 88.405797%\n",
      "Epoch 293\tTrain Loss: 0.04241\tVal Loss: 0.2641\tAccuracy: 87.922705%\n",
      "Epoch 294\tTrain Loss: 0.04465\tVal Loss: 0.2554\tAccuracy: 88.888889%\n",
      "Epoch 295\tTrain Loss: 0.04433\tVal Loss: 0.2599\tAccuracy: 88.405797%\n",
      "Epoch 296\tTrain Loss: 0.04249\tVal Loss: 0.265\tAccuracy: 87.922705%\n",
      "Epoch 297\tTrain Loss: 0.04644\tVal Loss: 0.2542\tAccuracy: 88.405797%\n",
      "Epoch 298\tTrain Loss: 0.04428\tVal Loss: 0.2584\tAccuracy: 88.405797%\n",
      "Epoch 299\tTrain Loss: 0.04362\tVal Loss: 0.2553\tAccuracy: 88.405797%\n",
      "Epoch 300\tTrain Loss: 0.04341\tVal Loss: 0.2563\tAccuracy: 88.405797%\n",
      "Epoch 301\tTrain Loss: 0.0529\tVal Loss: 0.2535\tAccuracy: 88.405797%\n",
      "Epoch 302\tTrain Loss: 0.04154\tVal Loss: 0.2637\tAccuracy: 87.922705%\n",
      "Epoch 303\tTrain Loss: 0.04595\tVal Loss: 0.2534\tAccuracy: 89.855072%\n",
      "Epoch 304\tTrain Loss: 0.04512\tVal Loss: 0.2558\tAccuracy: 88.888889%\n",
      "Epoch 305\tTrain Loss: 0.04451\tVal Loss: 0.259\tAccuracy: 88.405797%\n",
      "Epoch 306\tTrain Loss: 0.04675\tVal Loss: 0.2531\tAccuracy: 89.371981%\n",
      "Epoch 307\tTrain Loss: 0.04681\tVal Loss: 0.2519\tAccuracy: 89.371981%\n",
      "Epoch 308\tTrain Loss: 0.04511\tVal Loss: 0.259\tAccuracy: 89.371981%\n",
      "Epoch 309\tTrain Loss: 0.04839\tVal Loss: 0.2535\tAccuracy: 90.338164%\n",
      "Epoch 310\tTrain Loss: 0.04661\tVal Loss: 0.2549\tAccuracy: 91.304348%\n",
      "Epoch 311\tTrain Loss: 0.0471\tVal Loss: 0.2566\tAccuracy: 91.304348%\n",
      "Epoch 312\tTrain Loss: 0.0468\tVal Loss: 0.2576\tAccuracy: 90.338164%\n",
      "Epoch 313\tTrain Loss: 0.05566\tVal Loss: 0.2577\tAccuracy: 90.821256%\n",
      "Epoch 314\tTrain Loss: 0.0446\tVal Loss: 0.2678\tAccuracy: 89.855072%\n",
      "Epoch 315\tTrain Loss: 0.05208\tVal Loss: 0.2595\tAccuracy: 90.821256%\n",
      "Epoch 316\tTrain Loss: 0.04962\tVal Loss: 0.2588\tAccuracy: 89.855072%\n",
      "Epoch 317\tTrain Loss: 0.04972\tVal Loss: 0.2585\tAccuracy: 90.821256%\n",
      "Epoch 318\tTrain Loss: 0.04679\tVal Loss: 0.2567\tAccuracy: 89.855072%\n",
      "Epoch 319\tTrain Loss: 0.04674\tVal Loss: 0.2563\tAccuracy: 90.821256%\n",
      "Epoch 320\tTrain Loss: 0.04449\tVal Loss: 0.2543\tAccuracy: 90.338164%\n",
      "Epoch 321\tTrain Loss: 0.04356\tVal Loss: 0.2605\tAccuracy: 90.338164%\n",
      "Epoch 322\tTrain Loss: 0.04615\tVal Loss: 0.2564\tAccuracy: 89.855072%\n",
      "Epoch 323\tTrain Loss: 0.04616\tVal Loss: 0.256\tAccuracy: 90.821256%\n",
      "Epoch 324\tTrain Loss: 0.04549\tVal Loss: 0.2562\tAccuracy: 91.304348%\n",
      "Epoch 325\tTrain Loss: 0.045\tVal Loss: 0.256\tAccuracy: 90.821256%\n",
      "Epoch 326\tTrain Loss: 0.04408\tVal Loss: 0.2569\tAccuracy: 90.821256%\n",
      "Epoch 327\tTrain Loss: 0.04349\tVal Loss: 0.2574\tAccuracy: 90.821256%\n",
      "Epoch 328\tTrain Loss: 0.0453\tVal Loss: 0.2556\tAccuracy: 89.855072%\n",
      "Epoch 329\tTrain Loss: 0.04156\tVal Loss: 0.2627\tAccuracy: 89.371981%\n",
      "Epoch 330\tTrain Loss: 0.04449\tVal Loss: 0.2572\tAccuracy: 89.371981%\n",
      "Epoch 331\tTrain Loss: 0.04309\tVal Loss: 0.2568\tAccuracy: 87.922705%\n",
      "Epoch 332\tTrain Loss: 0.04258\tVal Loss: 0.2577\tAccuracy: 87.922705%\n",
      "Epoch 333\tTrain Loss: 0.04365\tVal Loss: 0.2618\tAccuracy: 88.888889%\n",
      "Epoch 334\tTrain Loss: 0.03923\tVal Loss: 0.2693\tAccuracy: 87.922705%\n",
      "Epoch 335\tTrain Loss: 0.04178\tVal Loss: 0.2613\tAccuracy: 88.405797%\n",
      "Epoch 336\tTrain Loss: 0.04873\tVal Loss: 0.2676\tAccuracy: 87.439614%\n",
      "Epoch 337\tTrain Loss: 0.03892\tVal Loss: 0.2761\tAccuracy: 85.990338%\n",
      "Epoch 338\tTrain Loss: 0.04197\tVal Loss: 0.2596\tAccuracy: 89.371981%\n",
      "Epoch 339\tTrain Loss: 0.04149\tVal Loss: 0.2656\tAccuracy: 87.922705%\n",
      "Epoch 340\tTrain Loss: 0.04041\tVal Loss: 0.2642\tAccuracy: 88.888889%\n",
      "Epoch 341\tTrain Loss: 0.03977\tVal Loss: 0.27\tAccuracy: 86.956522%\n",
      "Epoch 342\tTrain Loss: 0.04142\tVal Loss: 0.2606\tAccuracy: 88.405797%\n",
      "Epoch 343\tTrain Loss: 0.0413\tVal Loss: 0.2632\tAccuracy: 87.922705%\n",
      "Epoch 344\tTrain Loss: 0.03984\tVal Loss: 0.2638\tAccuracy: 87.922705%\n",
      "Epoch 345\tTrain Loss: 0.03988\tVal Loss: 0.2618\tAccuracy: 87.922705%\n",
      "Epoch 346\tTrain Loss: 0.04077\tVal Loss: 0.2634\tAccuracy: 88.405797%\n",
      "Epoch 347\tTrain Loss: 0.03872\tVal Loss: 0.2683\tAccuracy: 86.956522%\n",
      "Epoch 348\tTrain Loss: 0.0414\tVal Loss: 0.2591\tAccuracy: 88.405797%\n",
      "Epoch 349\tTrain Loss: 0.0404\tVal Loss: 0.2617\tAccuracy: 87.922705%\n",
      "Epoch 350\tTrain Loss: 0.03962\tVal Loss: 0.2639\tAccuracy: 87.439614%\n",
      "Epoch 351\tTrain Loss: 0.04004\tVal Loss: 0.2589\tAccuracy: 87.922705%\n",
      "Epoch 352\tTrain Loss: 0.042\tVal Loss: 0.2648\tAccuracy: 87.922705%\n",
      "Epoch 353\tTrain Loss: 0.03829\tVal Loss: 0.2694\tAccuracy: 86.956522%\n",
      "Epoch 354\tTrain Loss: 0.04147\tVal Loss: 0.2587\tAccuracy: 88.405797%\n",
      "Epoch 355\tTrain Loss: 0.04036\tVal Loss: 0.2596\tAccuracy: 87.922705%\n",
      "Epoch 356\tTrain Loss: 0.0398\tVal Loss: 0.2624\tAccuracy: 87.922705%\n",
      "Epoch 357\tTrain Loss: 0.04091\tVal Loss: 0.2622\tAccuracy: 88.405797%\n",
      "Epoch 358\tTrain Loss: 0.03817\tVal Loss: 0.267\tAccuracy: 86.956522%\n",
      "Epoch 359\tTrain Loss: 0.04159\tVal Loss: 0.2569\tAccuracy: 88.888889%\n",
      "Epoch 360\tTrain Loss: 0.04064\tVal Loss: 0.2609\tAccuracy: 87.922705%\n",
      "Epoch 361\tTrain Loss: 0.0403\tVal Loss: 0.2622\tAccuracy: 88.405797%\n",
      "Epoch 362\tTrain Loss: 0.03902\tVal Loss: 0.2652\tAccuracy: 86.956522%\n",
      "Epoch 363\tTrain Loss: 0.04191\tVal Loss: 0.255\tAccuracy: 88.888889%\n",
      "Epoch 364\tTrain Loss: 0.04097\tVal Loss: 0.258\tAccuracy: 87.922705%\n",
      "Epoch 365\tTrain Loss: 0.04015\tVal Loss: 0.257\tAccuracy: 88.405797%\n",
      "Epoch 366\tTrain Loss: 0.04093\tVal Loss: 0.2526\tAccuracy: 87.922705%\n",
      "Epoch 367\tTrain Loss: 0.04084\tVal Loss: 0.2536\tAccuracy: 88.888889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368\tTrain Loss: 0.04\tVal Loss: 0.2542\tAccuracy: 87.922705%\n",
      "Epoch 369\tTrain Loss: 0.04128\tVal Loss: 0.2587\tAccuracy: 87.922705%\n",
      "Epoch 370\tTrain Loss: 0.04315\tVal Loss: 0.2515\tAccuracy: 89.371981%\n",
      "Epoch 371\tTrain Loss: 0.04478\tVal Loss: 0.251\tAccuracy: 88.405797%\n",
      "Epoch 372\tTrain Loss: 0.04066\tVal Loss: 0.2602\tAccuracy: 87.922705%\n",
      "Epoch 373\tTrain Loss: 0.04378\tVal Loss: 0.2497\tAccuracy: 88.888889%\n",
      "Epoch 374\tTrain Loss: 0.0432\tVal Loss: 0.2518\tAccuracy: 88.888889%\n",
      "Epoch 375\tTrain Loss: 0.04275\tVal Loss: 0.2506\tAccuracy: 89.371981%\n",
      "Epoch 376\tTrain Loss: 0.04478\tVal Loss: 0.2488\tAccuracy: 89.371981%\n",
      "Epoch 377\tTrain Loss: 0.04201\tVal Loss: 0.2546\tAccuracy: 88.888889%\n",
      "Epoch 378\tTrain Loss: 0.04547\tVal Loss: 0.2504\tAccuracy: 90.338164%\n",
      "Epoch 379\tTrain Loss: 0.04437\tVal Loss: 0.2513\tAccuracy: 91.304348%\n",
      "Epoch 380\tTrain Loss: 0.0461\tVal Loss: 0.2525\tAccuracy: 91.304348%\n",
      "Epoch 381\tTrain Loss: 0.0438\tVal Loss: 0.2585\tAccuracy: 89.855072%\n",
      "Epoch 382\tTrain Loss: 0.04824\tVal Loss: 0.2596\tAccuracy: 90.821256%\n",
      "Epoch 383\tTrain Loss: 0.04724\tVal Loss: 0.2576\tAccuracy: 90.821256%\n",
      "Epoch 384\tTrain Loss: 0.04886\tVal Loss: 0.2559\tAccuracy: 91.304348%\n",
      "Epoch 385\tTrain Loss: 0.04356\tVal Loss: 0.2555\tAccuracy: 90.338164%\n",
      "Epoch 386\tTrain Loss: 0.04447\tVal Loss: 0.2513\tAccuracy: 91.304348%\n",
      "Epoch 387\tTrain Loss: 0.04204\tVal Loss: 0.2507\tAccuracy: 91.304348%\n",
      "Epoch 388\tTrain Loss: 0.04198\tVal Loss: 0.2549\tAccuracy: 90.338164%\n",
      "Epoch 389\tTrain Loss: 0.04451\tVal Loss: 0.2539\tAccuracy: 90.821256%\n",
      "Epoch 390\tTrain Loss: 0.04358\tVal Loss: 0.2511\tAccuracy: 90.821256%\n",
      "Epoch 391\tTrain Loss: 0.04225\tVal Loss: 0.2516\tAccuracy: 90.821256%\n",
      "Epoch 392\tTrain Loss: 0.04221\tVal Loss: 0.252\tAccuracy: 90.821256%\n",
      "Epoch 393\tTrain Loss: 0.04177\tVal Loss: 0.2513\tAccuracy: 90.338164%\n",
      "Epoch 394\tTrain Loss: 0.04188\tVal Loss: 0.2513\tAccuracy: 90.338164%\n",
      "Epoch 395\tTrain Loss: 0.04096\tVal Loss: 0.2515\tAccuracy: 89.371981%\n",
      "Epoch 396\tTrain Loss: 0.04068\tVal Loss: 0.2545\tAccuracy: 88.888889%\n",
      "Epoch 397\tTrain Loss: 0.03953\tVal Loss: 0.2629\tAccuracy: 87.439614%\n",
      "Epoch 398\tTrain Loss: 0.04106\tVal Loss: 0.2582\tAccuracy: 88.888889%\n",
      "Epoch 399\tTrain Loss: 0.04022\tVal Loss: 0.2601\tAccuracy: 87.922705%\n",
      "Epoch 400\tTrain Loss: 0.04162\tVal Loss: 0.262\tAccuracy: 88.405797%\n",
      "Epoch 401\tTrain Loss: 0.03762\tVal Loss: 0.2682\tAccuracy: 86.473430%\n",
      "Epoch 402\tTrain Loss: 0.03924\tVal Loss: 0.2603\tAccuracy: 89.371981%\n",
      "Epoch 403\tTrain Loss: 0.03922\tVal Loss: 0.2624\tAccuracy: 87.922705%\n",
      "Epoch 404\tTrain Loss: 0.03874\tVal Loss: 0.2633\tAccuracy: 86.956522%\n",
      "Epoch 405\tTrain Loss: 0.03829\tVal Loss: 0.2614\tAccuracy: 88.405797%\n",
      "Epoch 406\tTrain Loss: 0.03927\tVal Loss: 0.2628\tAccuracy: 87.922705%\n",
      "Epoch 407\tTrain Loss: 0.03765\tVal Loss: 0.2652\tAccuracy: 85.990338%\n",
      "Epoch 408\tTrain Loss: 0.03857\tVal Loss: 0.2606\tAccuracy: 88.405797%\n",
      "Epoch 409\tTrain Loss: 0.0389\tVal Loss: 0.2565\tAccuracy: 88.405797%\n",
      "Epoch 410\tTrain Loss: 0.03866\tVal Loss: 0.2588\tAccuracy: 88.405797%\n",
      "Epoch 411\tTrain Loss: 0.04\tVal Loss: 0.2576\tAccuracy: 88.405797%\n",
      "Epoch 412\tTrain Loss: 0.03798\tVal Loss: 0.2641\tAccuracy: 86.956522%\n",
      "Epoch 413\tTrain Loss: 0.03965\tVal Loss: 0.2537\tAccuracy: 89.371981%\n",
      "Epoch 414\tTrain Loss: 0.0404\tVal Loss: 0.2544\tAccuracy: 87.922705%\n",
      "Epoch 415\tTrain Loss: 0.04231\tVal Loss: 0.2573\tAccuracy: 88.888889%\n",
      "Epoch 416\tTrain Loss: 0.03798\tVal Loss: 0.2651\tAccuracy: 86.956522%\n",
      "Epoch 417\tTrain Loss: 0.03947\tVal Loss: 0.2525\tAccuracy: 89.855072%\n",
      "Epoch 418\tTrain Loss: 0.04\tVal Loss: 0.2547\tAccuracy: 88.888889%\n",
      "Epoch 419\tTrain Loss: 0.03842\tVal Loss: 0.2538\tAccuracy: 87.922705%\n",
      "Epoch 420\tTrain Loss: 0.04149\tVal Loss: 0.2502\tAccuracy: 88.888889%\n",
      "Epoch 421\tTrain Loss: 0.0398\tVal Loss: 0.2578\tAccuracy: 88.888889%\n",
      "Epoch 422\tTrain Loss: 0.04114\tVal Loss: 0.2531\tAccuracy: 89.371981%\n",
      "Epoch 423\tTrain Loss: 0.04019\tVal Loss: 0.2506\tAccuracy: 89.371981%\n",
      "Epoch 424\tTrain Loss: 0.03977\tVal Loss: 0.2507\tAccuracy: 88.888889%\n",
      "Epoch 425\tTrain Loss: 0.04179\tVal Loss: 0.2482\tAccuracy: 89.371981%\n",
      "Epoch 426\tTrain Loss: 0.03974\tVal Loss: 0.2533\tAccuracy: 89.371981%\n",
      "Epoch 427\tTrain Loss: 0.04249\tVal Loss: 0.2502\tAccuracy: 89.371981%\n",
      "Epoch 428\tTrain Loss: 0.04592\tVal Loss: 0.2491\tAccuracy: 89.371981%\n",
      "Epoch 429\tTrain Loss: 0.04046\tVal Loss: 0.2551\tAccuracy: 89.371981%\n",
      "Epoch 430\tTrain Loss: 0.0457\tVal Loss: 0.2503\tAccuracy: 90.821256%\n",
      "Epoch 431\tTrain Loss: 0.05239\tVal Loss: 0.2508\tAccuracy: 90.821256%\n",
      "Epoch 432\tTrain Loss: 0.04328\tVal Loss: 0.265\tAccuracy: 90.338164%\n",
      "Epoch 433\tTrain Loss: 0.04955\tVal Loss: 0.2571\tAccuracy: 91.304348%\n",
      "Epoch 434\tTrain Loss: 0.04892\tVal Loss: 0.2549\tAccuracy: 90.821256%\n",
      "Epoch 435\tTrain Loss: 0.04731\tVal Loss: 0.2566\tAccuracy: 91.304348%\n",
      "Epoch 436\tTrain Loss: 0.0442\tVal Loss: 0.2542\tAccuracy: 90.338164%\n",
      "Epoch 437\tTrain Loss: 0.04449\tVal Loss: 0.2512\tAccuracy: 91.304348%\n",
      "Epoch 438\tTrain Loss: 0.04222\tVal Loss: 0.2504\tAccuracy: 91.304348%\n",
      "Epoch 439\tTrain Loss: 0.04257\tVal Loss: 0.2498\tAccuracy: 91.304348%\n",
      "Epoch 440\tTrain Loss: 0.04079\tVal Loss: 0.2494\tAccuracy: 90.338164%\n",
      "Epoch 441\tTrain Loss: 0.04055\tVal Loss: 0.2484\tAccuracy: 90.821256%\n",
      "Epoch 442\tTrain Loss: 0.04364\tVal Loss: 0.2499\tAccuracy: 89.855072%\n",
      "Epoch 443\tTrain Loss: 0.03859\tVal Loss: 0.256\tAccuracy: 87.922705%\n",
      "Epoch 444\tTrain Loss: 0.04089\tVal Loss: 0.2509\tAccuracy: 89.855072%\n",
      "Epoch 445\tTrain Loss: 0.04138\tVal Loss: 0.2529\tAccuracy: 88.405797%\n",
      "Epoch 446\tTrain Loss: 0.04054\tVal Loss: 0.2521\tAccuracy: 88.405797%\n",
      "Epoch 447\tTrain Loss: 0.04072\tVal Loss: 0.2509\tAccuracy: 89.371981%\n",
      "Epoch 448\tTrain Loss: 0.03985\tVal Loss: 0.2526\tAccuracy: 88.405797%\n",
      "Epoch 449\tTrain Loss: 0.03865\tVal Loss: 0.2535\tAccuracy: 88.405797%\n",
      "Epoch 450\tTrain Loss: 0.03837\tVal Loss: 0.2539\tAccuracy: 88.888889%\n",
      "Epoch 451\tTrain Loss: 0.04095\tVal Loss: 0.2587\tAccuracy: 88.405797%\n",
      "Epoch 452\tTrain Loss: 0.03671\tVal Loss: 0.2657\tAccuracy: 86.473430%\n",
      "Epoch 453\tTrain Loss: 0.03802\tVal Loss: 0.2581\tAccuracy: 88.888889%\n",
      "Epoch 454\tTrain Loss: 0.03769\tVal Loss: 0.2596\tAccuracy: 87.439614%\n",
      "Epoch 455\tTrain Loss: 0.0376\tVal Loss: 0.2614\tAccuracy: 88.405797%\n",
      "Epoch 456\tTrain Loss: 0.03559\tVal Loss: 0.2683\tAccuracy: 85.990338%\n",
      "Epoch 457\tTrain Loss: 0.03742\tVal Loss: 0.2584\tAccuracy: 89.371981%\n",
      "Epoch 458\tTrain Loss: 0.03777\tVal Loss: 0.2604\tAccuracy: 87.922705%\n",
      "Epoch 459\tTrain Loss: 0.03693\tVal Loss: 0.2611\tAccuracy: 87.922705%\n",
      "Epoch 460\tTrain Loss: 0.0365\tVal Loss: 0.2591\tAccuracy: 87.922705%\n",
      "Epoch 461\tTrain Loss: 0.03625\tVal Loss: 0.2563\tAccuracy: 88.888889%\n",
      "Epoch 462\tTrain Loss: 0.03755\tVal Loss: 0.2645\tAccuracy: 88.405797%\n",
      "Epoch 463\tTrain Loss: 0.03478\tVal Loss: 0.2679\tAccuracy: 85.990338%\n",
      "Epoch 464\tTrain Loss: 0.03654\tVal Loss: 0.2579\tAccuracy: 89.371981%\n",
      "Epoch 465\tTrain Loss: 0.03683\tVal Loss: 0.2592\tAccuracy: 88.405797%\n",
      "Epoch 466\tTrain Loss: 0.03617\tVal Loss: 0.2581\tAccuracy: 87.922705%\n",
      "Epoch 467\tTrain Loss: 0.03583\tVal Loss: 0.2599\tAccuracy: 88.405797%\n",
      "Epoch 468\tTrain Loss: 0.03542\tVal Loss: 0.262\tAccuracy: 87.439614%\n",
      "Epoch 469\tTrain Loss: 0.03708\tVal Loss: 0.2588\tAccuracy: 87.922705%\n",
      "Epoch 470\tTrain Loss: 0.03661\tVal Loss: 0.2563\tAccuracy: 88.888889%\n",
      "Epoch 471\tTrain Loss: 0.03644\tVal Loss: 0.2594\tAccuracy: 88.405797%\n",
      "Epoch 472\tTrain Loss: 0.03618\tVal Loss: 0.2576\tAccuracy: 87.922705%\n",
      "Epoch 473\tTrain Loss: 0.03625\tVal Loss: 0.2589\tAccuracy: 87.439614%\n",
      "Epoch 474\tTrain Loss: 0.03786\tVal Loss: 0.2587\tAccuracy: 87.922705%\n",
      "Epoch 475\tTrain Loss: 0.03497\tVal Loss: 0.263\tAccuracy: 86.956522%\n",
      "Epoch 476\tTrain Loss: 0.03708\tVal Loss: 0.2593\tAccuracy: 88.405797%\n",
      "Epoch 477\tTrain Loss: 0.03644\tVal Loss: 0.2566\tAccuracy: 88.888889%\n",
      "Epoch 478\tTrain Loss: 0.03605\tVal Loss: 0.2594\tAccuracy: 87.922705%\n",
      "Epoch 479\tTrain Loss: 0.03707\tVal Loss: 0.2593\tAccuracy: 88.405797%\n",
      "Epoch 480\tTrain Loss: 0.03522\tVal Loss: 0.2623\tAccuracy: 86.956522%\n",
      "Epoch 481\tTrain Loss: 0.03705\tVal Loss: 0.2588\tAccuracy: 88.405797%\n",
      "Epoch 482\tTrain Loss: 0.03662\tVal Loss: 0.2577\tAccuracy: 87.922705%\n",
      "Epoch 483\tTrain Loss: 0.03608\tVal Loss: 0.2568\tAccuracy: 87.439614%\n",
      "Epoch 484\tTrain Loss: 0.03576\tVal Loss: 0.2596\tAccuracy: 87.922705%\n",
      "Epoch 485\tTrain Loss: 0.03703\tVal Loss: 0.258\tAccuracy: 88.405797%\n",
      "Epoch 486\tTrain Loss: 0.03531\tVal Loss: 0.2618\tAccuracy: 86.956522%\n",
      "Epoch 487\tTrain Loss: 0.03646\tVal Loss: 0.2593\tAccuracy: 87.922705%\n",
      "Epoch 488\tTrain Loss: 0.03656\tVal Loss: 0.2566\tAccuracy: 88.405797%\n",
      "Epoch 489\tTrain Loss: 0.03573\tVal Loss: 0.2566\tAccuracy: 87.922705%\n",
      "Epoch 490\tTrain Loss: 0.03683\tVal Loss: 0.2619\tAccuracy: 88.888889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491\tTrain Loss: 0.03472\tVal Loss: 0.267\tAccuracy: 86.473430%\n",
      "Epoch 492\tTrain Loss: 0.03706\tVal Loss: 0.2562\tAccuracy: 88.888889%\n",
      "Epoch 493\tTrain Loss: 0.03771\tVal Loss: 0.2588\tAccuracy: 88.405797%\n",
      "Epoch 494\tTrain Loss: 0.03591\tVal Loss: 0.2582\tAccuracy: 88.405797%\n",
      "Epoch 495\tTrain Loss: 0.03999\tVal Loss: 0.2595\tAccuracy: 88.888889%\n",
      "Epoch 496\tTrain Loss: 0.03467\tVal Loss: 0.274\tAccuracy: 85.990338%\n",
      "Epoch 497\tTrain Loss: 0.03619\tVal Loss: 0.2583\tAccuracy: 88.888889%\n",
      "Epoch 498\tTrain Loss: 0.03747\tVal Loss: 0.2586\tAccuracy: 87.922705%\n",
      "Epoch 499\tTrain Loss: 0.036\tVal Loss: 0.2616\tAccuracy: 87.922705%\n",
      "Epoch 500\tTrain Loss: 0.03671\tVal Loss: 0.2588\tAccuracy: 88.405797%\n",
      "Epoch 501\tTrain Loss: 0.03553\tVal Loss: 0.2656\tAccuracy: 86.956522%\n",
      "Epoch 502\tTrain Loss: 0.03663\tVal Loss: 0.2595\tAccuracy: 87.922705%\n",
      "Epoch 503\tTrain Loss: 0.0363\tVal Loss: 0.2555\tAccuracy: 88.888889%\n",
      "Epoch 504\tTrain Loss: 0.03588\tVal Loss: 0.2596\tAccuracy: 87.922705%\n",
      "Epoch 505\tTrain Loss: 0.03597\tVal Loss: 0.2622\tAccuracy: 88.405797%\n",
      "Epoch 506\tTrain Loss: 0.03476\tVal Loss: 0.2673\tAccuracy: 85.990338%\n",
      "Epoch 507\tTrain Loss: 0.0366\tVal Loss: 0.2571\tAccuracy: 88.888889%\n",
      "Epoch 508\tTrain Loss: 0.03637\tVal Loss: 0.2597\tAccuracy: 88.405797%\n",
      "Epoch 509\tTrain Loss: 0.03693\tVal Loss: 0.2614\tAccuracy: 88.888889%\n",
      "Epoch 510\tTrain Loss: 0.03415\tVal Loss: 0.272\tAccuracy: 85.990338%\n",
      "Epoch 511\tTrain Loss: 0.03589\tVal Loss: 0.2597\tAccuracy: 87.922705%\n",
      "Epoch 512\tTrain Loss: 0.03577\tVal Loss: 0.2621\tAccuracy: 87.922705%\n",
      "Epoch 513\tTrain Loss: 0.03688\tVal Loss: 0.2606\tAccuracy: 88.405797%\n",
      "Epoch 514\tTrain Loss: 0.03438\tVal Loss: 0.2693\tAccuracy: 85.990338%\n",
      "Epoch 515\tTrain Loss: 0.03606\tVal Loss: 0.2586\tAccuracy: 87.922705%\n",
      "Epoch 516\tTrain Loss: 0.03567\tVal Loss: 0.2634\tAccuracy: 87.922705%\n",
      "Epoch 517\tTrain Loss: 0.03578\tVal Loss: 0.2611\tAccuracy: 88.405797%\n",
      "Epoch 518\tTrain Loss: 0.03478\tVal Loss: 0.2707\tAccuracy: 85.990338%\n",
      "Epoch 519\tTrain Loss: 0.03526\tVal Loss: 0.2656\tAccuracy: 87.922705%\n",
      "Epoch 520\tTrain Loss: 0.03557\tVal Loss: 0.2582\tAccuracy: 87.922705%\n",
      "Epoch 521\tTrain Loss: 0.03851\tVal Loss: 0.2628\tAccuracy: 88.405797%\n",
      "Epoch 522\tTrain Loss: 0.03434\tVal Loss: 0.2664\tAccuracy: 86.473430%\n",
      "Epoch 523\tTrain Loss: 0.03563\tVal Loss: 0.2668\tAccuracy: 87.439614%\n",
      "Epoch 524\tTrain Loss: 0.03549\tVal Loss: 0.257\tAccuracy: 87.922705%\n",
      "Epoch 525\tTrain Loss: 0.03618\tVal Loss: 0.2665\tAccuracy: 87.922705%\n",
      "Epoch 526\tTrain Loss: 0.03419\tVal Loss: 0.2702\tAccuracy: 85.990338%\n",
      "Epoch 527\tTrain Loss: 0.03633\tVal Loss: 0.2645\tAccuracy: 88.405797%\n",
      "Epoch 528\tTrain Loss: 0.03549\tVal Loss: 0.2688\tAccuracy: 86.956522%\n",
      "Epoch 529\tTrain Loss: 0.03788\tVal Loss: 0.2618\tAccuracy: 87.922705%\n",
      "Epoch 530\tTrain Loss: 0.04238\tVal Loss: 0.2634\tAccuracy: 88.405797%\n",
      "Epoch 531\tTrain Loss: 0.03444\tVal Loss: 0.2685\tAccuracy: 86.473430%\n",
      "Epoch 532\tTrain Loss: 0.03653\tVal Loss: 0.2654\tAccuracy: 87.922705%\n",
      "Epoch 533\tTrain Loss: 0.03622\tVal Loss: 0.2597\tAccuracy: 87.922705%\n",
      "Epoch 534\tTrain Loss: 0.03583\tVal Loss: 0.2699\tAccuracy: 86.956522%\n",
      "Epoch 535\tTrain Loss: 0.03483\tVal Loss: 0.2681\tAccuracy: 86.473430%\n",
      "Epoch 536\tTrain Loss: 0.03592\tVal Loss: 0.2668\tAccuracy: 87.922705%\n",
      "Epoch 537\tTrain Loss: 0.03499\tVal Loss: 0.2575\tAccuracy: 88.405797%\n",
      "Epoch 538\tTrain Loss: 0.03622\tVal Loss: 0.2735\tAccuracy: 86.956522%\n",
      "Epoch 539\tTrain Loss: 0.03424\tVal Loss: 0.2674\tAccuracy: 86.473430%\n",
      "Epoch 540\tTrain Loss: 0.03706\tVal Loss: 0.2668\tAccuracy: 87.922705%\n",
      "Epoch 541\tTrain Loss: 0.03449\tVal Loss: 0.2676\tAccuracy: 87.922705%\n",
      "Epoch 542\tTrain Loss: 0.03594\tVal Loss: 0.2621\tAccuracy: 87.922705%\n",
      "Epoch 543\tTrain Loss: 0.03557\tVal Loss: 0.265\tAccuracy: 87.922705%\n",
      "Epoch 544\tTrain Loss: 0.03703\tVal Loss: 0.2613\tAccuracy: 88.405797%\n",
      "Epoch 545\tTrain Loss: 0.03441\tVal Loss: 0.2725\tAccuracy: 85.990338%\n",
      "Epoch 546\tTrain Loss: 0.03456\tVal Loss: 0.2644\tAccuracy: 87.922705%\n",
      "Epoch 547\tTrain Loss: 0.03624\tVal Loss: 0.2656\tAccuracy: 88.405797%\n",
      "Epoch 548\tTrain Loss: 0.03484\tVal Loss: 0.2661\tAccuracy: 87.439614%\n",
      "Epoch 549\tTrain Loss: 0.03589\tVal Loss: 0.2674\tAccuracy: 87.439614%\n",
      "Epoch 550\tTrain Loss: 0.0365\tVal Loss: 0.2604\tAccuracy: 88.405797%\n",
      "Epoch 551\tTrain Loss: 0.03511\tVal Loss: 0.2707\tAccuracy: 86.473430%\n",
      "Epoch 552\tTrain Loss: 0.03543\tVal Loss: 0.2667\tAccuracy: 87.922705%\n",
      "Epoch 553\tTrain Loss: 0.03525\tVal Loss: 0.2644\tAccuracy: 87.922705%\n",
      "Epoch 554\tTrain Loss: 0.03651\tVal Loss: 0.2639\tAccuracy: 88.405797%\n",
      "Epoch 555\tTrain Loss: 0.03412\tVal Loss: 0.2681\tAccuracy: 86.956522%\n",
      "Epoch 556\tTrain Loss: 0.03537\tVal Loss: 0.2664\tAccuracy: 87.922705%\n",
      "Epoch 557\tTrain Loss: 0.03832\tVal Loss: 0.2604\tAccuracy: 88.405797%\n",
      "Epoch 558\tTrain Loss: 0.03501\tVal Loss: 0.2691\tAccuracy: 86.956522%\n",
      "Epoch 559\tTrain Loss: 0.03641\tVal Loss: 0.2678\tAccuracy: 87.922705%\n",
      "Epoch 560\tTrain Loss: 0.03488\tVal Loss: 0.2612\tAccuracy: 88.405797%\n",
      "Epoch 561\tTrain Loss: 0.03729\tVal Loss: 0.2694\tAccuracy: 86.956522%\n",
      "Epoch 562\tTrain Loss: 0.03468\tVal Loss: 0.2719\tAccuracy: 85.990338%\n",
      "Epoch 563\tTrain Loss: 0.03628\tVal Loss: 0.2661\tAccuracy: 87.922705%\n",
      "Epoch 564\tTrain Loss: 0.03533\tVal Loss: 0.2623\tAccuracy: 87.922705%\n",
      "Epoch 565\tTrain Loss: 0.03745\tVal Loss: 0.2661\tAccuracy: 88.888889%\n",
      "Epoch 566\tTrain Loss: 0.03468\tVal Loss: 0.2746\tAccuracy: 85.990338%\n",
      "Epoch 567\tTrain Loss: 0.03564\tVal Loss: 0.2663\tAccuracy: 87.922705%\n",
      "Epoch 568\tTrain Loss: 0.03675\tVal Loss: 0.2649\tAccuracy: 88.405797%\n",
      "Epoch 569\tTrain Loss: 0.035\tVal Loss: 0.2689\tAccuracy: 86.956522%\n",
      "Epoch 570\tTrain Loss: 0.03605\tVal Loss: 0.2717\tAccuracy: 87.439614%\n",
      "Epoch 571\tTrain Loss: 0.03572\tVal Loss: 0.2663\tAccuracy: 87.922705%\n",
      "Epoch 572\tTrain Loss: 0.03475\tVal Loss: 0.27\tAccuracy: 87.439614%\n",
      "Epoch 573\tTrain Loss: 0.03605\tVal Loss: 0.2678\tAccuracy: 87.922705%\n",
      "Epoch 574\tTrain Loss: 0.03563\tVal Loss: 0.2625\tAccuracy: 88.405797%\n",
      "Epoch 575\tTrain Loss: 0.03683\tVal Loss: 0.2683\tAccuracy: 88.405797%\n",
      "Epoch 576\tTrain Loss: 0.03458\tVal Loss: 0.2693\tAccuracy: 86.956522%\n",
      "Epoch 577\tTrain Loss: 0.03655\tVal Loss: 0.2695\tAccuracy: 87.922705%\n",
      "Epoch 578\tTrain Loss: 0.03521\tVal Loss: 0.2603\tAccuracy: 88.405797%\n",
      "Epoch 579\tTrain Loss: 0.0352\tVal Loss: 0.2746\tAccuracy: 85.990338%\n",
      "Epoch 580\tTrain Loss: 0.03507\tVal Loss: 0.2688\tAccuracy: 86.956522%\n",
      "Epoch 581\tTrain Loss: 0.03834\tVal Loss: 0.275\tAccuracy: 87.439614%\n",
      "Epoch 582\tTrain Loss: 0.03441\tVal Loss: 0.2696\tAccuracy: 87.439614%\n",
      "Epoch 583\tTrain Loss: 0.03623\tVal Loss: 0.2712\tAccuracy: 86.956522%\n",
      "Epoch 584\tTrain Loss: 0.03555\tVal Loss: 0.2602\tAccuracy: 88.405797%\n",
      "Epoch 585\tTrain Loss: 0.03533\tVal Loss: 0.2744\tAccuracy: 85.990338%\n",
      "Epoch 586\tTrain Loss: 0.0347\tVal Loss: 0.2709\tAccuracy: 86.956522%\n",
      "Epoch 587\tTrain Loss: 0.04179\tVal Loss: 0.269\tAccuracy: 87.922705%\n",
      "Epoch 588\tTrain Loss: 0.03415\tVal Loss: 0.2696\tAccuracy: 87.439614%\n",
      "Epoch 589\tTrain Loss: 0.03622\tVal Loss: 0.2685\tAccuracy: 87.922705%\n",
      "Epoch 590\tTrain Loss: 0.03594\tVal Loss: 0.2643\tAccuracy: 88.405797%\n",
      "Epoch 591\tTrain Loss: 0.03525\tVal Loss: 0.2682\tAccuracy: 87.439614%\n",
      "Epoch 592\tTrain Loss: 0.03784\tVal Loss: 0.2643\tAccuracy: 88.888889%\n",
      "Epoch 593\tTrain Loss: 0.03425\tVal Loss: 0.2737\tAccuracy: 86.956522%\n",
      "Epoch 594\tTrain Loss: 0.03549\tVal Loss: 0.2749\tAccuracy: 87.922705%\n",
      "Epoch 595\tTrain Loss: 0.03459\tVal Loss: 0.2672\tAccuracy: 87.439614%\n",
      "Epoch 596\tTrain Loss: 0.03978\tVal Loss: 0.2792\tAccuracy: 85.507246%\n",
      "Epoch 597\tTrain Loss: 0.03552\tVal Loss: 0.2706\tAccuracy: 86.956522%\n",
      "Epoch 598\tTrain Loss: 0.03726\tVal Loss: 0.2698\tAccuracy: 87.922705%\n",
      "Epoch 599\tTrain Loss: 0.03526\tVal Loss: 0.2616\tAccuracy: 89.371981%\n",
      "Epoch 600\tTrain Loss: 0.03606\tVal Loss: 0.2726\tAccuracy: 86.956522%\n",
      "Epoch 601\tTrain Loss: 0.03397\tVal Loss: 0.2677\tAccuracy: 86.956522%\n",
      "Epoch 602\tTrain Loss: 0.03618\tVal Loss: 0.2709\tAccuracy: 86.956522%\n",
      "Epoch 603\tTrain Loss: 0.03619\tVal Loss: 0.2635\tAccuracy: 88.405797%\n",
      "Epoch 604\tTrain Loss: 0.03473\tVal Loss: 0.2721\tAccuracy: 86.473430%\n",
      "Epoch 605\tTrain Loss: 0.03585\tVal Loss: 0.269\tAccuracy: 87.439614%\n",
      "Epoch 606\tTrain Loss: 0.03509\tVal Loss: 0.2627\tAccuracy: 88.405797%\n",
      "Epoch 607\tTrain Loss: 0.03587\tVal Loss: 0.2741\tAccuracy: 85.990338%\n",
      "Epoch 608\tTrain Loss: 0.03471\tVal Loss: 0.2656\tAccuracy: 86.956522%\n",
      "Epoch 609\tTrain Loss: 0.0373\tVal Loss: 0.2759\tAccuracy: 85.990338%\n",
      "Epoch 610\tTrain Loss: 0.03437\tVal Loss: 0.2667\tAccuracy: 87.439614%\n",
      "Epoch 611\tTrain Loss: 0.03632\tVal Loss: 0.2759\tAccuracy: 85.990338%\n",
      "Epoch 612\tTrain Loss: 0.03623\tVal Loss: 0.2641\tAccuracy: 87.922705%\n",
      "Epoch 613\tTrain Loss: 0.0347\tVal Loss: 0.27\tAccuracy: 86.956522%\n",
      "Epoch 614\tTrain Loss: 0.03605\tVal Loss: 0.268\tAccuracy: 87.439614%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615\tTrain Loss: 0.03505\tVal Loss: 0.2646\tAccuracy: 87.922705%\n",
      "Epoch 616\tTrain Loss: 0.03748\tVal Loss: 0.2678\tAccuracy: 87.922705%\n",
      "Epoch 617\tTrain Loss: 0.03394\tVal Loss: 0.2657\tAccuracy: 86.956522%\n",
      "Epoch 618\tTrain Loss: 0.03545\tVal Loss: 0.2748\tAccuracy: 87.439614%\n",
      "Epoch 619\tTrain Loss: 0.03606\tVal Loss: 0.2623\tAccuracy: 87.922705%\n",
      "Epoch 620\tTrain Loss: 0.03468\tVal Loss: 0.2715\tAccuracy: 86.473430%\n",
      "Epoch 621\tTrain Loss: 0.03585\tVal Loss: 0.2674\tAccuracy: 87.922705%\n",
      "Epoch 622\tTrain Loss: 0.03437\tVal Loss: 0.2704\tAccuracy: 88.405797%\n",
      "Epoch 623\tTrain Loss: 0.03464\tVal Loss: 0.2646\tAccuracy: 87.439614%\n",
      "Epoch 624\tTrain Loss: 0.03585\tVal Loss: 0.2741\tAccuracy: 86.473430%\n",
      "Epoch 625\tTrain Loss: 0.03585\tVal Loss: 0.2661\tAccuracy: 87.922705%\n",
      "Epoch 626\tTrain Loss: 0.03456\tVal Loss: 0.2728\tAccuracy: 86.473430%\n",
      "Epoch 627\tTrain Loss: 0.03539\tVal Loss: 0.2682\tAccuracy: 87.922705%\n",
      "Epoch 628\tTrain Loss: 0.03608\tVal Loss: 0.2678\tAccuracy: 88.888889%\n",
      "Epoch 629\tTrain Loss: 0.03549\tVal Loss: 0.2687\tAccuracy: 87.439614%\n",
      "Epoch 630\tTrain Loss: 0.0363\tVal Loss: 0.2739\tAccuracy: 87.439614%\n",
      "Epoch 631\tTrain Loss: 0.03475\tVal Loss: 0.2672\tAccuracy: 87.922705%\n",
      "Epoch 632\tTrain Loss: 0.03422\tVal Loss: 0.2708\tAccuracy: 86.956522%\n",
      "Epoch 633\tTrain Loss: 0.03528\tVal Loss: 0.2724\tAccuracy: 87.439614%\n",
      "Epoch 634\tTrain Loss: 0.035\tVal Loss: 0.2644\tAccuracy: 88.888889%\n",
      "Epoch 635\tTrain Loss: 0.03769\tVal Loss: 0.2699\tAccuracy: 87.439614%\n",
      "Epoch 636\tTrain Loss: 0.03377\tVal Loss: 0.2661\tAccuracy: 87.439614%\n",
      "Epoch 637\tTrain Loss: 0.03628\tVal Loss: 0.273\tAccuracy: 86.956522%\n",
      "Epoch 638\tTrain Loss: 0.03608\tVal Loss: 0.2652\tAccuracy: 88.405797%\n",
      "Epoch 639\tTrain Loss: 0.03439\tVal Loss: 0.2751\tAccuracy: 85.507246%\n",
      "Epoch 640\tTrain Loss: 0.03593\tVal Loss: 0.2644\tAccuracy: 88.405797%\n",
      "Epoch 641\tTrain Loss: 0.03512\tVal Loss: 0.2694\tAccuracy: 88.405797%\n",
      "Epoch 642\tTrain Loss: 0.03743\tVal Loss: 0.2635\tAccuracy: 88.888889%\n",
      "Epoch 643\tTrain Loss: 0.03443\tVal Loss: 0.2758\tAccuracy: 85.990338%\n",
      "Epoch 644\tTrain Loss: 0.03763\tVal Loss: 0.268\tAccuracy: 88.405797%\n",
      "Epoch 645\tTrain Loss: 0.03472\tVal Loss: 0.2737\tAccuracy: 86.473430%\n",
      "Epoch 646\tTrain Loss: 0.03647\tVal Loss: 0.2686\tAccuracy: 87.439614%\n",
      "Epoch 647\tTrain Loss: 0.03606\tVal Loss: 0.2661\tAccuracy: 88.888889%\n",
      "Epoch 648\tTrain Loss: 0.03559\tVal Loss: 0.2702\tAccuracy: 87.922705%\n",
      "Epoch 649\tTrain Loss: 0.03401\tVal Loss: 0.2658\tAccuracy: 87.439614%\n",
      "Epoch 650\tTrain Loss: 0.03536\tVal Loss: 0.2745\tAccuracy: 87.439614%\n",
      "Epoch 651\tTrain Loss: 0.03472\tVal Loss: 0.267\tAccuracy: 89.371981%\n",
      "Epoch 652\tTrain Loss: 0.03552\tVal Loss: 0.2731\tAccuracy: 87.439614%\n",
      "Epoch 653\tTrain Loss: 0.0369\tVal Loss: 0.2707\tAccuracy: 87.439614%\n",
      "Epoch 654\tTrain Loss: 0.0349\tVal Loss: 0.2712\tAccuracy: 87.922705%\n",
      "Epoch 655\tTrain Loss: 0.03452\tVal Loss: 0.2676\tAccuracy: 87.439614%\n",
      "Epoch 656\tTrain Loss: 0.0367\tVal Loss: 0.2783\tAccuracy: 85.990338%\n",
      "Epoch 657\tTrain Loss: 0.03381\tVal Loss: 0.2689\tAccuracy: 87.439614%\n",
      "Epoch 658\tTrain Loss: 0.03584\tVal Loss: 0.2802\tAccuracy: 86.473430%\n",
      "Epoch 659\tTrain Loss: 0.03404\tVal Loss: 0.2613\tAccuracy: 88.888889%\n",
      "Epoch 660\tTrain Loss: 0.03728\tVal Loss: 0.2779\tAccuracy: 86.473430%\n",
      "Epoch 661\tTrain Loss: 0.0337\tVal Loss: 0.2692\tAccuracy: 86.956522%\n",
      "Epoch 662\tTrain Loss: 0.03499\tVal Loss: 0.2769\tAccuracy: 86.473430%\n",
      "Epoch 663\tTrain Loss: 0.03524\tVal Loss: 0.2667\tAccuracy: 87.922705%\n",
      "Epoch 664\tTrain Loss: 0.03614\tVal Loss: 0.2766\tAccuracy: 86.956522%\n",
      "Epoch 665\tTrain Loss: 0.03415\tVal Loss: 0.269\tAccuracy: 88.405797%\n",
      "Epoch 666\tTrain Loss: 0.03523\tVal Loss: 0.273\tAccuracy: 86.473430%\n",
      "Epoch 667\tTrain Loss: 0.04229\tVal Loss: 0.2788\tAccuracy: 86.473430%\n",
      "Epoch 668\tTrain Loss: 0.03428\tVal Loss: 0.2712\tAccuracy: 87.439614%\n",
      "Epoch 669\tTrain Loss: 0.03627\tVal Loss: 0.278\tAccuracy: 85.990338%\n",
      "Epoch 670\tTrain Loss: 0.03554\tVal Loss: 0.2657\tAccuracy: 88.888889%\n",
      "Epoch 671\tTrain Loss: 0.03512\tVal Loss: 0.2729\tAccuracy: 86.473430%\n",
      "Epoch 672\tTrain Loss: 0.03795\tVal Loss: 0.2685\tAccuracy: 88.888889%\n",
      "Epoch 673\tTrain Loss: 0.03452\tVal Loss: 0.2779\tAccuracy: 85.507246%\n",
      "Epoch 674\tTrain Loss: 0.03805\tVal Loss: 0.2681\tAccuracy: 88.405797%\n",
      "Epoch 675\tTrain Loss: 0.03396\tVal Loss: 0.2835\tAccuracy: 85.990338%\n",
      "Epoch 676\tTrain Loss: 0.0357\tVal Loss: 0.2642\tAccuracy: 88.405797%\n",
      "Epoch 677\tTrain Loss: 0.03787\tVal Loss: 0.2765\tAccuracy: 85.990338%\n",
      "Epoch 678\tTrain Loss: 0.03382\tVal Loss: 0.2685\tAccuracy: 87.922705%\n",
      "Epoch 679\tTrain Loss: 0.04074\tVal Loss: 0.2746\tAccuracy: 86.956522%\n",
      "Epoch 680\tTrain Loss: 0.03528\tVal Loss: 0.2751\tAccuracy: 86.956522%\n",
      "Epoch 681\tTrain Loss: 0.03713\tVal Loss: 0.2748\tAccuracy: 86.956522%\n",
      "Epoch 682\tTrain Loss: 0.03564\tVal Loss: 0.2745\tAccuracy: 87.439614%\n",
      "Epoch 683\tTrain Loss: 0.03785\tVal Loss: 0.2672\tAccuracy: 88.888889%\n",
      "Epoch 684\tTrain Loss: 0.0342\tVal Loss: 0.2801\tAccuracy: 85.507246%\n",
      "Epoch 685\tTrain Loss: 0.03488\tVal Loss: 0.2746\tAccuracy: 87.439614%\n",
      "Epoch 686\tTrain Loss: 0.03471\tVal Loss: 0.2668\tAccuracy: 87.922705%\n",
      "Epoch 687\tTrain Loss: 0.03443\tVal Loss: 0.2795\tAccuracy: 85.990338%\n",
      "Epoch 688\tTrain Loss: 0.03382\tVal Loss: 0.2712\tAccuracy: 87.439614%\n",
      "Epoch 689\tTrain Loss: 0.0362\tVal Loss: 0.2786\tAccuracy: 86.473430%\n",
      "Epoch 690\tTrain Loss: 0.03446\tVal Loss: 0.2688\tAccuracy: 87.922705%\n",
      "Epoch 691\tTrain Loss: 0.03558\tVal Loss: 0.2785\tAccuracy: 86.956522%\n",
      "Epoch 692\tTrain Loss: 0.03458\tVal Loss: 0.2693\tAccuracy: 88.405797%\n",
      "Epoch 693\tTrain Loss: 0.03694\tVal Loss: 0.2732\tAccuracy: 87.439614%\n",
      "Epoch 694\tTrain Loss: 0.03356\tVal Loss: 0.2709\tAccuracy: 86.956522%\n",
      "Epoch 695\tTrain Loss: 0.03577\tVal Loss: 0.2733\tAccuracy: 86.956522%\n",
      "Epoch 696\tTrain Loss: 0.03464\tVal Loss: 0.2685\tAccuracy: 89.371981%\n",
      "Epoch 697\tTrain Loss: 0.0346\tVal Loss: 0.2779\tAccuracy: 86.473430%\n",
      "Epoch 698\tTrain Loss: 0.03565\tVal Loss: 0.2721\tAccuracy: 87.439614%\n",
      "Epoch 699\tTrain Loss: 0.03402\tVal Loss: 0.2703\tAccuracy: 88.888889%\n",
      "Epoch 700\tTrain Loss: 0.03618\tVal Loss: 0.2711\tAccuracy: 88.405797%\n",
      "Epoch 701\tTrain Loss: 0.03369\tVal Loss: 0.2774\tAccuracy: 86.956522%\n",
      "Epoch 702\tTrain Loss: 0.03511\tVal Loss: 0.273\tAccuracy: 87.439614%\n",
      "Epoch 703\tTrain Loss: 0.03777\tVal Loss: 0.2737\tAccuracy: 88.888889%\n",
      "Epoch 704\tTrain Loss: 0.03314\tVal Loss: 0.2751\tAccuracy: 86.956522%\n",
      "Epoch 705\tTrain Loss: 0.03558\tVal Loss: 0.2741\tAccuracy: 86.956522%\n",
      "Epoch 706\tTrain Loss: 0.03424\tVal Loss: 0.2697\tAccuracy: 88.888889%\n",
      "Epoch 707\tTrain Loss: 0.03353\tVal Loss: 0.274\tAccuracy: 87.922705%\n",
      "Epoch 708\tTrain Loss: 0.03523\tVal Loss: 0.2775\tAccuracy: 86.956522%\n",
      "Epoch 709\tTrain Loss: 0.03407\tVal Loss: 0.2751\tAccuracy: 88.888889%\n",
      "Epoch 710\tTrain Loss: 0.03295\tVal Loss: 0.2809\tAccuracy: 85.990338%\n",
      "Epoch 711\tTrain Loss: 0.03502\tVal Loss: 0.2732\tAccuracy: 86.956522%\n",
      "Epoch 712\tTrain Loss: 0.0355\tVal Loss: 0.2762\tAccuracy: 86.956522%\n",
      "Epoch 713\tTrain Loss: 0.03892\tVal Loss: 0.2797\tAccuracy: 86.956522%\n",
      "Epoch 714\tTrain Loss: 0.03492\tVal Loss: 0.2755\tAccuracy: 87.439614%\n",
      "Epoch 715\tTrain Loss: 0.0356\tVal Loss: 0.2773\tAccuracy: 86.956522%\n",
      "Epoch 716\tTrain Loss: 0.03492\tVal Loss: 0.2688\tAccuracy: 87.922705%\n",
      "Epoch 717\tTrain Loss: 0.03363\tVal Loss: 0.2764\tAccuracy: 87.922705%\n",
      "Epoch 718\tTrain Loss: 0.03868\tVal Loss: 0.2705\tAccuracy: 89.371981%\n",
      "Epoch 719\tTrain Loss: 0.03386\tVal Loss: 0.2835\tAccuracy: 85.507246%\n",
      "Epoch 720\tTrain Loss: 0.03439\tVal Loss: 0.2744\tAccuracy: 86.473430%\n",
      "Epoch 721\tTrain Loss: 0.03423\tVal Loss: 0.2731\tAccuracy: 87.922705%\n",
      "Epoch 722\tTrain Loss: 0.03355\tVal Loss: 0.2728\tAccuracy: 87.439614%\n",
      "Epoch 723\tTrain Loss: 0.03439\tVal Loss: 0.2844\tAccuracy: 85.507246%\n",
      "Epoch 724\tTrain Loss: 0.03353\tVal Loss: 0.2752\tAccuracy: 87.439614%\n",
      "Epoch 725\tTrain Loss: 0.04398\tVal Loss: 0.2738\tAccuracy: 86.956522%\n",
      "Epoch 726\tTrain Loss: 0.03414\tVal Loss: 0.2766\tAccuracy: 86.956522%\n",
      "Epoch 727\tTrain Loss: 0.03454\tVal Loss: 0.28\tAccuracy: 86.956522%\n",
      "Epoch 728\tTrain Loss: 0.03342\tVal Loss: 0.2664\tAccuracy: 88.888889%\n",
      "Epoch 729\tTrain Loss: 0.03553\tVal Loss: 0.2856\tAccuracy: 85.507246%\n",
      "Epoch 730\tTrain Loss: 0.03306\tVal Loss: 0.2685\tAccuracy: 87.439614%\n",
      "Epoch 731\tTrain Loss: 0.0348\tVal Loss: 0.2825\tAccuracy: 85.024155%\n",
      "Epoch 732\tTrain Loss: 0.03384\tVal Loss: 0.2749\tAccuracy: 86.956522%\n",
      "Epoch 733\tTrain Loss: 0.03489\tVal Loss: 0.2737\tAccuracy: 87.439614%\n",
      "Epoch 734\tTrain Loss: 0.03498\tVal Loss: 0.2792\tAccuracy: 86.473430%\n",
      "Epoch 735\tTrain Loss: 0.0332\tVal Loss: 0.2709\tAccuracy: 87.439614%\n",
      "Epoch 736\tTrain Loss: 0.0351\tVal Loss: 0.2781\tAccuracy: 86.956522%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737\tTrain Loss: 0.03365\tVal Loss: 0.2701\tAccuracy: 88.405797%\n",
      "Epoch 738\tTrain Loss: 0.03431\tVal Loss: 0.2777\tAccuracy: 86.473430%\n",
      "Epoch 739\tTrain Loss: 0.03555\tVal Loss: 0.2784\tAccuracy: 86.956522%\n",
      "Epoch 740\tTrain Loss: 0.03422\tVal Loss: 0.2732\tAccuracy: 87.439614%\n",
      "Epoch 741\tTrain Loss: 0.03344\tVal Loss: 0.277\tAccuracy: 86.473430%\n",
      "Epoch 742\tTrain Loss: 0.03426\tVal Loss: 0.2793\tAccuracy: 86.473430%\n",
      "Epoch 743\tTrain Loss: 0.03544\tVal Loss: 0.269\tAccuracy: 88.405797%\n",
      "Epoch 744\tTrain Loss: 0.03341\tVal Loss: 0.2811\tAccuracy: 85.024155%\n",
      "Epoch 745\tTrain Loss: 0.03543\tVal Loss: 0.284\tAccuracy: 85.024155%\n",
      "Epoch 746\tTrain Loss: 0.03369\tVal Loss: 0.2737\tAccuracy: 87.439614%\n",
      "Epoch 747\tTrain Loss: 0.03916\tVal Loss: 0.2849\tAccuracy: 85.507246%\n",
      "Epoch 748\tTrain Loss: 0.03373\tVal Loss: 0.2737\tAccuracy: 87.439614%\n",
      "Epoch 749\tTrain Loss: 0.03614\tVal Loss: 0.2802\tAccuracy: 86.956522%\n",
      "Epoch 750\tTrain Loss: 0.03437\tVal Loss: 0.2701\tAccuracy: 88.405797%\n",
      "Epoch 751\tTrain Loss: 0.0331\tVal Loss: 0.278\tAccuracy: 86.473430%\n",
      "Epoch 752\tTrain Loss: 0.03403\tVal Loss: 0.2797\tAccuracy: 85.990338%\n",
      "Epoch 753\tTrain Loss: 0.0361\tVal Loss: 0.2746\tAccuracy: 87.439614%\n",
      "Epoch 754\tTrain Loss: 0.0337\tVal Loss: 0.2786\tAccuracy: 86.956522%\n",
      "Epoch 755\tTrain Loss: 0.03441\tVal Loss: 0.2762\tAccuracy: 86.956522%\n",
      "Epoch 756\tTrain Loss: 0.03401\tVal Loss: 0.2755\tAccuracy: 87.922705%\n",
      "Epoch 757\tTrain Loss: 0.03337\tVal Loss: 0.2721\tAccuracy: 86.956522%\n",
      "Epoch 758\tTrain Loss: 0.03515\tVal Loss: 0.2794\tAccuracy: 85.990338%\n",
      "Epoch 759\tTrain Loss: 0.03295\tVal Loss: 0.2671\tAccuracy: 87.439614%\n",
      "Epoch 760\tTrain Loss: 0.03591\tVal Loss: 0.2814\tAccuracy: 85.990338%\n",
      "Epoch 761\tTrain Loss: 0.03315\tVal Loss: 0.2711\tAccuracy: 86.473430%\n",
      "Epoch 762\tTrain Loss: 0.03618\tVal Loss: 0.2815\tAccuracy: 85.990338%\n",
      "Epoch 763\tTrain Loss: 0.03277\tVal Loss: 0.2761\tAccuracy: 87.439614%\n",
      "Epoch 764\tTrain Loss: 0.03482\tVal Loss: 0.2755\tAccuracy: 86.956522%\n",
      "Epoch 765\tTrain Loss: 0.03383\tVal Loss: 0.2709\tAccuracy: 87.439614%\n",
      "Epoch 766\tTrain Loss: 0.03527\tVal Loss: 0.276\tAccuracy: 87.922705%\n",
      "Epoch 767\tTrain Loss: 0.03339\tVal Loss: 0.2793\tAccuracy: 85.507246%\n",
      "Epoch 768\tTrain Loss: 0.03511\tVal Loss: 0.2783\tAccuracy: 87.439614%\n",
      "Epoch 769\tTrain Loss: 0.03342\tVal Loss: 0.2757\tAccuracy: 86.473430%\n",
      "Epoch 770\tTrain Loss: 0.03485\tVal Loss: 0.2784\tAccuracy: 86.956522%\n",
      "Epoch 771\tTrain Loss: 0.03349\tVal Loss: 0.2697\tAccuracy: 88.405797%\n",
      "Epoch 772\tTrain Loss: 0.03482\tVal Loss: 0.2789\tAccuracy: 86.473430%\n",
      "Epoch 773\tTrain Loss: 0.03286\tVal Loss: 0.2715\tAccuracy: 86.956522%\n",
      "Epoch 774\tTrain Loss: 0.03403\tVal Loss: 0.2824\tAccuracy: 85.507246%\n",
      "Epoch 775\tTrain Loss: 0.03611\tVal Loss: 0.2743\tAccuracy: 87.439614%\n",
      "Epoch 776\tTrain Loss: 0.03385\tVal Loss: 0.2739\tAccuracy: 86.956522%\n",
      "Epoch 777\tTrain Loss: 0.04196\tVal Loss: 0.2799\tAccuracy: 85.507246%\n",
      "Epoch 778\tTrain Loss: 0.03322\tVal Loss: 0.2756\tAccuracy: 87.439614%\n",
      "Epoch 779\tTrain Loss: 0.03506\tVal Loss: 0.2768\tAccuracy: 86.473430%\n",
      "Epoch 780\tTrain Loss: 0.0346\tVal Loss: 0.2757\tAccuracy: 87.922705%\n",
      "Epoch 781\tTrain Loss: 0.03311\tVal Loss: 0.2726\tAccuracy: 86.473430%\n",
      "Epoch 782\tTrain Loss: 0.03476\tVal Loss: 0.2806\tAccuracy: 85.507246%\n",
      "Epoch 783\tTrain Loss: 0.03299\tVal Loss: 0.269\tAccuracy: 88.405797%\n",
      "Epoch 784\tTrain Loss: 0.03411\tVal Loss: 0.2805\tAccuracy: 85.507246%\n",
      "Epoch 785\tTrain Loss: 0.0346\tVal Loss: 0.2712\tAccuracy: 87.439614%\n",
      "Epoch 786\tTrain Loss: 0.03377\tVal Loss: 0.2764\tAccuracy: 86.956522%\n",
      "Epoch 787\tTrain Loss: 0.0333\tVal Loss: 0.2701\tAccuracy: 86.956522%\n",
      "Epoch 788\tTrain Loss: 0.03688\tVal Loss: 0.2844\tAccuracy: 85.024155%\n",
      "Epoch 789\tTrain Loss: 0.03253\tVal Loss: 0.2735\tAccuracy: 86.956522%\n",
      "Epoch 790\tTrain Loss: 0.0338\tVal Loss: 0.2804\tAccuracy: 85.990338%\n",
      "Epoch 791\tTrain Loss: 0.03423\tVal Loss: 0.2693\tAccuracy: 88.888889%\n",
      "Epoch 792\tTrain Loss: 0.03388\tVal Loss: 0.2743\tAccuracy: 85.990338%\n",
      "Epoch 793\tTrain Loss: 0.03485\tVal Loss: 0.2763\tAccuracy: 86.473430%\n",
      "Epoch 794\tTrain Loss: 0.03256\tVal Loss: 0.2667\tAccuracy: 88.888889%\n",
      "Epoch 795\tTrain Loss: 0.0348\tVal Loss: 0.278\tAccuracy: 85.507246%\n",
      "Epoch 796\tTrain Loss: 0.0335\tVal Loss: 0.2686\tAccuracy: 87.439614%\n",
      "Epoch 797\tTrain Loss: 0.03387\tVal Loss: 0.2761\tAccuracy: 86.473430%\n",
      "Epoch 798\tTrain Loss: 0.03603\tVal Loss: 0.268\tAccuracy: 87.439614%\n",
      "Epoch 799\tTrain Loss: 0.03314\tVal Loss: 0.2765\tAccuracy: 86.956522%\n",
      "Epoch 800\tTrain Loss: 0.03413\tVal Loss: 0.275\tAccuracy: 88.405797%\n",
      "Epoch 801\tTrain Loss: 0.0336\tVal Loss: 0.2797\tAccuracy: 86.473430%\n",
      "Epoch 802\tTrain Loss: 0.03752\tVal Loss: 0.2775\tAccuracy: 85.990338%\n",
      "Epoch 803\tTrain Loss: 0.03393\tVal Loss: 0.2712\tAccuracy: 86.956522%\n",
      "Epoch 804\tTrain Loss: 0.03625\tVal Loss: 0.2808\tAccuracy: 85.024155%\n",
      "Epoch 805\tTrain Loss: 0.03306\tVal Loss: 0.273\tAccuracy: 86.956522%\n",
      "Epoch 806\tTrain Loss: 0.03406\tVal Loss: 0.2761\tAccuracy: 86.473430%\n",
      "Epoch 807\tTrain Loss: 0.03349\tVal Loss: 0.2696\tAccuracy: 88.405797%\n",
      "Epoch 808\tTrain Loss: 0.03437\tVal Loss: 0.2727\tAccuracy: 88.405797%\n",
      "Epoch 809\tTrain Loss: 0.0331\tVal Loss: 0.2726\tAccuracy: 86.473430%\n",
      "Epoch 810\tTrain Loss: 0.0343\tVal Loss: 0.2804\tAccuracy: 86.473430%\n",
      "Epoch 811\tTrain Loss: 0.03292\tVal Loss: 0.2707\tAccuracy: 87.439614%\n",
      "Epoch 812\tTrain Loss: 0.03432\tVal Loss: 0.2787\tAccuracy: 86.473430%\n",
      "Epoch 813\tTrain Loss: 0.03641\tVal Loss: 0.2682\tAccuracy: 89.371981%\n",
      "Epoch 814\tTrain Loss: 0.03239\tVal Loss: 0.2732\tAccuracy: 86.956522%\n",
      "Epoch 815\tTrain Loss: 0.03406\tVal Loss: 0.2784\tAccuracy: 85.990338%\n",
      "Epoch 816\tTrain Loss: 0.03495\tVal Loss: 0.2706\tAccuracy: 88.888889%\n",
      "Epoch 817\tTrain Loss: 0.03338\tVal Loss: 0.273\tAccuracy: 86.473430%\n",
      "Epoch 818\tTrain Loss: 0.04274\tVal Loss: 0.2802\tAccuracy: 85.990338%\n",
      "Epoch 819\tTrain Loss: 0.03241\tVal Loss: 0.2724\tAccuracy: 86.956522%\n",
      "Epoch 820\tTrain Loss: 0.03428\tVal Loss: 0.2818\tAccuracy: 85.507246%\n",
      "Epoch 821\tTrain Loss: 0.0336\tVal Loss: 0.269\tAccuracy: 88.405797%\n",
      "Epoch 822\tTrain Loss: 0.03408\tVal Loss: 0.2764\tAccuracy: 85.507246%\n",
      "Epoch 823\tTrain Loss: 0.03559\tVal Loss: 0.2787\tAccuracy: 85.507246%\n",
      "Epoch 824\tTrain Loss: 0.03245\tVal Loss: 0.2752\tAccuracy: 87.439614%\n",
      "Epoch 825\tTrain Loss: 0.03319\tVal Loss: 0.2793\tAccuracy: 86.473430%\n",
      "Epoch 826\tTrain Loss: 0.03487\tVal Loss: 0.2735\tAccuracy: 88.405797%\n",
      "Epoch 827\tTrain Loss: 0.03363\tVal Loss: 0.2756\tAccuracy: 86.956522%\n",
      "Epoch 828\tTrain Loss: 0.03498\tVal Loss: 0.2753\tAccuracy: 86.473430%\n",
      "Epoch 829\tTrain Loss: 0.03334\tVal Loss: 0.2758\tAccuracy: 87.439614%\n",
      "Epoch 830\tTrain Loss: 0.03217\tVal Loss: 0.2718\tAccuracy: 87.439614%\n",
      "Epoch 831\tTrain Loss: 0.03415\tVal Loss: 0.2797\tAccuracy: 85.507246%\n",
      "Epoch 832\tTrain Loss: 0.03274\tVal Loss: 0.2643\tAccuracy: 88.888889%\n",
      "Epoch 833\tTrain Loss: 0.0333\tVal Loss: 0.2793\tAccuracy: 85.990338%\n",
      "Epoch 834\tTrain Loss: 0.03348\tVal Loss: 0.2709\tAccuracy: 87.439614%\n",
      "Epoch 835\tTrain Loss: 0.03326\tVal Loss: 0.2843\tAccuracy: 85.507246%\n",
      "Epoch 836\tTrain Loss: 0.03375\tVal Loss: 0.2717\tAccuracy: 87.439614%\n",
      "Epoch 837\tTrain Loss: 0.03296\tVal Loss: 0.2713\tAccuracy: 86.956522%\n",
      "Epoch 838\tTrain Loss: 0.03451\tVal Loss: 0.2775\tAccuracy: 86.473430%\n",
      "Epoch 839\tTrain Loss: 0.03299\tVal Loss: 0.2741\tAccuracy: 86.473430%\n",
      "Epoch 840\tTrain Loss: 0.03392\tVal Loss: 0.2766\tAccuracy: 85.990338%\n",
      "Epoch 841\tTrain Loss: 0.03435\tVal Loss: 0.2732\tAccuracy: 87.922705%\n",
      "Epoch 842\tTrain Loss: 0.03209\tVal Loss: 0.2778\tAccuracy: 86.956522%\n",
      "Epoch 843\tTrain Loss: 0.03361\tVal Loss: 0.2771\tAccuracy: 86.473430%\n",
      "Epoch 844\tTrain Loss: 0.03381\tVal Loss: 0.2734\tAccuracy: 88.405797%\n",
      "Epoch 845\tTrain Loss: 0.03283\tVal Loss: 0.2743\tAccuracy: 86.956522%\n",
      "Epoch 846\tTrain Loss: 0.03483\tVal Loss: 0.2814\tAccuracy: 85.990338%\n",
      "Epoch 847\tTrain Loss: 0.03229\tVal Loss: 0.2765\tAccuracy: 86.956522%\n",
      "Epoch 848\tTrain Loss: 0.03328\tVal Loss: 0.2754\tAccuracy: 86.473430%\n",
      "Epoch 849\tTrain Loss: 0.03455\tVal Loss: 0.2773\tAccuracy: 86.956522%\n",
      "Epoch 850\tTrain Loss: 0.03239\tVal Loss: 0.2728\tAccuracy: 87.439614%\n",
      "Epoch 851\tTrain Loss: 0.03341\tVal Loss: 0.2772\tAccuracy: 86.473430%\n",
      "Epoch 852\tTrain Loss: 0.03448\tVal Loss: 0.2695\tAccuracy: 88.405797%\n",
      "Epoch 853\tTrain Loss: 0.0323\tVal Loss: 0.2807\tAccuracy: 86.473430%\n",
      "Epoch 854\tTrain Loss: 0.0342\tVal Loss: 0.2772\tAccuracy: 85.990338%\n",
      "Epoch 855\tTrain Loss: 0.03313\tVal Loss: 0.2738\tAccuracy: 88.405797%\n",
      "Epoch 856\tTrain Loss: 0.03282\tVal Loss: 0.2765\tAccuracy: 85.990338%\n",
      "Epoch 857\tTrain Loss: 0.03424\tVal Loss: 0.2799\tAccuracy: 85.990338%\n",
      "Epoch 858\tTrain Loss: 0.03237\tVal Loss: 0.2748\tAccuracy: 87.439614%\n",
      "Epoch 859\tTrain Loss: 0.03377\tVal Loss: 0.2767\tAccuracy: 86.473430%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860\tTrain Loss: 0.03756\tVal Loss: 0.2742\tAccuracy: 87.922705%\n",
      "Epoch 861\tTrain Loss: 0.03281\tVal Loss: 0.2775\tAccuracy: 86.956522%\n",
      "Epoch 862\tTrain Loss: 0.03858\tVal Loss: 0.2821\tAccuracy: 85.024155%\n",
      "Epoch 863\tTrain Loss: 0.03353\tVal Loss: 0.2788\tAccuracy: 85.990338%\n",
      "Epoch 864\tTrain Loss: 0.03473\tVal Loss: 0.279\tAccuracy: 86.473430%\n",
      "Epoch 865\tTrain Loss: 0.03357\tVal Loss: 0.2735\tAccuracy: 86.956522%\n",
      "Epoch 866\tTrain Loss: 0.03367\tVal Loss: 0.2728\tAccuracy: 87.922705%\n",
      "Epoch 867\tTrain Loss: 0.03329\tVal Loss: 0.2781\tAccuracy: 86.473430%\n",
      "Epoch 868\tTrain Loss: 0.03358\tVal Loss: 0.2788\tAccuracy: 85.990338%\n",
      "Epoch 869\tTrain Loss: 0.03276\tVal Loss: 0.2744\tAccuracy: 87.922705%\n",
      "Epoch 870\tTrain Loss: 0.03289\tVal Loss: 0.2753\tAccuracy: 86.473430%\n",
      "Epoch 871\tTrain Loss: 0.03414\tVal Loss: 0.2785\tAccuracy: 85.507246%\n",
      "Epoch 872\tTrain Loss: 0.03434\tVal Loss: 0.2707\tAccuracy: 88.405797%\n",
      "Epoch 873\tTrain Loss: 0.03298\tVal Loss: 0.2771\tAccuracy: 86.956522%\n",
      "Epoch 874\tTrain Loss: 0.03421\tVal Loss: 0.2743\tAccuracy: 87.922705%\n",
      "Epoch 875\tTrain Loss: 0.03224\tVal Loss: 0.2807\tAccuracy: 85.990338%\n",
      "Epoch 876\tTrain Loss: 0.03722\tVal Loss: 0.2711\tAccuracy: 88.405797%\n",
      "Epoch 877\tTrain Loss: 0.03162\tVal Loss: 0.2752\tAccuracy: 86.473430%\n",
      "Epoch 878\tTrain Loss: 0.03587\tVal Loss: 0.2832\tAccuracy: 85.507246%\n",
      "Epoch 879\tTrain Loss: 0.03295\tVal Loss: 0.2753\tAccuracy: 86.956522%\n",
      "Epoch 880\tTrain Loss: 0.03922\tVal Loss: 0.2825\tAccuracy: 85.990338%\n",
      "Epoch 881\tTrain Loss: 0.03399\tVal Loss: 0.2726\tAccuracy: 86.473430%\n",
      "Epoch 882\tTrain Loss: 0.03456\tVal Loss: 0.2834\tAccuracy: 85.990338%\n",
      "Epoch 883\tTrain Loss: 0.03449\tVal Loss: 0.2698\tAccuracy: 88.405797%\n",
      "Epoch 884\tTrain Loss: 0.03386\tVal Loss: 0.2769\tAccuracy: 86.956522%\n",
      "Epoch 885\tTrain Loss: 0.03475\tVal Loss: 0.2772\tAccuracy: 86.956522%\n",
      "Epoch 886\tTrain Loss: 0.03264\tVal Loss: 0.2691\tAccuracy: 88.405797%\n",
      "Epoch 887\tTrain Loss: 0.0338\tVal Loss: 0.2823\tAccuracy: 85.507246%\n",
      "Epoch 888\tTrain Loss: 0.03245\tVal Loss: 0.2717\tAccuracy: 86.956522%\n",
      "Epoch 889\tTrain Loss: 0.03426\tVal Loss: 0.2807\tAccuracy: 85.507246%\n",
      "Epoch 890\tTrain Loss: 0.03457\tVal Loss: 0.2716\tAccuracy: 88.405797%\n",
      "Epoch 891\tTrain Loss: 0.03437\tVal Loss: 0.2809\tAccuracy: 85.990338%\n",
      "Epoch 892\tTrain Loss: 0.03562\tVal Loss: 0.2834\tAccuracy: 85.507246%\n",
      "Epoch 893\tTrain Loss: 0.03363\tVal Loss: 0.2768\tAccuracy: 86.473430%\n",
      "Epoch 894\tTrain Loss: 0.0343\tVal Loss: 0.2771\tAccuracy: 85.990338%\n",
      "Epoch 895\tTrain Loss: 0.03341\tVal Loss: 0.2696\tAccuracy: 87.439614%\n",
      "Epoch 896\tTrain Loss: 0.0346\tVal Loss: 0.2767\tAccuracy: 85.990338%\n",
      "Epoch 897\tTrain Loss: 0.03272\tVal Loss: 0.2779\tAccuracy: 86.473430%\n",
      "Epoch 898\tTrain Loss: 0.03405\tVal Loss: 0.276\tAccuracy: 85.990338%\n",
      "Epoch 899\tTrain Loss: 0.03419\tVal Loss: 0.2723\tAccuracy: 88.405797%\n",
      "Epoch 900\tTrain Loss: 0.03332\tVal Loss: 0.2761\tAccuracy: 85.990338%\n",
      "Epoch 901\tTrain Loss: 0.03375\tVal Loss: 0.2734\tAccuracy: 86.956522%\n",
      "Epoch 902\tTrain Loss: 0.03224\tVal Loss: 0.2788\tAccuracy: 86.473430%\n",
      "Epoch 903\tTrain Loss: 0.03643\tVal Loss: 0.2665\tAccuracy: 87.922705%\n",
      "Epoch 904\tTrain Loss: 0.03258\tVal Loss: 0.2795\tAccuracy: 84.541063%\n",
      "Epoch 905\tTrain Loss: 0.03417\tVal Loss: 0.2805\tAccuracy: 86.956522%\n",
      "Epoch 906\tTrain Loss: 0.03224\tVal Loss: 0.2805\tAccuracy: 86.473430%\n",
      "Epoch 907\tTrain Loss: 0.03333\tVal Loss: 0.2772\tAccuracy: 85.990338%\n",
      "Epoch 908\tTrain Loss: 0.0341\tVal Loss: 0.2756\tAccuracy: 86.956522%\n",
      "Epoch 909\tTrain Loss: 0.03351\tVal Loss: 0.2771\tAccuracy: 87.439614%\n",
      "Epoch 910\tTrain Loss: 0.03451\tVal Loss: 0.2796\tAccuracy: 85.990338%\n",
      "Epoch 911\tTrain Loss: 0.03203\tVal Loss: 0.2704\tAccuracy: 88.405797%\n",
      "Epoch 912\tTrain Loss: 0.03398\tVal Loss: 0.2816\tAccuracy: 85.990338%\n",
      "Epoch 913\tTrain Loss: 0.03387\tVal Loss: 0.2732\tAccuracy: 87.439614%\n",
      "Epoch 914\tTrain Loss: 0.03466\tVal Loss: 0.2888\tAccuracy: 85.507246%\n",
      "Epoch 915\tTrain Loss: 0.03499\tVal Loss: 0.2671\tAccuracy: 88.405797%\n",
      "Epoch 916\tTrain Loss: 0.03308\tVal Loss: 0.2822\tAccuracy: 84.541063%\n",
      "Epoch 917\tTrain Loss: 0.03459\tVal Loss: 0.2756\tAccuracy: 86.473430%\n",
      "Epoch 918\tTrain Loss: 0.03345\tVal Loss: 0.2849\tAccuracy: 85.024155%\n",
      "Epoch 919\tTrain Loss: 0.03384\tVal Loss: 0.2744\tAccuracy: 86.473430%\n",
      "Epoch 920\tTrain Loss: 0.03937\tVal Loss: 0.2771\tAccuracy: 86.956522%\n",
      "Epoch 921\tTrain Loss: 0.03333\tVal Loss: 0.2773\tAccuracy: 86.473430%\n",
      "Epoch 922\tTrain Loss: 0.03477\tVal Loss: 0.2841\tAccuracy: 85.507246%\n",
      "Epoch 923\tTrain Loss: 0.03285\tVal Loss: 0.2697\tAccuracy: 87.439614%\n",
      "Epoch 924\tTrain Loss: 0.03492\tVal Loss: 0.2822\tAccuracy: 85.507246%\n",
      "Epoch 925\tTrain Loss: 0.03265\tVal Loss: 0.2733\tAccuracy: 86.473430%\n",
      "Epoch 926\tTrain Loss: 0.03494\tVal Loss: 0.2792\tAccuracy: 86.473430%\n",
      "Epoch 927\tTrain Loss: 0.03343\tVal Loss: 0.2706\tAccuracy: 88.405797%\n",
      "Epoch 928\tTrain Loss: 0.03317\tVal Loss: 0.2768\tAccuracy: 85.990338%\n",
      "Epoch 929\tTrain Loss: 0.03351\tVal Loss: 0.2789\tAccuracy: 86.473430%\n",
      "Epoch 930\tTrain Loss: 0.03442\tVal Loss: 0.2734\tAccuracy: 87.922705%\n",
      "Epoch 931\tTrain Loss: 0.03306\tVal Loss: 0.2802\tAccuracy: 85.507246%\n",
      "Epoch 932\tTrain Loss: 0.03456\tVal Loss: 0.2759\tAccuracy: 86.956522%\n",
      "Epoch 933\tTrain Loss: 0.03315\tVal Loss: 0.2816\tAccuracy: 86.473430%\n",
      "Epoch 934\tTrain Loss: 0.03403\tVal Loss: 0.2734\tAccuracy: 86.956522%\n",
      "Epoch 935\tTrain Loss: 0.03622\tVal Loss: 0.2793\tAccuracy: 85.990338%\n",
      "Epoch 936\tTrain Loss: 0.03403\tVal Loss: 0.2753\tAccuracy: 86.473430%\n",
      "Epoch 937\tTrain Loss: 0.03812\tVal Loss: 0.2845\tAccuracy: 85.507246%\n",
      "Epoch 938\tTrain Loss: 0.0331\tVal Loss: 0.2783\tAccuracy: 86.473430%\n",
      "Epoch 939\tTrain Loss: 0.03464\tVal Loss: 0.2756\tAccuracy: 86.473430%\n",
      "Epoch 940\tTrain Loss: 0.03367\tVal Loss: 0.2744\tAccuracy: 86.956522%\n",
      "Epoch 941\tTrain Loss: 0.03586\tVal Loss: 0.2743\tAccuracy: 86.956522%\n",
      "Epoch 942\tTrain Loss: 0.03293\tVal Loss: 0.2799\tAccuracy: 85.990338%\n",
      "Epoch 943\tTrain Loss: 0.03393\tVal Loss: 0.2821\tAccuracy: 86.473430%\n",
      "Epoch 944\tTrain Loss: 0.03305\tVal Loss: 0.2759\tAccuracy: 87.439614%\n",
      "Epoch 945\tTrain Loss: 0.03259\tVal Loss: 0.2816\tAccuracy: 84.541063%\n",
      "Epoch 946\tTrain Loss: 0.034\tVal Loss: 0.2785\tAccuracy: 86.473430%\n",
      "Epoch 947\tTrain Loss: 0.03388\tVal Loss: 0.2737\tAccuracy: 87.922705%\n",
      "Epoch 948\tTrain Loss: 0.03376\tVal Loss: 0.2742\tAccuracy: 86.473430%\n",
      "Epoch 949\tTrain Loss: 0.03432\tVal Loss: 0.2844\tAccuracy: 85.507246%\n",
      "Epoch 950\tTrain Loss: 0.03177\tVal Loss: 0.2704\tAccuracy: 87.922705%\n",
      "Epoch 951\tTrain Loss: 0.03428\tVal Loss: 0.2869\tAccuracy: 85.024155%\n",
      "Epoch 952\tTrain Loss: 0.03224\tVal Loss: 0.2734\tAccuracy: 85.990338%\n",
      "Epoch 953\tTrain Loss: 0.03453\tVal Loss: 0.2787\tAccuracy: 85.990338%\n",
      "Epoch 954\tTrain Loss: 0.03524\tVal Loss: 0.2733\tAccuracy: 87.922705%\n",
      "Epoch 955\tTrain Loss: 0.03289\tVal Loss: 0.284\tAccuracy: 85.507246%\n",
      "Epoch 956\tTrain Loss: 0.0334\tVal Loss: 0.2764\tAccuracy: 86.956522%\n",
      "Epoch 957\tTrain Loss: 0.03351\tVal Loss: 0.2765\tAccuracy: 86.956522%\n",
      "Epoch 958\tTrain Loss: 0.03399\tVal Loss: 0.2768\tAccuracy: 86.473430%\n",
      "Epoch 959\tTrain Loss: 0.03365\tVal Loss: 0.2804\tAccuracy: 85.990338%\n",
      "Epoch 960\tTrain Loss: 0.03443\tVal Loss: 0.2727\tAccuracy: 87.922705%\n",
      "Epoch 961\tTrain Loss: 0.03292\tVal Loss: 0.2831\tAccuracy: 84.541063%\n",
      "Epoch 962\tTrain Loss: 0.03379\tVal Loss: 0.2794\tAccuracy: 85.990338%\n",
      "Epoch 963\tTrain Loss: 0.03345\tVal Loss: 0.2804\tAccuracy: 86.956522%\n",
      "Epoch 964\tTrain Loss: 0.03519\tVal Loss: 0.2845\tAccuracy: 85.990338%\n",
      "Epoch 965\tTrain Loss: 0.03471\tVal Loss: 0.2753\tAccuracy: 85.990338%\n",
      "Epoch 966\tTrain Loss: 0.03514\tVal Loss: 0.2823\tAccuracy: 85.990338%\n",
      "Epoch 967\tTrain Loss: 0.03396\tVal Loss: 0.2769\tAccuracy: 87.439614%\n",
      "Epoch 968\tTrain Loss: 0.03346\tVal Loss: 0.2817\tAccuracy: 86.473430%\n",
      "Epoch 969\tTrain Loss: 0.03424\tVal Loss: 0.2793\tAccuracy: 86.473430%\n",
      "Epoch 970\tTrain Loss: 0.03318\tVal Loss: 0.2775\tAccuracy: 87.439614%\n",
      "Epoch 971\tTrain Loss: 0.03456\tVal Loss: 0.2785\tAccuracy: 85.507246%\n",
      "Epoch 972\tTrain Loss: 0.03463\tVal Loss: 0.2771\tAccuracy: 86.473430%\n",
      "Epoch 973\tTrain Loss: 0.03219\tVal Loss: 0.2691\tAccuracy: 87.922705%\n",
      "Epoch 974\tTrain Loss: 0.03478\tVal Loss: 0.2857\tAccuracy: 85.024155%\n",
      "Epoch 975\tTrain Loss: 0.0323\tVal Loss: 0.2755\tAccuracy: 86.473430%\n",
      "Epoch 976\tTrain Loss: 0.03352\tVal Loss: 0.2825\tAccuracy: 86.473430%\n",
      "Epoch 977\tTrain Loss: 0.0346\tVal Loss: 0.2735\tAccuracy: 87.439614%\n",
      "Epoch 978\tTrain Loss: 0.03332\tVal Loss: 0.2781\tAccuracy: 85.024155%\n",
      "Epoch 979\tTrain Loss: 0.03355\tVal Loss: 0.2747\tAccuracy: 86.473430%\n",
      "Epoch 980\tTrain Loss: 0.03227\tVal Loss: 0.2787\tAccuracy: 86.956522%\n",
      "Epoch 981\tTrain Loss: 0.03602\tVal Loss: 0.2766\tAccuracy: 87.439614%\n",
      "Epoch 982\tTrain Loss: 0.0321\tVal Loss: 0.2777\tAccuracy: 86.473430%\n",
      "Epoch 983\tTrain Loss: 0.03336\tVal Loss: 0.278\tAccuracy: 86.473430%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984\tTrain Loss: 0.03625\tVal Loss: 0.2706\tAccuracy: 87.439614%\n",
      "Epoch 985\tTrain Loss: 0.03319\tVal Loss: 0.2835\tAccuracy: 84.541063%\n",
      "Epoch 986\tTrain Loss: 0.03379\tVal Loss: 0.2741\tAccuracy: 86.473430%\n",
      "Epoch 987\tTrain Loss: 0.03302\tVal Loss: 0.2832\tAccuracy: 85.024155%\n",
      "Epoch 988\tTrain Loss: 0.03314\tVal Loss: 0.2729\tAccuracy: 85.990338%\n",
      "Epoch 989\tTrain Loss: 0.03361\tVal Loss: 0.2799\tAccuracy: 85.990338%\n",
      "Epoch 990\tTrain Loss: 0.03315\tVal Loss: 0.2725\tAccuracy: 87.922705%\n",
      "Epoch 991\tTrain Loss: 0.03443\tVal Loss: 0.2789\tAccuracy: 84.541063%\n",
      "Epoch 992\tTrain Loss: 0.03384\tVal Loss: 0.2815\tAccuracy: 85.990338%\n",
      "Epoch 993\tTrain Loss: 0.03253\tVal Loss: 0.2806\tAccuracy: 86.473430%\n",
      "Epoch 994\tTrain Loss: 0.03339\tVal Loss: 0.2756\tAccuracy: 85.990338%\n",
      "Epoch 995\tTrain Loss: 0.03454\tVal Loss: 0.279\tAccuracy: 85.990338%\n",
      "Epoch 996\tTrain Loss: 0.03291\tVal Loss: 0.2762\tAccuracy: 86.473430%\n",
      "Epoch 997\tTrain Loss: 0.03373\tVal Loss: 0.2812\tAccuracy: 86.956522%\n",
      "Epoch 998\tTrain Loss: 0.03317\tVal Loss: 0.2736\tAccuracy: 86.956522%\n",
      "Epoch 999\tTrain Loss: 0.03399\tVal Loss: 0.2804\tAccuracy: 84.541063%\n",
      "Model saved to models/91.304_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=26, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=6, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(1000, deeper_model, loss_fcn, new_optim, train_res_dataloader, val_res_dataloader, logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b62ce",
   "metadata": {},
   "source": [
    "# 91.30% Accurate!\n",
    "Towards the end the validation loss began trending up and the accuracy began dropping. Further optimization which might squeeze out improvements in accuracy include the use of `nn.Embedding` ([Guo and Berkhahn](https://arxiv.org/abs/1604.06737), 2015) and learning rate annealing. As the Kaggle contest is over, the test set with which ultimate accuracy may be judged, is withheld. Nonetheless, `91.30%` accuracy beats the current highest score on Kaggle by a considerable margin `+10%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae802d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
